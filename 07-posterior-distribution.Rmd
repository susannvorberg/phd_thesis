# A Bayesian Statistical Model for Residue-Residue Contact Prediction

All methods so far predict contacts by finding the one solution of parameters $\via$ and $\wijab$ that maximizes a regularized version of the log likelihood of the [MSA](#abbrev) and in a second step transforming the [MAP](#abbrev) estimates of the couplings $\w^*$ into heuristic contact scores (see Introduction \@ref(pseudo-likelihood)). 
Apart from the heuristic transformation that omits meaningful information comprised in the coupling matrices $\wij$ as discussed in section \@ref(interpreting-coupling-matrices), using the [MAP](#abbrev) estimate of the parameters instead of the true distribution has the decisive disadvantage of concealing the uncertainty of the estimates.

The next sections present the derivation of a principled Bayesian statistical approach for contact prediction eradicating these deficiencies. 
The model provides estimates of the posterior probability distributions of contact states $\cij$ for all residues pairs $i$ and $j$, given the [MSA](#abbrev) $\X$.
A true contact (contact state $\cij\eq1$) is defined as two residues whose $\Cb$-$\Cb$ distance $\le 8 \angstrom$, whereas a residue pair with $\Cb$-$\Cb$ distance $>8 \angstrom$ is considered not to be in physical contact (contact state $\cij\eq0$). 
<!--
The model provides estimates of the probability distributions of the distances $\rij$ between $\Cb$ atoms of all residues pairs $i$ and $j$, given the [MSA](#abbrev) $\X$. 
-->
The parameters $(\v, \w)$ of the [MRF](#abbrev) model describing the probability distribution of the sequences in the [MSA](#abbrev) are treated as hidden parameters that can be integrated out using an approximation to the posterior distribution of couplings $\w$.
This approach also allows to explictely model the dependence of coupling coeffcients $\wij$ on contacts/non-contacts as a mixture of Gaussians with
contact state dependent mixture weights and thus can even learn correlations between couplings.

<!--
## Computing the Posterior Distribution of Distances $p(\r | \X)$ {#overview-posterior-distances}
-->
## Computing the Posterior Probabiilty of a Contact {#overview-posterior-distances}

The joint probability of contact states $\c$ and [MRF](#abbrev) model parameters $(\v, \w)$ given the [MSA](#abbrev) $\X$ and a set of sequence derived features $\phi$ (such as listed in method section \@ref(seq-features)), can be written as a hierarchical Bayesian model of the form:

\begin{align}
        p(\c, \v, \w | \X, \phi) &\propto p(\X | \v, \w) p(\v, \w | \c) \, p(\c | \phi ) \, .
(\#eq:hierarchical-bayesian-model)
\end{align}

The ultimate goal is to compute the posterior probability of the contact states, $p(\c | \X, \phi)$, that can be obtained by treating the parameters $(\v, \w)$ as hidden variables and marginalizing over these parameters,

\begin{align}
    p(\c | \X , \phi) &\propto  p(\X | \c) p(\c | \phi)\\
    p(\X | \c) &= \int \int p(\X | \v,\w) \, p(\v, \w | \c) \,d\v\,d\w  \; .
(\#eq:integrate-out-vw)
\end{align}

The single potentials $\v$ will be fixed at their best estimate $\v^*$ (see method section \@ref(prior-v)) by using a very tight prior $p(\v) = \Gauss(\v|\v^*,\lambda_v^{-1} \I) \rightarrow \delta(\v-\v*)$ for $\lambda_v \rightarrow \infty$ that acts as a delta function. 
This allows the replacement of the intergral over $\v$ with the value of the integrand at its mode $\v^*$. 

Computing the integral over $\w$ can be achieved by factorizing the integrand into factors over $(i,j)$ and performing each integration over the coupling coefficients $\wij$ for $(i,j)$ separately. 

For that account, the prior over $\w$ will be modelled as a product over independent contributions over $\wij$ with $\wij$ depending only on the contact state $\cij$, which is described in detail in method section \@ref(coupling-prior).
The prior over the *Potts* model parameters then yields,

\begin{equation}
  p(\v,\w|\c) = \Gauss(\v|\v^*,\lambda_v^{-1} \I) \, \prod_{1\le i<j\le L} p(\wij|\cij) \; .
(\#eq:definition-parameter-prior)
\end{equation}

Furthermore, method section \@ref(laplace-approx) proposes an approximation to the regularised likelihood, $p(\X | \v,\w) \, p(\v, \w)$, with a Gaussian distribution that facilitates the analytical solution of the integral in eq. \@ref(eq:integrate-out-vw).
The detailed derivation of the solution to the integral is covered in method section \@ref(likelihood-fct-distances).

Finally, the marginals $p(\cij | \X, \phi) = \int  p(\c | \X, \phi) d \c_{\backslash ij}$, where $\c_{\backslash ij}$ is the vector containing all coordinates of $\c$ except $\cij$ can be computed to obtain the posterior probability distribution of the contact states (see method section \@ref(posterior-of-rij)). 


## Training the Hyperparameters in the Likelihood Function of Contact States  {#bayesian-model-training-hyperparameters}

The likelihood function of contact states,  given in eq. \@ref(eq:pXr-final), is obtained by solving the integral in eq. \@ref(eq:integrate-out-vw).
It contains the hyperparameters $\gamma_k(\cij)$, $\muk$ and $\Lk$ representing the weights, mean vectors and precision matrices of the $K$ Gaussian components of the contact state dependent coupling prior, respectively.
The hyperparameters are trained by maximizing the logarithm of the likelihood over a set of training [MSAs](#abbrev) as described in detail in method section \@ref(training-hyperparameters).

The [MAP](#abbrev) estimates of the coupling parameters $\wij^*$ is are needed to compute the Hessian of the regularized *Potts* model likelihood, which again is needed for the Gaussian approximation to the likelihood.
For that purpose, I tested couplings $\wij^*$ obtained from pseudo-likelihood maximization as well as the couplings $\wij^*$ obtained by maximizing the full likelihood with [CD](#abbrev).

## Training on couplings from pseudo-likelihood maximization

I trained models with $K \in \{3,5,10\}$ Gaussian mixture components with diagonal precision matrices $\Lk$ and a zero-component that is fixed at $\mu_0=0$.
Convergence has only been observed for Gaussian mixture with $K \eq 3$ components and for the smallest datasets with 10000 and 100,000 residue pairs per contact class.
However, the resultant mixtures are consistent regardless of the dataset size and independent repeated trainings.

Figure \@ref(fig:stats-pll-3comp-100k) shows the statistics of the hyperparameters for a three component Gaussian mixture trained on 100,000 residue pairs per contact class. 
The zeroth component, with $\mu_0=0$ has a weight for 0.88 for the non-contact class whereas it has only weight 0.5 in the contact class, which is expected given that the couplings $\wijab$ for non-contacts have a much tighter distribution around zero than contacts. Component 2 has the highest standard deviations and the broadest spread. It is not surprising that it has low ($g_2(0) \eq 0.0026$) component weight for non-contacts but a higher  weight ($g_2(1) \eq 0.14$) for contacts. 

(ref:caption-stats-pll-3comp-100k) Statistics for the hyperparameters, $\gamma_k(\cij)$, $\muk$ and $\Lk$ obtained after 371 iterations. Trained on 100,000 residue pairs per contact class for a three component Gaussian mixture and using pseudo-likelihood couplings to estimate the Hessian. 

```{r stats-pll-3comp-100k, echo = FALSE, out.width = '100%', fig.cap = '(ref:caption-stats-pll-3comp-100k)'}
knitr::include_graphics("img/bayesian_model/pll/3/stats-pll-3comp-100k.png")
```

(ref:caption-vis1d-aa-pll-3comp-300k) Visualisation of 1diemnsion projection for AA. Green solid line: Gaussian mixture for contacts. Blue solid line: Gaussian mixture for non-contacts. Light blue dashed line: Gaussian component 0. Dark blue dashed line: Gaussian component 1. Light Green dashed line: Gaussian component 2. Color code is identical to Figure \@ref(fig:stats-pll-3comp-100k) 

```{r vis1d-aa-pll-3comp-300k, echo = FALSE, out.width = '49%', fig.show='hold', fig.cap = '(ref:caption-vis1d-aa-pll-3comp-300k)'}
knitr::include_graphics(c("img/bayesian_model/pll/3/aa_pll-3comp-300k-nolegend.png","img/bayesian_model/pll/3/ww_pll-3comp-300k-nolegend.png","img/bayesian_model/pll/3/er_pll-3comp-300k-nolegend.png","img/bayesian_model/pll/3/ee_pll-3comp-300k-nolegend.png"))
```





















