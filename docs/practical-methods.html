<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>PhD thesis: residue-residue contact prediction</title>
  <meta name="description" content="This is my PhD thesis on residue-residue contact prediction.">
  <meta name="generator" content="bookdown 0.3.9 and GitBook 2.6.7">

  <meta property="og:title" content="PhD thesis: residue-residue contact prediction" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my PhD thesis on residue-residue contact prediction." />
  <meta name="github-repo" content="susannvorberg/phd_thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="PhD thesis: residue-residue contact prediction" />
  
  <meta name="twitter:description" content="This is my PhD thesis on residue-residue contact prediction." />
  

<meta name="author" content="Susann Vorberg">


<meta name="date" content="2017-10-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="theoretical-methods-1.html">
<link rel="next" href="conclusion.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />








<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
  tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]},
  TeX: { 
    extensions: ["mediawiki-texvc.js", "sinuitx.js"],
    Macros: {
      Cb: "C_\\beta",
      eq: "\\!=\\!",
      Gauss: "\\mathcal{N}",
      H: "\\mathbf{H}",
      Hij : "\\H_{ij}",
      I: "\\mathbf{I}",
      Lijk: "\\mathbf{\\Lambda}_{ij,k}",
      Lk: "\\mathbf{\\Lambda}_k",
      LL: "L\\!L(\\mathbf{v}, \\mathbf{w})",
      LLreg: "L\\!L_\\mathrm{reg}",
      muijk: "\\mathbf{\\mu}_{ij,k}",
      muk: "\\mathbf{\\mu}_k",
      neff: "N_\\mathrm{eff}",
      r: "\\mathbf{r}",
      rij: "r_{ij}",
      c: "\\mathbf{c}",
      cij: "c_{ij}",
      seq: "\\mathbf{x}",
      Qij: "\\mathbf{Q}_{ij}",
      q: "\\mathbf{q}",
      qij: "\\mathbf{q'}_{ij}",
      Sn: "\\mathcal{S}_n",
      v: "\\mathbf{v}",
      vi: "\\mathcal{v}_{i}",
      vj: "\\mathcal{v}_{j}",
      via: "\\mathcal{v}_{ia}",
      vja: "\\mathcal{v}_{ja}",
      w: "\\mathbf{w}",
      wij: "\\mathbf{w}_{ij}",
      wijab: "\\mathcal{w}_{ijab}",
      wijcd: "\\mathcal{w}_{ijcd}",
      wklcd: "\\mathcal{w}_{klcd}",
      X: "\\mathbf{X}",
      angstrom: "\\AA \\; \\;"
      }
  }
});
</script>


 
<!--
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js", "[siunitx]/siunitx.js"],
  TeX: { TagSide: "left" }
});
MathJax.Ajax.config.path['siunitx']  = '../latex/MathJax-siunitx-master/';
</script>
//-->



<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD Thesis Susann Vorberg</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="general-intro.html"><a href="general-intro.html"><i class="fa fa-check"></i><b>1</b> Biological Background</a></li>
<li class="chapter" data-level="2" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Contact Prediction</a><ul>
<li class="chapter" data-level="2.1" data-path="local-methods.html"><a href="local-methods.html"><i class="fa fa-check"></i><b>2.1</b> Local Statistical Models</a></li>
<li class="chapter" data-level="2.2" data-path="global-methods.html"><a href="global-methods.html"><i class="fa fa-check"></i><b>2.2</b> Global Statistical Models</a></li>
<li class="chapter" data-level="2.3" data-path="meta-predictors.html"><a href="meta-predictors.html"><i class="fa fa-check"></i><b>2.3</b> Machine Learning Methods and Meta-Predictors</a></li>
<li class="chapter" data-level="2.4" data-path="maxent.html"><a href="maxent.html"><i class="fa fa-check"></i><b>2.4</b> Modelling Protein Families with Potts Model</a><ul>
<li class="chapter" data-level="2.4.1" data-path="maxent.html"><a href="maxent.html#potts-model-properties"><i class="fa fa-check"></i><b>2.4.1</b> Model Properties</a></li>
<li class="chapter" data-level="2.4.2" data-path="maxent.html"><a href="maxent.html#potts-mle"><i class="fa fa-check"></i><b>2.4.2</b> Inferring Parameters for the Potts Model</a></li>
<li class="chapter" data-level="2.4.3" data-path="maxent.html"><a href="maxent.html#potts-model-solutions"><i class="fa fa-check"></i><b>2.4.3</b> Solving the Inverse Potts Problem</a></li>
<li class="chapter" data-level="2.4.4" data-path="maxent.html"><a href="maxent.html#post-processing-heuristics"><i class="fa fa-check"></i><b>2.4.4</b> Computing Contact Maps</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="application-contact-prediction.html"><a href="application-contact-prediction.html"><i class="fa fa-check"></i><b>2.5</b> Applications</a></li>
<li class="chapter" data-level="2.6" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html"><i class="fa fa-check"></i><b>2.6</b> Evaluating Contact Prediction Methods</a><ul>
<li class="chapter" data-level="2.6.1" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html#seq-sep"><i class="fa fa-check"></i><b>2.6.1</b> Sequence Separation</a></li>
<li class="chapter" data-level="2.6.2" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html#interpretation-of-evaluation-results"><i class="fa fa-check"></i><b>2.6.2</b> Interpretation of Evaluation Results</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="challenges.html"><a href="challenges.html"><i class="fa fa-check"></i><b>2.7</b> Challenges for Coevolutionary Inference</a><ul>
<li class="chapter" data-level="2.7.1" data-path="challenges.html"><a href="challenges.html#phylogenetic-effects-as-a-source-of-noise"><i class="fa fa-check"></i><b>2.7.1</b> Phylogenetic Effects as a Source of Noise</a></li>
<li class="chapter" data-level="2.7.2" data-path="challenges.html"><a href="challenges.html#entropic-effects-as-a-source-of-noise"><i class="fa fa-check"></i><b>2.7.2</b> Entropic Effects as a Source of Noise</a></li>
<li class="chapter" data-level="2.7.3" data-path="challenges.html"><a href="challenges.html#finite-sampling-effects"><i class="fa fa-check"></i><b>2.7.3</b> Finite Sampling Effects</a></li>
<li class="chapter" data-level="2.7.4" data-path="challenges.html"><a href="challenges.html#multiple-sequence-alignments"><i class="fa fa-check"></i><b>2.7.4</b> Multiple Sequence Alignments</a></li>
<li class="chapter" data-level="2.7.5" data-path="challenges.html"><a href="challenges.html#alternative-sources-of-coevolution"><i class="fa fa-check"></i><b>2.7.5</b> Alternative Sources of Coevolution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpreting-coupling-matrices.html"><a href="interpreting-coupling-matrices.html"><i class="fa fa-check"></i><b>3</b> Interpretation of Coupling Matrices</a><ul>
<li class="chapter" data-level="3.1" data-path="correlation-between-couplings-and-class.html"><a href="correlation-between-couplings-and-class.html"><i class="fa fa-check"></i><b>3.1</b> Single Coupling Values Carry Evidence of Contacts</a></li>
<li class="chapter" data-level="3.2" data-path="physico-chemical-fingerprints-in-coupling-matrices.html"><a href="physico-chemical-fingerprints-in-coupling-matrices.html"><i class="fa fa-check"></i><b>3.2</b> Physico-Chemical Fingerprints in Coupling Matrices</a></li>
<li class="chapter" data-level="3.3" data-path="coupling-profiles.html"><a href="coupling-profiles.html"><i class="fa fa-check"></i><b>3.3</b> Coupling Profiles Vary with Distance</a></li>
<li class="chapter" data-level="3.4" data-path="higher-order-coupling-profiles.html"><a href="higher-order-coupling-profiles.html"><i class="fa fa-check"></i><b>3.4</b> Higher Order Dependencies Between Couplings</a></li>
<li class="chapter" data-level="3.5" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>3.5</b> Methods</a><ul>
<li class="chapter" data-level="3.5.1" data-path="methods.html"><a href="methods.html#method-coupling-correlation"><i class="fa fa-check"></i><b>3.5.1</b> Correlation of Couplings with Contact Class</a></li>
<li class="chapter" data-level="3.5.2" data-path="methods.html"><a href="methods.html#method-coupling-profile"><i class="fa fa-check"></i><b>3.5.2</b> Coupling Distribution Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="optimizing-full-likelihood.html"><a href="optimizing-full-likelihood.html"><i class="fa fa-check"></i><b>4</b> Optimizing the Full Likelihood</a><ul>
<li class="chapter" data-level="4.1" data-path="full-likelihood-gradient.html"><a href="full-likelihood-gradient.html"><i class="fa fa-check"></i><b>4.1</b> Approximating the Gradient of the Full Likelihood with Contrastive Divergence</a></li>
<li class="chapter" data-level="4.2" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html"><i class="fa fa-check"></i><b>4.2</b> Optimizing the Full Likelihood</a><ul>
<li class="chapter" data-level="4.2.1" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html#convergence-criteria-sgd"><i class="fa fa-check"></i><b>4.2.1</b> Convergence Criterion for Stochastic Gradient Descent</a></li>
<li class="chapter" data-level="4.2.2" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html#sgd-hyperparameter-tuning"><i class="fa fa-check"></i><b>4.2.2</b> Tuning Hyperparameters of Stochastic Gradient Descent Optimizer</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html"><i class="fa fa-check"></i><b>4.3</b> Tuning the Gibbs Sampling Scheme for Contrastive Divergence</a><ul>
<li class="chapter" data-level="4.3.1" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#regularization-for-cd-with-sgd"><i class="fa fa-check"></i><b>4.3.1</b> Tuning Regularization Coefficients for Contrastive Divergence</a></li>
<li class="chapter" data-level="4.3.2" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-sampling-size"><i class="fa fa-check"></i><b>4.3.2</b> Varying the Sample Size</a></li>
<li class="chapter" data-level="4.3.3" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-gibbs-steps"><i class="fa fa-check"></i><b>4.3.3</b> Varying the number of Gibbs Steps</a></li>
<li class="chapter" data-level="4.3.4" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-gibbs-steps"><i class="fa fa-check"></i><b>4.3.4</b> Persistent Contrastive Divergence</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="adam-results.html"><a href="adam-results.html"><i class="fa fa-check"></i><b>4.4</b> Using ADAM to optimize Contrastive Divergence</a></li>
<li class="chapter" data-level="4.5" data-path="comparing-pll-cd.html"><a href="comparing-pll-cd.html"><i class="fa fa-check"></i><b>4.5</b> Comparing CD couplings to pLL couplings</a><ul>
<li class="chapter" data-level="4.5.1" data-path="comparing-pll-cd.html"><a href="comparing-pll-cd.html#protein-1c75a00"><i class="fa fa-check"></i><b>4.5.1</b> Protein 1c75A00</a></li>
<li class="chapter" data-level="4.5.2" data-path="comparing-pll-cd.html"><a href="comparing-pll-cd.html#protein-1ss3a00-and-1c55a00"><i class="fa fa-check"></i><b>4.5.2</b> Protein 1ss3A00 and 1c55A00</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="theoretical-methods.html"><a href="theoretical-methods.html"><i class="fa fa-check"></i><b>4.6</b> Theoretical Methods</a><ul>
<li class="chapter" data-level="4.6.1" data-path="theoretical-methods.html"><a href="theoretical-methods.html#potts-full-likelihood"><i class="fa fa-check"></i><b>4.6.1</b> The Potts Model</a></li>
<li class="chapter" data-level="4.6.2" data-path="theoretical-methods.html"><a href="theoretical-methods.html#gap-treatment"><i class="fa fa-check"></i><b>4.6.2</b> Treating Gaps as Missing Information</a></li>
<li class="chapter" data-level="4.6.3" data-path="theoretical-methods.html"><a href="theoretical-methods.html#the-regularized-full-log-likelihood-and-its-gradient-with-gap-treatment"><i class="fa fa-check"></i><b>4.6.3</b> The Regularized Full Log Likelihood and its Gradient With Gap Treatment</a></li>
<li class="chapter" data-level="4.6.4" data-path="theoretical-methods.html"><a href="theoretical-methods.html#prior-v"><i class="fa fa-check"></i><b>4.6.4</b> The prior on <span class="math inline">\(\v\)</span></a></li>
<li class="chapter" data-level="4.6.5" data-path="theoretical-methods.html"><a href="theoretical-methods.html#methods-sgd"><i class="fa fa-check"></i><b>4.6.5</b> Practical Methods</a></li>
<li class="chapter" data-level="4.6.6" data-path="theoretical-methods.html"><a href="theoretical-methods.html#methods-full-likelihood-adam"><i class="fa fa-check"></i><b>4.6.6</b> Tuning Hyperparameters of <em>ADAM</em> Optimizer</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="methods-cd-sampling.html"><a href="methods-cd-sampling.html"><i class="fa fa-check"></i><b>4.7</b> Computing the Gradient with Contrastive Divergence</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="contact-prior.html"><a href="contact-prior.html"><i class="fa fa-check"></i><b>5</b> Random Forest Contact Prior</a><ul>
<li class="chapter" data-level="5.1" data-path="random-forest-classifiers.html"><a href="random-forest-classifiers.html"><i class="fa fa-check"></i><b>5.1</b> Random Forest Classifiers</a></li>
<li class="chapter" data-level="5.2" data-path="hyperparameter-optimization-for-random-forest.html"><a href="hyperparameter-optimization-for-random-forest.html"><i class="fa fa-check"></i><b>5.2</b> Hyperparameter Optimization for Random Forest</a></li>
<li class="chapter" data-level="5.3" data-path="evaluating-random-forest-model-as-contact-predictor.html"><a href="evaluating-random-forest-model-as-contact-predictor.html"><i class="fa fa-check"></i><b>5.3</b> Evaluating Random Forest Model as Contact Predictor</a></li>
<li class="chapter" data-level="5.4" data-path="using-contact-scores-as-additional-features.html"><a href="using-contact-scores-as-additional-features.html"><i class="fa fa-check"></i><b>5.4</b> Using Contact Scores as Additional Features</a></li>
<li class="chapter" data-level="5.5" data-path="methods-1.html"><a href="methods-1.html"><i class="fa fa-check"></i><b>5.5</b> Methods</a><ul>
<li class="chapter" data-level="5.5.1" data-path="methods-1.html"><a href="methods-1.html#seq-features"><i class="fa fa-check"></i><b>5.5.1</b> Features used to train Random Forest Model</a></li>
<li class="chapter" data-level="5.5.2" data-path="methods-1.html"><a href="methods-1.html#seq-features-global"><i class="fa fa-check"></i><b>5.5.2</b> Global Features</a></li>
<li class="chapter" data-level="5.5.3" data-path="methods-1.html"><a href="methods-1.html#seq-features-single"><i class="fa fa-check"></i><b>5.5.3</b> Single Position Features</a></li>
<li class="chapter" data-level="5.5.4" data-path="methods-1.html"><a href="methods-1.html#seq-features-pairwise"><i class="fa fa-check"></i><b>5.5.4</b> Pairwise Features</a></li>
<li class="chapter" data-level="5.5.5" data-path="methods-1.html"><a href="methods-1.html#rf-training"><i class="fa fa-check"></i><b>5.5.5</b> Training Random Forest Contact Prior</a></li>
<li class="chapter" data-level="5.5.6" data-path="methods-1.html"><a href="methods-1.html#rf-feature-selection"><i class="fa fa-check"></i><b>5.5.6</b> Feature Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bayesian-approach.html"><a href="bayesian-approach.html"><i class="fa fa-check"></i><b>6</b> A Bayesian Statistical Model for Residue-Residue Contact Prediction</a><ul>
<li class="chapter" data-level="6.1" data-path="overview-posterior-distances.html"><a href="overview-posterior-distances.html"><i class="fa fa-check"></i><b>6.1</b> Computing the Posterior Probabiilty of a Contact</a></li>
<li class="chapter" data-level="6.2" data-path="coupling-prior.html"><a href="coupling-prior.html"><i class="fa fa-check"></i><b>6.2</b> Modelling the Prior Over Couplings Depending on Contact States</a></li>
<li class="chapter" data-level="6.3" data-path="bayesian-model-training-hyperparameters.html"><a href="bayesian-model-training-hyperparameters.html"><i class="fa fa-check"></i><b>6.3</b> Training the Hyperparameters in the Likelihood Function of Contact States</a></li>
<li class="chapter" data-level="6.4" data-path="training-on-couplings-from-pseudo-likelihood-maximization.html"><a href="training-on-couplings-from-pseudo-likelihood-maximization.html"><i class="fa fa-check"></i><b>6.4</b> Training on couplings from pseudo-likelihood maximization</a></li>
<li class="chapter" data-level="6.5" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html"><i class="fa fa-check"></i><b>6.5</b> Theoretical Methods</a><ul>
<li class="chapter" data-level="6.5.1" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#methods-coupling-prior"><i class="fa fa-check"></i><b>6.5.1</b> Modelling the Prior Over Couplings Depending on Contact States</a></li>
<li class="chapter" data-level="6.5.2" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#laplace-approx"><i class="fa fa-check"></i><b>6.5.2</b> Gaussian Approximation to the Posterior of Couplings</a></li>
<li class="chapter" data-level="6.5.3" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#likelihood-fct-distances"><i class="fa fa-check"></i><b>6.5.3</b> Integrating out the Hidden Variables to Obtain the Likelihood Function of the Contact States</a></li>
<li class="chapter" data-level="6.5.4" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#posterior-of-rij"><i class="fa fa-check"></i><b>6.5.4</b> Computing The Posterior Probability of Contacts</a></li>
<li class="chapter" data-level="6.5.5" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#Hessian-offdiagonal"><i class="fa fa-check"></i><b>6.5.5</b> The Hessian off-diagonal Elements Carry a Negligible Signal</a></li>
<li class="chapter" data-level="6.5.6" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#neg-Hessian-computation"><i class="fa fa-check"></i><b>6.5.6</b> Efficiently Computing the negative Hessian of the regularized log-likelihood</a></li>
<li class="chapter" data-level="6.5.7" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#inv-lambda-ij-k"><i class="fa fa-check"></i><b>6.5.7</b> Efficiently Computing the Inverse of Matrix <span class="math inline">\(\Lijk\)</span></a></li>
<li class="chapter" data-level="6.5.8" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#gradient-muk"><i class="fa fa-check"></i><b>6.5.8</b> The gradient of the log likelihood with respect to <span class="math inline">\(\muk\)</span></a></li>
<li class="chapter" data-level="6.5.9" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#gradient-lambdak"><i class="fa fa-check"></i><b>6.5.9</b> The gradient of the log likelihood with respect to <span class="math inline">\(\Lk\)</span></a></li>
<li class="chapter" data-level="6.5.10" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#the-gradient-of-the-log-likelihood-with-respect-to-gamma_k"><i class="fa fa-check"></i><b>6.5.10</b> The gradient of the log likelihood with respect to <span class="math inline">\(\gamma_k\)</span></a></li>
<li class="chapter" data-level="6.5.11" data-path="theoretical-methods-1.html"><a href="theoretical-methods-1.html#extending-the-bayesian-statistical-model-for-the-prediction-of-protein-residue-residue-distances"><i class="fa fa-check"></i><b>6.5.11</b> Extending the Bayesian Statistical Model for the Prediction of Protein Residue-Residue Distances</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="practical-methods.html"><a href="practical-methods.html"><i class="fa fa-check"></i><b>6.6</b> Practical Methods</a><ul>
<li class="chapter" data-level="6.6.1" data-path="practical-methods.html"><a href="practical-methods.html#training-hyperparameters"><i class="fa fa-check"></i><b>6.6.1</b> Training the Hyperparameters in the Likelihood Function of Contact States</a></li>
<li class="chapter" data-level="6.6.2" data-path="practical-methods.html"><a href="practical-methods.html#dataset-training-hyperparmeters"><i class="fa fa-check"></i><b>6.6.2</b> Dataset Specifications</a></li>
<li class="chapter" data-level="6.6.3" data-path="practical-methods.html"><a href="practical-methods.html#model-specifications-training-hyperparmeters"><i class="fa fa-check"></i><b>6.6.3</b> Model Specifications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>7</b> Conclusion</a></li>
<li class="chapter" data-level="8" data-path="general-methods.html"><a href="general-methods.html"><i class="fa fa-check"></i><b>8</b> General Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="dataset.html"><a href="dataset.html"><i class="fa fa-check"></i><b>8.1</b> Dataset</a></li>
<li class="chapter" data-level="8.2" data-path="computing-pseudo-likelihood-couplings.html"><a href="computing-pseudo-likelihood-couplings.html"><i class="fa fa-check"></i><b>8.2</b> Computing Pseudo-Likelihood Couplings</a><ul>
<li class="chapter" data-level="8.2.1" data-path="computing-pseudo-likelihood-couplings.html"><a href="computing-pseudo-likelihood-couplings.html#diff-ccmpred-ccmpredpy"><i class="fa fa-check"></i><b>8.2.1</b> Differences between CCMpred and CCMpredpy</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="seq-reweighting.html"><a href="seq-reweighting.html"><i class="fa fa-check"></i><b>8.3</b> Sequence Reweighting</a></li>
<li class="chapter" data-level="8.4" data-path="amino-acid-frequencies.html"><a href="amino-acid-frequencies.html"><i class="fa fa-check"></i><b>8.4</b> Computing Amino Acid Frequencies</a></li>
<li class="chapter" data-level="8.5" data-path="methods-regularization.html"><a href="methods-regularization.html"><i class="fa fa-check"></i><b>8.5</b> Regularization</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="abbrev.html"><a href="abbrev.html"><i class="fa fa-check"></i><b>A</b> Abbreviations</a></li>
<li class="chapter" data-level="B" data-path="amino-acids.html"><a href="amino-acids.html"><i class="fa fa-check"></i><b>B</b> Amino Acid Alphabet</a></li>
<li class="chapter" data-level="C" data-path="dataset-properties.html"><a href="dataset-properties.html"><i class="fa fa-check"></i><b>C</b> Dataset Properties</a></li>
<li class="chapter" data-level="D" data-path="interpretation-of-coupling-matrices.html"><a href="interpretation-of-coupling-matrices.html"><i class="fa fa-check"></i><b>D</b> Interpretation of Coupling Matrices</a></li>
<li class="chapter" data-level="E" data-path="optimizing-full-likelihood-with-gradient-descent.html"><a href="optimizing-full-likelihood-with-gradient-descent.html"><i class="fa fa-check"></i><b>E</b> Optimizing Full Likelihood with Gradient Descent</a></li>
<li class="chapter" data-level="F" data-path="training-of-the-random-forest-contact-prior.html"><a href="training-of-the-random-forest-contact-prior.html"><i class="fa fa-check"></i><b>F</b> Training of the Random Forest Contact Prior</a></li>
<li class="chapter" data-level="G" data-path="bayesian-statistical-model-for-contact-prediction.html"><a href="bayesian-statistical-model-for-contact-prediction.html"><i class="fa fa-check"></i><b>G</b> Bayesian statistical model for contact prediction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PhD thesis: residue-residue contact prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-methods" class="section level2">
<h2><span class="header-section-number">6.6</span> Practical Methods</h2>
<div id="training-hyperparameters" class="section level3">
<h3><span class="header-section-number">6.6.1</span> Training the Hyperparameters in the Likelihood Function of Contact States</h3>
<p>The model parameters <span class="math inline">\(\mathbf{\mu} = (\mathbf{\mu}_{1},\ldots,\mathbf{\mu}_K)\)</span>, <span class="math inline">\(\mathbf{\Lambda} = (\mathbf{\Lambda}_1,\ldots,\mathbf{\Lambda}_K)\)</span> and <span class="math inline">\(\mathbf{\gamma} = (\mathbf{\gamma}_1,\ldots,\mathbf{\gamma}_K)\)</span> will be trained by maximizing the logarithm of the full likelihood over a set of training <a href="abbrev.html#abbrev">MSAs</a> <span class="math inline">\(\X^1,\ldots,\X^N\)</span> and associated structures with <span class="math inline">\(\c^1,\ldots,\c^M\)</span> plus a regularizer <span class="math inline">\(R(\mathbf{\mu}, \mathbf{\Lambda})\)</span>:</p>
<span class="math display">\[\begin{equation}
    L\!L(\mathbf{\mu}, \mathbf{\Lambda}, \mathbf{\gamma}) + R(\mathbf{\mu}, \mathbf{\Lambda}) = \sum_{n=1}^M  \log p(\X^m | \c^m, \mathbf{\mu}, \mathbf{\Lambda}, \mathbf{\gamma} ) + R(\mathbf{\mu}, \mathbf{\Lambda})  \rightarrow \max \, .
\end{equation}\]</span>
<p>The regulariser penalizes values of <span class="math inline">\(\muk\)</span> and <span class="math inline">\(\Lk\)</span> that deviate too far from zero:</p>
<span class="math display" id="eq:reg">\[\begin{align}
    R(\mathbf{\mu}, \mathbf{\Lambda}) = -\frac{1}{2 \sigma_{\mu}^2} \sum_{k=1}^K \sum_{ab=1}^{400} \mu_{k,ab}^2 
                        -\frac{1}{2 \sigma_\text{diag}^2} \sum_{k=1}^K \sum_{ab=1}^{400} \Lambda_{k,ab,ab}^2
\tag{6.31}
\end{align}\]</span>
<p>Reasonable values are <span class="math inline">\(\sigma_{\mu}=0.1\)</span>, <span class="math inline">\(\sigma_\text{diag} = 100\)</span>.</p>
<p>The log likelihood can be optimized using L-BFGS-B <span class="citation">[<a href="#ref-Byrd1995">236</a>]</span>, which requires the computation of the gradient of the log likelihood. For simplicity of notation, the following calculations consider the contribution of the log likelihood for just one protein, which allows to drop the index <span class="math inline">\(m\)</span> in <span class="math inline">\(\cij^m\)</span>, <span class="math inline">\((\wij^m)^*\)</span> and <span class="math inline">\(\Hij^m\)</span>. From eq. <a href="theoretical-methods-1.html#eq:pXr-final">(6.12)</a> the log likelihood for a single protein is</p>
<span class="math display" id="eq:ll-coupling-prior">\[\begin{equation}
    L\!L(\mathbf{\mu}, \mathbf{\Lambda}, \gamma_k) =  \sum_{1 \le i &lt; j \le L}  \log \sum_{k=0}^K g_{k}(\cij) \frac{\Gauss( \mathbf{0} | \muk, \Lk^{-1})}{\Gauss(\mathbf{0} | \muijk, \Lijk^{-1})}  + R(\mathbf{\mu}, \mathbf{\Lambda}) + \text{const.}\,.
\tag{6.32}
\end{equation}\]</span>
<p>For the optimization, I used the module <code>optimize.minimize</code> from the Python package <code>SciPy (v 0.19.1)</code> and the flag <code>method=&quot;L-BFGS-B&quot;</code>. According to the default setting, optimization will converge when <code>(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} &lt;= ftol</code> with <code>ftol=2.220446049250313e-09</code>.</p>
</div>
<div id="dataset-training-hyperparmeters" class="section level3">
<h3><span class="header-section-number">6.6.2</span> Dataset Specifications</h3>
<p>An equal number of residue pairs that are in physical contact <span class="math inline">\(\Delta\Cb &lt;8 \angstrom\)</span> and are not in contact <span class="math inline">\(\Delta\Cb &gt;8 \angstrom\)</span> is selected according to the following criteria:</p>
<ul>
<li>contact: <span class="math inline">\(\Delta\Cb &lt;8 \angstrom\)</span></li>
<li>non-contact: <span class="math inline">\(\Delta\Cb &gt;8 \angstrom\)</span> or <span class="math inline">\(\Delta\Cb &gt;20 \angstrom\)</span></li>
<li>diversity (<span class="math inline">\(\frac{\sqrt{N}}{L}\)</span>) &gt; 0.3</li>
<li>percentage of gaps per column <span class="math inline">\(\leq 0.5\)</span></li>
<li>number of non-gapped sequences at position <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, <span class="math inline">\(N_{ij} &gt; 1\)</span></li>
<li>maximum number of contacts selected per protein = 500</li>
<li>maximum number of non-contacts selected per protein = 1000</li>
<li>number residue pairs for contacts (<span class="math inline">\(\cij \eq 1\)</span>) and<br />
non-contacts (<span class="math inline">\(\cij \eq 0\)</span>) <span class="math inline">\(\in \{10000, 100000, 30000, 500000 \}\)</span></li>
</ul>
<p>Before residue pairs are selected from a protein, they are shuffled to avoid position bias. Proteins from subsets 1-5 of the dataset described in method section <a href="dataset.html#dataset">8.1</a> have been used for training.</p>
<p>The <a href="abbrev.html#abbrev">MAP</a> estimates of the coupling parameters <span class="math inline">\(\wij^*\)</span> that are needed to compute the Hessian <span class="math inline">\(\Hij\)</span> as descibed in method section <a href="theoretical-methods-1.html#neg-Hessian-computation">6.5.6</a> are computed by maximizing the pseudo-likelihodd and by maximizing the full likelihood with contrastive divergence.</p>
</div>
<div id="model-specifications-training-hyperparmeters" class="section level3">
<h3><span class="header-section-number">6.6.3</span> Model Specifications</h3>
<p>The mixture weights <span class="math inline">\(g_k(\cij)\)</span> are randomly sampled from a uniform distribution over the half-open interval [0, 1) and normalized so that <span class="math inline">\(\sum_k^K g_k(\cij) = 1\)</span> for <span class="math inline">\(\cij=0\)</span> and <span class="math inline">\(\cij=1\)</span>, respectively. Subsequently, the <span class="math inline">\(g_k(\cij)\)</span> are reparameterized as softmax functions as given in eq. <a href="theoretical-methods-1.html#eq:def-g-k-binary">(6.5)</a> and fixing <span class="math inline">\(\gamma_0(\cij)=0\)</span> to avoid overparametrization.</p>
<p>The 400 dimensional <span class="math inline">\(\muk\)</span> vectors for <span class="math inline">\(k \in \{1, \ldots, K\}\)</span> are initialized from 400 random draws from a normal distribution with zero mean and standard deviation <span class="math inline">\(\sigma \eq 0.05\)</span>. The zeroth component is kept fixed at zero (<span class="math inline">\(\mathbf{\mu_0} \eq 0\)</span>) and will not be optimized.</p>
<p>The precision matrices <span class="math inline">\(\Lk\)</span> will be modelled as diagonal matrices, setting all off-diagonal elements to zero. The 400 diagonal elements <span class="math inline">\((\Lk)_{ab, ab}\)</span> for <span class="math inline">\(k \in \{1, \ldots, K\}\)</span> are initialized from 400 random draws from a normal distribution with zero mean and standard deviation <span class="math inline">\(\sigma \eq 0.005\)</span>. The 400 diagonal elements of the precision matrix for the zeroth component <span class="math inline">\(\mathbf{\Lambda_0}\)</span> are initialized as 400 random draws from a normal distribution with zero mean and standard deviation <span class="math inline">\(\sigma \eq 0.0005\)</span>. Therefore, the zeroth component is sharply centered at zero. Furthermore, the diagonals of the precision matrices are reparameterized as <span class="math inline">\((\Lk)_{ab, ab} = \exp((\Lk)_{ab, ab}^{\prime})\)</span> in order to ensure that the values stay positive. Gradients for <span class="math inline">\(\Lk\)</span> derived in next sections have been adapted according to this reparametrization.</p>
<p>The number of model parameters assembles as follows:</p>
<ul>
<li><span class="math inline">\((K-1) \times 400\)</span> parameters for <span class="math inline">\(\muk\)</span> with <span class="math inline">\(k \in \{1, \ldots, K \}\)</span> (<span class="math inline">\(\mu_0 = 0\)</span>)</li>
<li><span class="math inline">\(K \times 400\)</span> parameters for the diagonal <span class="math inline">\((\Lk)_{ab, ab}\)</span> with <span class="math inline">\(k \in \{0, \ldots, K\}\)</span></li>
<li><span class="math inline">\(2 \times (K\!-\!1)\)</span> parameters for <span class="math inline">\(\gamma_k(\cij)\)</span> for <span class="math inline">\(k \in \{1,2\}\)</span> and <span class="math inline">\(\cij \in \{0,1\}\)</span> (<span class="math inline">\(\gamma_0(\cij)\eq1\)</span>).</li>
</ul>
<p>This yields 2004 parameters for <span class="math inline">\(K\eq3\)</span> Gaussian components, 3608 parameters for <span class="math inline">\(K\eq5\)</span> and 7618 parameters for <span class="math inline">\(K\eq10\)</span> components.</p>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Byrd1995">
<p>236. Byrd, R.H., Lu, P., Nocedal, J., and Zhu, C. (1995). A Limited Memory Algorithm for Bound Constrained Optimization. SIAM J. Sci. Comput. <em>16</em>, 1190–1208. Available at: <a href="http://epubs.siam.org/doi/10.1137/0916069" class="uri">http://epubs.siam.org/doi/10.1137/0916069</a>.</p>
</div>
</div>
<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://contactpredictionthesis.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="theoretical-methods-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/susannvorberg/phd_thesis/edit/master/07-posterior-distribution.Rmd",
"text": "Edit"
},
"download": ["PhD_thesis_Susann_Vorberg.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
