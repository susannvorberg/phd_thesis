<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>PhD thesis: residue-residue contact prediction</title>
  <meta name="description" content="This is my PhD thesis on residue-residue contact prediction.">
  <meta name="generator" content="bookdown 0.3.9 and GitBook 2.6.7">

  <meta property="og:title" content="PhD thesis: residue-residue contact prediction" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my PhD thesis on residue-residue contact prediction." />
  <meta name="github-repo" content="susannvorberg/phd_thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="PhD thesis: residue-residue contact prediction" />
  
  <meta name="twitter:description" content="This is my PhD thesis on residue-residue contact prediction." />
  

<meta name="author" content="Susann Vorberg">


<meta name="date" content="2017-08-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="contact-prediction.html">
<link rel="next" href="interpretation-of-coupling-matrices.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />








<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
  TeX: { 
    extensions: ["mediawiki-texvc.js"],
    Macros: {
      eq: "\\!=\\!",
      neff: "N_\\mathrm{eff}",
      seq: "\\mathbf{x}",
      v: "\\mathbf{v}",
      via: "\\mathcal{v}_{ia}",
      w: "\\mathbf{w}",
      wijab: "\\mathcal{w}_{ijab}",
      wijcd: "\\mathcal{w}_{ijcd}",
      I: "\\mathbf{I}",
      Cb: "C_\\beta"
      }
  }
});
</script>

<!--
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
   extensions: ["[siunitx]/siunitx.js"]
 });
 MathJax.Ajax.config.path['siunitx']  = 'http://rawgit.com/burnpanck/MathJax-siunitx/master/';
 </script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { TagSide: "left" }
});
</script>
//-->



<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD Thesis Susann Vorberg</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="structure-prediction.html"><a href="structure-prediction.html"><i class="fa fa-check"></i><b>1.1</b> Structure Prediction</a><ul>
<li class="chapter" data-level="1.1.1" data-path="structure-prediction.html"><a href="structure-prediction.html#template-based-methods"><i class="fa fa-check"></i><b>1.1.1</b> Template-based methods</a></li>
<li class="chapter" data-level="1.1.2" data-path="structure-prediction.html"><a href="structure-prediction.html#template-free-structure-prediction"><i class="fa fa-check"></i><b>1.1.2</b> Template-free structure prediction</a></li>
<li class="chapter" data-level="1.1.3" data-path="structure-prediction.html"><a href="structure-prediction.html#contact-assisted-denovo-predictions"><i class="fa fa-check"></i><b>1.1.3</b> contact assisted denovo predictions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="contact-prediction.html"><a href="contact-prediction.html"><i class="fa fa-check"></i><b>1.2</b> Contact Prediction</a><ul>
<li class="chapter" data-level="1.2.1" data-path="contact-prediction.html"><a href="contact-prediction.html#correlated-mutations"><i class="fa fa-check"></i><b>1.2.1</b> Correlated mutations</a></li>
<li class="chapter" data-level="1.2.2" data-path="contact-prediction.html"><a href="contact-prediction.html#intro-cp-evaluation"><i class="fa fa-check"></i><b>1.2.2</b> Benchmarking methods</a></li>
<li class="chapter" data-level="1.2.3" data-path="contact-prediction.html"><a href="contact-prediction.html#pitfalls"><i class="fa fa-check"></i><b>1.2.3</b> Pitfalls</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="state-of-the-art-cp.html"><a href="state-of-the-art-cp.html"><i class="fa fa-check"></i><b>1.3</b> State of the Art CP</a><ul>
<li class="chapter" data-level="1.3.1" data-path="state-of-the-art-cp.html"><a href="state-of-the-art-cp.html#local-methods"><i class="fa fa-check"></i><b>1.3.1</b> Local methods</a></li>
<li class="chapter" data-level="1.3.2" data-path="state-of-the-art-cp.html"><a href="state-of-the-art-cp.html#global-methods"><i class="fa fa-check"></i><b>1.3.2</b> Global methods</a></li>
<li class="chapter" data-level="1.3.3" data-path="state-of-the-art-cp.html"><a href="state-of-the-art-cp.html#maxent"><i class="fa fa-check"></i><b>1.3.3</b> Maximum entropy models for modelling protein families</a></li>
<li class="chapter" data-level="1.3.4" data-path="state-of-the-art-cp.html"><a href="state-of-the-art-cp.html#post-processing-heuristics"><i class="fa fa-check"></i><b>1.3.4</b> Computing contact map from coupling matrix</a></li>
<li class="chapter" data-level="1.3.5" data-path="state-of-the-art-cp.html"><a href="state-of-the-art-cp.html#meta-predictors"><i class="fa fa-check"></i><b>1.3.5</b> Meta-predictors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretation-of-coupling-matrices.html"><a href="interpretation-of-coupling-matrices.html"><i class="fa fa-check"></i><b>2</b> Interpretation of Coupling Matrices</a><ul>
<li class="chapter" data-level="2.1" data-path="single-coupling-values-carry-evidence-of-contacts.html"><a href="single-coupling-values-carry-evidence-of-contacts.html"><i class="fa fa-check"></i><b>2.1</b> Single Coupling Values Carry Evidence of Contacts</a></li>
<li class="chapter" data-level="2.2" data-path="physico-chemical-fingerprints-in-coupling-matrices.html"><a href="physico-chemical-fingerprints-in-coupling-matrices.html"><i class="fa fa-check"></i><b>2.2</b> Physico-Chemical Fingerprints in Coupling Matrices</a></li>
<li class="chapter" data-level="2.3" data-path="signals-in-coupling-matrices-vary-with-distance.html"><a href="signals-in-coupling-matrices-vary-with-distance.html"><i class="fa fa-check"></i><b>2.3</b> Signals in Coupling Matrices Vary with Distance</a></li>
<li class="chapter" data-level="2.4" data-path="higher-order-dependencies-between-couplings.html"><a href="higher-order-dependencies-between-couplings.html"><i class="fa fa-check"></i><b>2.4</b> Higher Order dependencies between Couplings</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>3</b> Methods</a><ul>
<li class="chapter" data-level="3.1" data-path="dataset.html"><a href="dataset.html"><i class="fa fa-check"></i><b>3.1</b> Dataset</a></li>
<li class="chapter" data-level="3.2" data-path="optimizing-pseudo-likelihood.html"><a href="optimizing-pseudo-likelihood.html"><i class="fa fa-check"></i><b>3.2</b> Optimizing Pseudo-Likelihood</a><ul>
<li class="chapter" data-level="3.2.1" data-path="optimizing-pseudo-likelihood.html"><a href="optimizing-pseudo-likelihood.html#pseudo-likelihood-objective-function-and-its-gradients"><i class="fa fa-check"></i><b>3.2.1</b> Pseudo-Likelihood Objective Function and its Gradients</a></li>
<li class="chapter" data-level="3.2.2" data-path="optimizing-pseudo-likelihood.html"><a href="optimizing-pseudo-likelihood.html#diff-ccmpred-ccmpredpy"><i class="fa fa-check"></i><b>3.2.2</b> Differences between CCMpred and CCMpredpy</a></li>
<li class="chapter" data-level="3.2.3" data-path="optimizing-pseudo-likelihood.html"><a href="optimizing-pseudo-likelihood.html#seq-reweighting"><i class="fa fa-check"></i><b>3.2.3</b> Sequence Reweighting</a></li>
<li class="chapter" data-level="3.2.4" data-path="optimizing-pseudo-likelihood.html"><a href="optimizing-pseudo-likelihood.html#amino-acid-frequencies"><i class="fa fa-check"></i><b>3.2.4</b> Computing Amino Acid Frequencies</a></li>
<li class="chapter" data-level="3.2.5" data-path="optimizing-pseudo-likelihood.html"><a href="optimizing-pseudo-likelihood.html#regularization"><i class="fa fa-check"></i><b>3.2.5</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-coupling-matrices.html"><a href="analysis-of-coupling-matrices.html"><i class="fa fa-check"></i><b>3.3</b> Analysis of Coupling Matrices</a><ul>
<li class="chapter" data-level="3.3.1" data-path="analysis-of-coupling-matrices.html"><a href="analysis-of-coupling-matrices.html#method-coupling-correlation"><i class="fa fa-check"></i><b>3.3.1</b> Correlation of Couplings with Contact Class</a></li>
<li class="chapter" data-level="3.3.2" data-path="analysis-of-coupling-matrices.html"><a href="analysis-of-coupling-matrices.html#method-coupling-profile"><i class="fa fa-check"></i><b>3.3.2</b> Coupling Distribution Plots</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="predicting-residue-residue-contacts-by-optimizing-contrastive-divergence.html"><a href="predicting-residue-residue-contacts-by-optimizing-contrastive-divergence.html"><i class="fa fa-check"></i><b>3.4</b> Predicting Residue-Residue Contacts by Optimizing Contrastive Divergence</a><ul>
<li class="chapter" data-level="3.4.1" data-path="predicting-residue-residue-contacts-by-optimizing-contrastive-divergence.html"><a href="predicting-residue-residue-contacts-by-optimizing-contrastive-divergence.html#full-likelihood"><i class="fa fa-check"></i><b>3.4.1</b> Full-likelihood</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="abbrev.html"><a href="abbrev.html"><i class="fa fa-check"></i><b>A</b> Abbreviations</a></li>
<li class="chapter" data-level="B" data-path="dataset-properties.html"><a href="dataset-properties.html"><i class="fa fa-check"></i><b>B</b> Dataset Properties</a><ul>
<li class="chapter" data-level="B.1" data-path="alignment-diversity.html"><a href="alignment-diversity.html"><i class="fa fa-check"></i><b>B.1</b> Alignment Diversity</a></li>
<li class="chapter" data-level="B.2" data-path="proportion-of-gaps-in-alignment.html"><a href="proportion-of-gaps-in-alignment.html"><i class="fa fa-check"></i><b>B.2</b> Proportion of Gaps in Alignment</a></li>
<li class="chapter" data-level="B.3" data-path="alignment-size-number-of-sequences.html"><a href="alignment-size-number-of-sequences.html"><i class="fa fa-check"></i><b>B.3</b> Alignment Size (number of sequences)</a></li>
<li class="chapter" data-level="B.4" data-path="protein-length.html"><a href="protein-length.html"><i class="fa fa-check"></i><b>B.4</b> Protein Length</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="amino-acid-interaction-preferences-reflected-in-coupling-matrices.html"><a href="amino-acid-interaction-preferences-reflected-in-coupling-matrices.html"><i class="fa fa-check"></i><b>C</b> Amino Acid Interaction Preferences Reflected in Coupling Matrices</a><ul>
<li class="chapter" data-level="C.1" data-path="pi-cation.html"><a href="pi-cation.html"><i class="fa fa-check"></i><b>C.1</b> Pi-Cation interactions</a></li>
<li class="chapter" data-level="C.2" data-path="disulfide.html"><a href="disulfide.html"><i class="fa fa-check"></i><b>C.2</b> Disulfide Bonds</a></li>
<li class="chapter" data-level="C.3" data-path="aromatic-proline.html"><a href="aromatic-proline.html"><i class="fa fa-check"></i><b>C.3</b> Aromatic-Proline Interactions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PhD thesis: residue-residue contact prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="state-of-the-art-cp" class="section level2">
<h2><span class="header-section-number">1.3</span> State of the Art CP</h2>
<div id="local-methods" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Local methods</h3>
<p>MI and correlation measures suffer from transitivity of correlations</p>
</div>
<div id="global-methods" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Global methods</h3>
<p>In 2010, Burger and Nijmwegen developed a Bayesian network model <span class="citation">[<a href="#ref-Burger2010">21</a>]</span> that is able to disentangle direct from indirect correlations and introducing informative priors to improve precision. independently of weight in 2009</p>
</div>
<div id="maxent" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Maximum entropy models for modelling protein families</h3>
<p>The principle of maximum entropy was postulated by Jaynes in 1957 <span class="citation">[<a href="#ref-Jaynes1957a">34</a>]</span> <span class="citation">[<a href="#ref-Jaynes1957b">35</a>]</span>, stating that the probability distribution which best represents observed data is the one that is in agreement with measured constraints and has the largest entropy. It is a distribution that makes minimal assumptions and therefore is the least biased estimate of a distribution given the measured constraints.</p>
<p>Applied to the problem of modelling protein families, one would seek a probability distribution over an alignment <span class="math inline">\(\mathbf{X}\)</span> comprising <span class="math inline">\(N\)</span> protein sequences <span class="math inline">\(\seq^{(n)} = (x_i^{(n)},..., x_L^{(n)})\)</span> of length <span class="math inline">\(L\)</span>. Every position <span class="math inline">\(x_i^{(n)}\)</span> in the <a href="abbrev.html#abbrev">MSA</a> can take one of 21 states representing the 20 naturally occuring amino acids and a gap (‘-’) state. The distribution should reproduce the empirical single <span class="math inline">\(\mathcal{f}(x_i \eq a)\)</span> and pairwise <span class="math inline">\(\mathcal{f}(x_i \eq a, x_j \eq b)\)</span> amino acid frequencies of the alignment:</p>
<span class="math display" id="eq:emp-freq">\[\begin{equation}
 p(x_i\eq a) = \mathcal{f}(x_i\eq a) = \frac{1}{N}\sum_{n=1}^N I(x_i^{(n)} \eq a) \\
 p(x_i\eq a, x_j \eq b) = \mathcal{f}(x_i\eq a, x_j\eq b) = \frac{1}{N} \sum_{n=1}^N I(x_i^{(n)} \eq a, x_j^{(n)} \eq b)
 \tag{1.1}
\end{equation}\]</span>
<p>Introducing Lagrange multipliers to maximize the entropy <span class="math inline">\(S= -\sum_{\seq} p(\seq) \log p(\seq)\)</span> of the distribution subject to the constraints given in eq. <a href="state-of-the-art-cp.html#eq:emp-freq">(1.1)</a> results in the formulation of an exponential model known as <em>Potts model</em> or its generalized form a <em>Markov Random Field</em>:</p>
<span class="math display" id="eq:max-ent-model">\[\begin{equation}
p(\seq | \v,\w) = \frac{1}{Z} \exp \left( \sum_{i=1}^L v_i(x_i) \sum_{1 \leq i &lt; j \leq L}^L w_{ij}(x_i, x_j) \right)
\tag{1.2}
\end{equation}\]</span>
<p><span class="math inline">\(Z\)</span> is a normalization constant also known as <em>partition function</em> that ensures the total probabilty adds up to one by summing over all possible assignments to <span class="math inline">\(\seq\)</span>.</p>
<span class="math display" id="eq:partition-fct-likelihood">\[\begin{equation}
  Z = \sum_{\seq&#39; \in [1,...,20]^L} p(\seq&#39; | \v, \w)
  \tag{1.3}
\end{equation}\]</span>
<div id="properties-of-model-parameters" class="section level4">
<h4><span class="header-section-number">1.3.3.1</span> Properties of model parameters</h4>
<p>The Langrange multipliers <span class="math inline">\(\v\)</span> and <span class="math inline">\(\w\)</span>, introduced to satisfy the constraints in eq. <a href="state-of-the-art-cp.html#eq:emp-freq">(1.1)</a>, specify the maximum entropy model and need to be tuned. The single potentials <span class="math inline">\(v_i(a)\)</span> correspond to the single amino acid frequencies whereas the pairwise potentials <span class="math inline">\(w_{ij}(a,b)\)</span>, also called couplings, reflect the tendency of an amino acid a at position i to co-occur with an amino acid b at position j in the alignment.</p>
<p>Maximum entropy models belong to the family of exponential models and thus have a unique global minimum.</p>
<p>Markov Random Field belongs to the class of undirected graphical models. Therefore they can be represented as a graph with nodes corresponding to positions in the alignment and edges describing the dependency structure between nodes.</p>
<p>Can disentangle direct and indirect correlations.</p>
<p>Infer parameters of a maximum entropy model, more specifically a Potts model (statistical physics) aka markov random fiels (computer science). Likelihood function is convex, but Maximum Likelihood inference of model is infeasible: Likelihood function needs to be reevaluated at each iteration during optimization but partition function term sums over 20^L sequences.</p>
</div>
<div id="infering-model-parameters" class="section level4">
<h4><span class="header-section-number">1.3.3.2</span> Infering model parameters</h4>
<p>Typically, one would obtain parameter estimates by maximizing the log-likelihood function of the parameters over observed sequences in the alignment <span class="math inline">\(\mathbf{X}\)</span>:</p>
<span class="math display">\[\begin{equation}
    \mathcal{L}(\v, \w | \mathbf{X}) = \sum_{n=1}^N \log p(\seq^{(n)}) = \sum_{n=1}^N \left[ \sum_{i=1}^L v_i(x_i^{(n)}) \sum_{\substack{i,j=1 \\ i \neq j}}^L w_{ij}(x_i^{(n)}, x_j^{(n)}) - \log Z \right]
\end{equation}\]</span>
<p>However, optimizing the log-likelihood requires computing the partition function that sums <span class="math inline">\(20^L\)</span> terms. Naturally occurig protein domains comprise hundreds of residues. Because of this exponential complexity in protein length L it is computationally intractable to evaluate the log-likelihood function at every iteration of an optimization procedure.</p>
<p>Several approximate solutions have been developed to evade the infeasible computation of the partition function. In 1999 Lapedes et al. <span class="citation">[<a href="#ref-Lapedes1999">33</a>]</span> were the first to apply maximum entropy models to the problem of predicting residue pairs in spatial proximity and thus entangling transitive effects. They used an iterative Monte Carlo procedure to obtain estimates of the partition function.</p>
<p>In 2009 Weight et al proposed a message-passing algorithm to approximate the partition function <span class="citation">[<a href="#ref-Weigt2009">36</a>]</span>. Eventhough their approach is computationally very expensive and only applicable to small proteins, they obtained remarkable results for the two-component signaling system in bacteria.</p>
<p>Balakrishnan and collegues <span class="citation">[<a href="#ref-Balakrishnan2011">37</a>]</span> were the first to apply L1-regularized pseudo-likelihood optimization in 2011. Pseudo-likelihood optimizes a different objective and does not aim at approximating the partition function Z. This approach is described in more detail in <a href="#Pseudo-Likelihood"><strong>??</strong></a> as it represents the most successfull approach, eventhough it was not taken notice of at that time.</p>
<p>Also in 2011, another approximate solution to the partition fucntion was proposed that uses mean-field expansion <span class="citation">[<a href="#ref-Morcos2011">20</a>]</span>. This method is termed mfDCA. This study resulted in the first 3D models of yet unsolved protein structures being computed with the help of predicted contacts <span class="citation">[<span class="citeproc-not-found" data-reference-id="CITE"><strong>???</strong></span>]</span> This method allowed high-throughput predictions as the mean-field approach boils down to inverting the covariance matrix which allows for shorter running times.</p>
<p>A related approach is sparse inverse covariance estimation (PSICOV) method by Jones and colleggues.<span class="citation">[<a href="#ref-Jones2012">38</a>]</span> They use L1-regularization to invert the correlation matrix and enforce sparsity which is known as grapgical Lasso <span class="citation">[<a href="#ref-Friedman2008">39</a>]</span>. Both procedures, mfDCA and PSICOV, assume that model distribution is a multivariate Gaussian. it has been shown by Banerjee et al. (2008) that this dual optimization solution also applies to binary data (as is the case in this application). In order to represent the <a href="abbrev.html#abbrev">MSA</a> as continuous distributed, each position is encoded as a 20-dimensional binary vector.</p>
<p>So far using pseudo-likelihood maximization to infer the model directly from the input alignment has proven to be the most accurate approach. There exist several implementations of pseudo-likelihood maximization that vary only in implemenation details, perform similarly and thus are equally popular in the community: CCmpred <span class="citation">[<a href="#ref-Seemayer2014">40</a>]</span>, plmDCA<span class="citation">[<a href="#ref-Ekeberg2014">41</a>]</span>, GREMLIN <span class="citation">[<a href="#ref-Kamisetty2013">42</a>]</span>.</p>
</div>
<div id="pseudo-likelihood" class="section level4">
<h4><span class="header-section-number">1.3.3.3</span> Pseudo-Likelihood</h4>
<p>Instead of optimizing the likelihood, Besag suggested in 1975 to rather optimize a function that he termed <em>pseudo-likelihood</em> that replaces the joint probability with the product over conditionals <span class="citation">[<a href="#ref-Besag1975">43</a>]</span>:</p>
<span class="math display">\[\begin{equation}
  p(\seq | \v,\w) =   \prod_{i=1}^L p(x_i | \seq_{/xi}\v,\w) =  \prod_{i=1}^L \frac{1}{Z_i} \exp \left(  v_i(x_i) \sum_{\substack{j=1 \\ j \neq i}}^L w_{ij}(x_i, x_j) \right)
\end{equation}\]</span>
<p>Here, the normalization term <span class="math inline">\(Z_i\)</span> sums only over all assignments to one position <span class="math inline">\(i\)</span> in sequence:</p>
<span class="math display">\[\begin{equation}
  Z_i = \sum_{a=1}^{20} \exp \left( v_i(a) \sum_{\substack{j=1 \\ j \neq i}}^L w_{ij}(a, x_j) \right)
\end{equation}\]</span>
<p>The learning objective must include a regularization, as it is overparametrized. The indeterminacy can be fixed by including a regularization prior that also prevents overfitting. Commonly <span class="citation">[<a href="#ref-Seemayer2014">40</a>]</span> <span class="citation">[<a href="#ref-Ekeberg2014">41</a>]</span>, an L2-regularization is used which corresponds to a zero centered Gaussian prior.</p>
<span class="math display">\[\begin{align}
  R(\v, \w)  &amp;= \mathcal{N}(\v | \vec{0}, \lambda_v I^{-1})  + \mathcal{N}(\w | \vec{0}, \lambda_w I^{-1}) \\
             &amp;= \lambda_v ||\v||_2^2 + \lambda_w ||\w||_2^2 
\end{align}\]</span>
<p>The pseudo-likelihood function retains the concavity of the likelihood.<span class="citation">[<a href="#ref-Stein2015a">44</a>]</span> Moreover, it has been shown that <em>pseudo-likelihood</em> is a consistent estimator in the limit of infinite data for pairwise <a href="abbrev.html#abbrev">MRF</a> <span class="citation">[<a href="#ref-Besag1975">43</a>]</span> <span class="citation">[<a href="#ref-Gidas1988">45</a>]</span>. That is, as the number of sequences in the alignment increases, pseudo-likelihood estimates converge towards the true full likelihood parameters.</p>
<p>the proba- bility of them-th observation, xm, is approximated by the product of the conditional probabilities<span class="citation">[<a href="#ref-Stein2015a">44</a>]</span></p>
<p>Recall from above that our pseudo-likelihood uses the full representation and fixes the gauge by the regularization terms Rl2. Our procedure is therefore first to infer the interaction parameters using using the pseudo-likelihood and the regularization, and then change to the zero-sum gauge <span class="citation">[<a href="#ref-Ekeberg2013">46</a>]</span></p>
<p>On one hand, this improvement might not be surpris-ing: it is known that, for very large data sets, pseudo- likelihood maximization becomes asymptotically equiva- lent to full maximum-likelihood inference, whereas mean- field inference remains intrinsically approximate, and this may result in an improved PLM performance. On the other hand, the above advantage holds if and only if the following two conditions are fulfilled: data a drawn independently from a probability distribution, and this probability distribution is the the Boltzmann distribution of a Potts model. None of these two con- ditions actually hold for real protein sequences <span class="citation">[<a href="#ref-Ekeberg2013">46</a>]</span></p>
<p>Disregarding the improvements, we find that overall the predicted contact pairs for plmDCA and mfDCA are highly overlapping, illustrating the robustness of DCA results with respect to the algorithmic implementation<span class="citation">[<a href="#ref-Ekeberg2013">46</a>]</span></p>
</div>
</div>
<div id="post-processing-heuristics" class="section level3">
<h3><span class="header-section-number">1.3.4</span> Computing contact map from coupling matrix</h3>
<ul>
<li>direct information</li>
<li>frobenius norm</li>
</ul>
<p>average product correction (also for MI)</p>
<p>(benchmark plot for localmethods + ccmpred)</p>
</div>
<div id="meta-predictors" class="section level3">
<h3><span class="header-section-number">1.3.5</span> Meta-predictors</h3>
<ul>
<li>combining different approaches</li>
<li>jones et al: overlap between methods but also many unique predictions</li>
<li>machine learning methods incorporate sequence-derived features:</li>
<li>secondary structure predictions</li>
<li>solvent accessibilty</li>
<li>contact potentials</li>
<li>msa properties</li>
<li>pssms</li>
<li>physico-chemcial properties of amino acids</li>
</ul>
<p>However, Meta-predictors will improve if basic methods improve. Ultra-deep learning paper identifies coevolution features as crucial feature.</p>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Burger2010">
<p>21. Burger, L., and Nimwegen, E. van (2010). Disentangling direct from indirect co-evolution of residues in protein alignments. PLoS Comput. Biol. <em>6</em>, e1000633. Available at: <a href="http://dx.plos.org/10.1371/journal.pcbi.1000633" class="uri">http://dx.plos.org/10.1371/journal.pcbi.1000633</a>.</p>
</div>
<div id="ref-Jaynes1957a">
<p>34. Jaynes, E.T. (1957). Information Theory and Statistical Mechanics I. Phys. Rev. <em>106</em>, 620–630. Available at: <a href="https://link.aps.org/doi/10.1103/PhysRev.106.620" class="uri">https://link.aps.org/doi/10.1103/PhysRev.106.620</a>.</p>
</div>
<div id="ref-Jaynes1957b">
<p>35. Jaynes, E.T. (1957). Information Theory and Statistical Mechanics. II. Phys. Rev. <em>108</em>, 171–190. Available at: <a href="https://link.aps.org/doi/10.1103/PhysRev.108.171" class="uri">https://link.aps.org/doi/10.1103/PhysRev.108.171</a>.</p>
</div>
<div id="ref-Lapedes1999">
<p>33. Lapedes, A., Giraud, B., Liu, L., and Stormo, G. (1999). Correlated mutations in models of protein sequences: phylogenetic and structural effects. <em>33</em>, 236–256. Available at: <a href="http://www.citeulike.org/user/qluo/article/5092214" class="uri">http://www.citeulike.org/user/qluo/article/5092214</a>.</p>
</div>
<div id="ref-Weigt2009">
<p>36. Weigt, M., White, R.A., Szurmant, H., Hoch, J.A., and Hwa, T. (2009). Identification of direct residue contacts in protein-protein interaction by message passing. Proc. Natl. Acad. Sci. U. S. A. <em>106</em>, 67–72. Available at: <a href="http://www.pnas.org/content/106/1/67.abstract" class="uri">http://www.pnas.org/content/106/1/67.abstract</a>.</p>
</div>
<div id="ref-Balakrishnan2011">
<p>37. Balakrishnan, S., Kamisetty, H., Carbonell, J.G., Lee, S.-I., and Langmead, C.J. (2011). Learning generative models for protein fold families. Proteins <em>79</em>, 1061–78. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/21268112" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/21268112</a>.</p>
</div>
<div id="ref-Morcos2011">
<p>20. Morcos, F., Pagnani, A., Lunt, B., Bertolino, A., Marks, D.S., Sander, C., Zecchina, R., Onuchic, J.N., Hwa, T., and Weigt, M. (2011). Direct-coupling analysis of residue coevolution captures native contacts across many protein families. Proc. Natl. Acad. Sci. U. S. A. <em>108</em>, E1293–301. Available at: <a href="http://www.pnas.org/content/108/49/E1293.full" class="uri">http://www.pnas.org/content/108/49/E1293.full</a>.</p>
</div>
<div id="ref-Jones2012">
<p>38. Jones, D.T., Buchan, D.W.A., Cozzetto, D., and Pontil, M. (2012). PSICOV: precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments. Bioinformatics <em>28</em>, 184–90. Available at: <a href="http://bioinformatics.oxfordjournals.org/content/28/2/184.full" class="uri">http://bioinformatics.oxfordjournals.org/content/28/2/184.full</a>.</p>
</div>
<div id="ref-Friedman2008">
<p>39. Friedman, J., Hastie, T., and Tibshirani, R. (2008). Sparse inverse covariance estimation with the graphical lasso. Biostatistics <em>9</em>, 432–41. Available at: <a href="http://biostatistics.oxfordjournals.org/content/9/3/432.abstract" class="uri">http://biostatistics.oxfordjournals.org/content/9/3/432.abstract</a>.</p>
</div>
<div id="ref-Seemayer2014">
<p>40. Seemayer, S., Gruber, M., and Söding, J. (2014). CCMpred-fast and precise prediction of protein residue-residue contacts from correlated mutations. Bioinformatics, btu500. Available at: <a href="http://bioinformatics.oxfordjournals.org/content/early/2014/08/12/bioinformatics.btu500" class="uri">http://bioinformatics.oxfordjournals.org/content/early/2014/08/12/bioinformatics.btu500</a>.</p>
</div>
<div id="ref-Ekeberg2014">
<p>41. Ekeberg, M., Hartonen, T., and Aurell, E. (2014). Fast pseudolikelihood maximization for direct-coupling analysis of protein structure from many homologous amino-acid sequences. J. Comput. Phys. <em>276</em>, 341–356. Available at: <a href="http://www.sciencedirect.com/science/article/pii/S0021999114005178" class="uri">http://www.sciencedirect.com/science/article/pii/S0021999114005178</a>.</p>
</div>
<div id="ref-Kamisetty2013">
<p>42. Kamisetty, H., Ovchinnikov, S., and Baker, D. (2013). Assessing the utility of coevolution-based residue-residue contact predictions in a sequence- and structure-rich era. Proc. Natl. Acad. Sci. U. S. A. <em>110</em>, 15674–9. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3785744{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3785744{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-Besag1975">
<p>43. Besag, J. (1975). Statistical Analysis of Non-Lattice Data. Source Stat. <em>24</em>, 179–195. Available at: <a href="http://www.jstor.org http://www.jstor.org/stable/2987782" class="uri">http://www.jstor.org http://www.jstor.org/stable/2987782</a>.</p>
</div>
<div id="ref-Stein2015a">
<p>44. Stein, R.R., Marks, D.S., and Sander, C. (2015). Inferring Pairwise Interactions from Biological Data Using Maximum-Entropy Probability Models. PLOS Comput. Biol. <em>11</em>, e1004182. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4520494{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4520494{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-Gidas1988">
<p>45. Gidas, B. (1988). Consistency of maximum likelihood and pseudo-likelihood estimators for Gibbs Distributions. Stoch. Differ. Syst. Stoch. Control Theory Appl. Available at: <a href="http://www.researchgate.net/publication/244456377{\_}Consistency{\_}of{\_}maximum{\_}likelihood{\_}and{\_}pseudo-likelihood{\_}estimators{\_}for{\_}Gibbs{\_}Distributions" class="uri">http://www.researchgate.net/publication/244456377{\_}Consistency{\_}of{\_}maximum{\_}likelihood{\_}and{\_}pseudo-likelihood{\_}estimators{\_}for{\_}Gibbs{\_}Distributions</a>.</p>
</div>
<div id="ref-Ekeberg2013">
<p>46. Ekeberg, M., Lövkvist, C., Lan, Y., Weigt, M., and Aurell, E. (2013). Improved contact prediction in proteins: Using pseudolikelihoods to infer Potts models. Phys. Rev. E <em>87</em>, 012707. Available at: <a href="http://link.aps.org/doi/10.1103/PhysRevE.87.012707" class="uri">http://link.aps.org/doi/10.1103/PhysRevE.87.012707</a>.</p>
</div>
</div>
<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://contactpredictionthesis.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="contact-prediction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interpretation-of-coupling-matrices.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/susannvorberg/phd_thesis/edit/master/03-intro.Rmd",
"text": "Edit"
},
"download": ["PhD thesis Susann Vorberg.pdf", "PhD thesis Susann Vorberg.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
