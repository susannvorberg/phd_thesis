<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>PhD thesis: residue-residue contact prediction</title>
  <meta name="description" content="This is my PhD thesis on residue-residue contact prediction.">
  <meta name="generator" content="bookdown 0.3.9 and GitBook 2.6.7">

  <meta property="og:title" content="PhD thesis: residue-residue contact prediction" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my PhD thesis on residue-residue contact prediction." />
  <meta name="github-repo" content="susannvorberg/phd_thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="PhD thesis: residue-residue contact prediction" />
  
  <meta name="twitter:description" content="This is my PhD thesis on residue-residue contact prediction." />
  

<meta name="author" content="Susann Vorberg">


<meta name="date" content="2017-10-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html">
<link rel="next" href="abbrev.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />








<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
  tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]},
  TeX: { 
    extensions: ["mediawiki-texvc.js", "sinuitx.js"],
    Macros: {
      Cb: "C_\\beta",
      eq: "\\!=\\!",
      Gauss: "\\mathcal{N}",
      H: "\\mathbf{H}",
      Hij : "\\H_{ij}",
      I: "\\mathbf{I}",
      Lijk: "\\mathbf{\\Lambda}_{ij,k}",
      Lk: "\\mathbf{\\Lambda}_k",
      LL: "L\\!L(\\mathbf{v}, \\mathbf{w})",
      LLreg: "L\\!L_\\mathrm{reg}",
      muijk: "\\mathbf{\\mu}_{ij,k}",
      muk: "\\mathbf{\\mu}_k",
      neff: "N_\\mathrm{eff}",
      r: "\\mathbf{r}",
      rij: "r_{ij}",
      seq: "\\mathbf{x}",
      Qij: "\\mathbf{Q}_{ij}",
      q: "\\mathbf{q}",
      qij: "\\mathbf{q'}_{ij}",
      Sn: "\\mathcal{S}_n",
      v: "\\mathbf{v}",
      vi: "\\mathcal{v}_{i}",
      vj: "\\mathcal{v}_{j}",
      via: "\\mathcal{v}_{ia}",
      w: "\\mathbf{w}",
      wij: "\\mathbf{w}_{ij}",
      wijab: "\\mathcal{w}_{ijab}",
      wijcd: "\\mathcal{w}_{ijcd}",
      wklcd: "\\mathcal{w}_{klcd}",
      X: "\\mathbf{X}",
      angstrom: "\\AA \\; \\;"
      }
  }
});
</script>


 
<!--
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js", "[siunitx]/siunitx.js"],
  TeX: { TagSide: "left" }
});
MathJax.Ajax.config.path['siunitx']  = '../latex/MathJax-siunitx-master/';
</script>
//-->



<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD Thesis Susann Vorberg</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="general-intro.html"><a href="general-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="protein-structure.html"><a href="protein-structure.html"><i class="fa fa-check"></i><b>1.1</b> Protein Structure</a><ul>
<li class="chapter" data-level="1.1.1" data-path="protein-structure.html"><a href="protein-structure.html#amino-acid-interactions"><i class="fa fa-check"></i><b>1.1.1</b> Amino Acid Interactions</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="structure-prediction.html"><a href="structure-prediction.html"><i class="fa fa-check"></i><b>1.2</b> Structure Prediction</a><ul>
<li class="chapter" data-level="1.2.1" data-path="structure-prediction.html"><a href="structure-prediction.html#template-based-methods"><i class="fa fa-check"></i><b>1.2.1</b> Template-based methods</a></li>
<li class="chapter" data-level="1.2.2" data-path="structure-prediction.html"><a href="structure-prediction.html#template-free-structure-prediction"><i class="fa fa-check"></i><b>1.2.2</b> Template-free structure prediction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html"><i class="fa fa-check"></i><b>2</b> Introduction to Contact Prediction</a><ul>
<li class="chapter" data-level="2.1" data-path="local-methods.html"><a href="local-methods.html"><i class="fa fa-check"></i><b>2.1</b> Local Statistical Models</a></li>
<li class="chapter" data-level="2.2" data-path="global-methods.html"><a href="global-methods.html"><i class="fa fa-check"></i><b>2.2</b> Global Statistical Models</a></li>
<li class="chapter" data-level="2.3" data-path="meta-predictors.html"><a href="meta-predictors.html"><i class="fa fa-check"></i><b>2.3</b> Machine Learning Methods and Meta-Predictors</a></li>
<li class="chapter" data-level="2.4" data-path="maxent.html"><a href="maxent.html"><i class="fa fa-check"></i><b>2.4</b> Modelling Protein Families with Potts Model</a><ul>
<li class="chapter" data-level="2.4.1" data-path="maxent.html"><a href="maxent.html#potts-model-properties"><i class="fa fa-check"></i><b>2.4.1</b> Model Properties</a></li>
<li class="chapter" data-level="2.4.2" data-path="maxent.html"><a href="maxent.html#potts-mle"><i class="fa fa-check"></i><b>2.4.2</b> Inferring Parameters for the Potts Model</a></li>
<li class="chapter" data-level="2.4.3" data-path="maxent.html"><a href="maxent.html#potts-model-solutions"><i class="fa fa-check"></i><b>2.4.3</b> Solving the Inverse Potts Problem</a></li>
<li class="chapter" data-level="2.4.4" data-path="maxent.html"><a href="maxent.html#post-processing-heuristics"><i class="fa fa-check"></i><b>2.4.4</b> Computing Contact Maps</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>2.5</b> Applications</a><ul>
<li class="chapter" data-level="2.5.1" data-path="applications.html"><a href="applications.html#other-applications"><i class="fa fa-check"></i><b>2.5.1</b> other applications</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html"><i class="fa fa-check"></i><b>2.6</b> Evaluating Contact Prediction Methods</a><ul>
<li class="chapter" data-level="2.6.1" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html#seq-sep"><i class="fa fa-check"></i><b>2.6.1</b> Sequence Separation</a></li>
<li class="chapter" data-level="2.6.2" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html#interpretation-of-evaluation-results"><i class="fa fa-check"></i><b>2.6.2</b> Interpretation of Evaluation Results</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="challenges.html"><a href="challenges.html"><i class="fa fa-check"></i><b>2.7</b> Challenges for Coevolutionary Inference</a><ul>
<li class="chapter" data-level="2.7.1" data-path="challenges.html"><a href="challenges.html#phylogenetic-effects-as-a-source-of-noise"><i class="fa fa-check"></i><b>2.7.1</b> Phylogenetic Effects as a Source of Noise</a></li>
<li class="chapter" data-level="2.7.2" data-path="challenges.html"><a href="challenges.html#entropic-effects-as-a-source-of-noise"><i class="fa fa-check"></i><b>2.7.2</b> Entropic Effects as a Source of Noise</a></li>
<li class="chapter" data-level="2.7.3" data-path="challenges.html"><a href="challenges.html#finite-sampling-effects"><i class="fa fa-check"></i><b>2.7.3</b> Finite Sampling Effects</a></li>
<li class="chapter" data-level="2.7.4" data-path="challenges.html"><a href="challenges.html#multiple-sequence-alignments"><i class="fa fa-check"></i><b>2.7.4</b> Multiple Sequence Alignments</a></li>
<li class="chapter" data-level="2.7.5" data-path="challenges.html"><a href="challenges.html#alternative-sources-of-coevolution"><i class="fa fa-check"></i><b>2.7.5</b> Alternative Sources of Coevolution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="developing-a-bayesian-model-for-contact-prediction.html"><a href="developing-a-bayesian-model-for-contact-prediction.html"><i class="fa fa-check"></i><b>3</b> Developing a Bayesian Model for Contact Prediction</a></li>
<li class="chapter" data-level="4" data-path="interpreting-coupling-matrices.html"><a href="interpreting-coupling-matrices.html"><i class="fa fa-check"></i><b>4</b> Interpretation of Coupling Matrices</a><ul>
<li class="chapter" data-level="4.1" data-path="correlation-between-couplings-and-class.html"><a href="correlation-between-couplings-and-class.html"><i class="fa fa-check"></i><b>4.1</b> Single Coupling Values Carry Evidence of Contacts</a></li>
<li class="chapter" data-level="4.2" data-path="physico-chemical-fingerprints-in-coupling-matrices.html"><a href="physico-chemical-fingerprints-in-coupling-matrices.html"><i class="fa fa-check"></i><b>4.2</b> Physico-Chemical Fingerprints in Coupling Matrices</a></li>
<li class="chapter" data-level="4.3" data-path="coupling-profiles-vary-with-distance.html"><a href="coupling-profiles-vary-with-distance.html"><i class="fa fa-check"></i><b>4.3</b> Coupling Profiles Vary with Distance</a></li>
<li class="chapter" data-level="4.4" data-path="higher-order-dependencies-between-couplings.html"><a href="higher-order-dependencies-between-couplings.html"><i class="fa fa-check"></i><b>4.4</b> Higher Order Dependencies Between Couplings</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="optimizing-full-likelihood.html"><a href="optimizing-full-likelihood.html"><i class="fa fa-check"></i><b>5</b> Optimizing the Full Likelihood</a><ul>
<li class="chapter" data-level="5.1" data-path="full-likelihood-gradient.html"><a href="full-likelihood-gradient.html"><i class="fa fa-check"></i><b>5.1</b> Approximating the Gradient of the Full Likelihood with Contrastive Divergence</a></li>
<li class="chapter" data-level="5.2" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html"><i class="fa fa-check"></i><b>5.2</b> Optimizing the Full Likelihood</a><ul>
<li class="chapter" data-level="5.2.1" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html#cd-sampling-size"><i class="fa fa-check"></i><b>5.2.1</b> Varying the Sample Size</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="adam-results.html"><a href="adam-results.html"><i class="fa fa-check"></i><b>5.3</b> Using ADAM to optimize Contrastive Divergence</a></li>
<li class="chapter" data-level="5.4" data-path="comparing-cd-couplings-to-pll-couplings.html"><a href="comparing-cd-couplings-to-pll-couplings.html"><i class="fa fa-check"></i><b>5.4</b> Comparing CD couplings to pLL couplings</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-bayesian-statistical-model-for-residue-residue-contact-prediction.html"><a href="a-bayesian-statistical-model-for-residue-residue-contact-prediction.html"><i class="fa fa-check"></i><b>6</b> A Bayesian Statistical Model for Residue-Residue Contact Prediction</a><ul>
<li class="chapter" data-level="6.1" data-path="overview-posterior-distances.html"><a href="overview-posterior-distances.html"><i class="fa fa-check"></i><b>6.1</b> Computing the Posterior Distribution of Distances <span class="math inline">\(p(\r | \X)\)</span></a></li>
<li class="chapter" data-level="6.2" data-path="coupling-prior.html"><a href="coupling-prior.html"><i class="fa fa-check"></i><b>6.2</b> Modelling the prior over couplings with dependence on <span class="math inline">\(\rij\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="laplace-approx.html"><a href="laplace-approx.html"><i class="fa fa-check"></i><b>6.3</b> Gaussian approximation to the posterior of couplings</a><ul>
<li class="chapter" data-level="6.3.1" data-path="laplace-approx.html"><a href="laplace-approx.html#laplace-approx-improvement"><i class="fa fa-check"></i><b>6.3.1</b> Iterative improvement of Laplace approximation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="likelihood-fct-distances.html"><a href="likelihood-fct-distances.html"><i class="fa fa-check"></i><b>6.4</b> Computing the likelihood function of distances <span class="math inline">\(p(\X | \r)\)</span></a></li>
<li class="chapter" data-level="6.5" data-path="posterior-of-rij.html"><a href="posterior-of-rij.html"><i class="fa fa-check"></i><b>6.5</b> The posterior probability distribution for <span class="math inline">\(\rij\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="contact-prior.html"><a href="contact-prior.html"><i class="fa fa-check"></i><b>7</b> Contact Prior</a><ul>
<li class="chapter" data-level="7.1" data-path="random-forest-classifiers.html"><a href="random-forest-classifiers.html"><i class="fa fa-check"></i><b>7.1</b> Random Forest Classifiers</a></li>
<li class="chapter" data-level="7.2" data-path="evaluating-random-forest-model-as-contact-predictor.html"><a href="evaluating-random-forest-model-as-contact-predictor.html"><i class="fa fa-check"></i><b>7.2</b> Evaluating Random Forest Model as Contact Predictor</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>8</b> Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="dataset.html"><a href="dataset.html"><i class="fa fa-check"></i><b>8.1</b> Dataset</a></li>
<li class="chapter" data-level="8.2" data-path="computing-pseudo-likelihood-couplings.html"><a href="computing-pseudo-likelihood-couplings.html"><i class="fa fa-check"></i><b>8.2</b> Computing Pseudo-Likelihood Couplings</a><ul>
<li class="chapter" data-level="8.2.1" data-path="computing-pseudo-likelihood-couplings.html"><a href="computing-pseudo-likelihood-couplings.html#diff-ccmpred-ccmpredpy"><i class="fa fa-check"></i><b>8.2.1</b> Differences between CCMpred and CCMpredpy</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="seq-reweighting.html"><a href="seq-reweighting.html"><i class="fa fa-check"></i><b>8.3</b> Sequence Reweighting</a></li>
<li class="chapter" data-level="8.4" data-path="amino-acid-frequencies.html"><a href="amino-acid-frequencies.html"><i class="fa fa-check"></i><b>8.4</b> Computing Amino Acid Frequencies</a></li>
<li class="chapter" data-level="8.5" data-path="methods-regularization.html"><a href="methods-regularization.html"><i class="fa fa-check"></i><b>8.5</b> Regularization</a></li>
<li class="chapter" data-level="8.6" data-path="potts-full-likelihood.html"><a href="potts-full-likelihood.html"><i class="fa fa-check"></i><b>8.6</b> The Potts Model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="potts-full-likelihood.html"><a href="potts-full-likelihood.html#gap-treatment"><i class="fa fa-check"></i><b>8.6.1</b> Treating Gaps as Missing Information</a></li>
<li class="chapter" data-level="8.6.2" data-path="potts-full-likelihood.html"><a href="potts-full-likelihood.html#the-regularized-full-log-likelihood-and-its-gradient-with-gap-treatment"><i class="fa fa-check"></i><b>8.6.2</b> The Regularized Full Log Likelihood and its Gradient With Gap Treatment</a></li>
<li class="chapter" data-level="8.6.3" data-path="potts-full-likelihood.html"><a href="potts-full-likelihood.html#prior-v"><i class="fa fa-check"></i><b>8.6.3</b> The prior on <span class="math inline">\(\v\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="analysis-of-coupling-matrices.html"><a href="analysis-of-coupling-matrices.html"><i class="fa fa-check"></i><b>8.7</b> Analysis of Coupling Matrices</a><ul>
<li class="chapter" data-level="8.7.1" data-path="analysis-of-coupling-matrices.html"><a href="analysis-of-coupling-matrices.html#method-coupling-correlation"><i class="fa fa-check"></i><b>8.7.1</b> Correlation of Couplings with Contact Class</a></li>
<li class="chapter" data-level="8.7.2" data-path="analysis-of-coupling-matrices.html"><a href="analysis-of-coupling-matrices.html#method-coupling-profile"><i class="fa fa-check"></i><b>8.7.2</b> Coupling Distribution Plots</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="methods-sgd.html"><a href="methods-sgd.html"><i class="fa fa-check"></i><b>8.8</b> Optimizing Contrastive Divergence with Stochastic Gradient Descent</a><ul>
<li class="chapter" data-level="8.8.1" data-path="methods-sgd.html"><a href="methods-sgd.html#convergence-criterion-for-stochastic-gradient-descent"><i class="fa fa-check"></i><b>8.8.1</b> Convergence Criterion for Stochastic Gradient Descent</a></li>
<li class="chapter" data-level="8.8.2" data-path="methods-sgd.html"><a href="methods-sgd.html#sgd-hyperparameter-tuning"><i class="fa fa-check"></i><b>8.8.2</b> Tuning Hyperparameters of Stochastic Gradient Descent Optimizer</a></li>
<li class="chapter" data-level="8.8.3" data-path="methods-sgd.html"><a href="methods-sgd.html#methods-full-likelihood-adam"><i class="fa fa-check"></i><b>8.8.3</b> Tuning Hyperparameters of <em>ADAM</em> Optimizer</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="regularization-for-cd-with-sgd.html"><a href="regularization-for-cd-with-sgd.html"><i class="fa fa-check"></i><b>8.9</b> Tuning Regularization Coefficients for Contrastive Divergence</a></li>
<li class="chapter" data-level="8.10" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html"><i class="fa fa-check"></i><b>8.10</b> Tuning the Gibbs Sampling Scheme for Contrastive Divergence</a><ul>
<li class="chapter" data-level="8.10.1" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-gibbs-steps"><i class="fa fa-check"></i><b>8.10.1</b> Varying the number of Gibbs Steps</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html"><i class="fa fa-check"></i><b>8.11</b> Bayesian Model for Residue-Resdiue Contact Prediction</a><ul>
<li class="chapter" data-level="8.11.1" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html#neg-Hessian-computation"><i class="fa fa-check"></i><b>8.11.1</b> Efficiently Computing the negative Hessian of the regularized log-likelihood</a></li>
<li class="chapter" data-level="8.11.2" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html#inv-lambda-ij-k"><i class="fa fa-check"></i><b>8.11.2</b> Efficiently Computing the Inverse of Matrix <span class="math inline">\(\Lijk\)</span></a></li>
<li class="chapter" data-level="8.11.3" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html#training-hyperparameters"><i class="fa fa-check"></i><b>8.11.3</b> Training the Hyperparameters <span class="math inline">\(\muk\)</span>, <span class="math inline">\(\Lk\)</span> and <span class="math inline">\(\gamma_k\)</span></a></li>
<li class="chapter" data-level="8.11.4" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html#the-gradient-of-the-log-likelihood-with-respect-to-mathbfmu"><i class="fa fa-check"></i><b>8.11.4</b> The gradient of the log likelihood with respect to <span class="math inline">\(\mathbf{\mu}\)</span></a></li>
<li class="chapter" data-level="8.11.5" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html#the-gradient-of-the-log-likelihood-with-respect-to-lk"><i class="fa fa-check"></i><b>8.11.5</b> The gradient of the log likelihood with respect to <span class="math inline">\(\Lk\)</span></a></li>
<li class="chapter" data-level="8.11.6" data-path="bayesian-model-for-residue-resdiue-contact-prediction.html"><a href="bayesian-model-for-residue-resdiue-contact-prediction.html#the-gradient-of-the-log-likelihood-with-respect-to-gamma_k"><i class="fa fa-check"></i><b>8.11.6</b> The gradient of the log likelihood with respect to <span class="math inline">\(\gamma_k\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html"><a href="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html"><i class="fa fa-check"></i><b>8.12</b> Bayesian Statistical Model for Prediction of Protein Residue-Residue Distances</a><ul>
<li class="chapter" data-level="8.12.1" data-path="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html"><a href="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html#modelling-the-dependence-of-wij-on-distance"><i class="fa fa-check"></i><b>8.12.1</b> Modelling the dependence of <span class="math inline">\(\wij\)</span> on distance</a></li>
<li class="chapter" data-level="8.12.2" data-path="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html"><a href="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html#training-the-hyperparameters-rho_k-and-alpha_k-for-distance-dependent-prior"><i class="fa fa-check"></i><b>8.12.2</b> Training the Hyperparameters <span class="math inline">\(\rho_k\)</span> and <span class="math inline">\(\alpha_k\)</span> for distance-dependent prior</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="training-random-forest-contat-prior.html"><a href="training-random-forest-contat-prior.html"><i class="fa fa-check"></i><b>8.13</b> Training Random Forest Contat Prior</a><ul>
<li class="chapter" data-level="8.13.1" data-path="training-random-forest-contat-prior.html"><a href="training-random-forest-contat-prior.html#seq-features"><i class="fa fa-check"></i><b>8.13.1</b> Sequence Derived Features</a></li>
<li class="chapter" data-level="8.13.2" data-path="training-random-forest-contat-prior.html"><a href="training-random-forest-contat-prior.html#rf-hyperparameter-optimization"><i class="fa fa-check"></i><b>8.13.2</b> Hyperparameter Optimization for Random Forest Prior</a></li>
<li class="chapter" data-level="8.13.3" data-path="training-random-forest-contat-prior.html"><a href="training-random-forest-contat-prior.html#rf-feature-selection"><i class="fa fa-check"></i><b>8.13.3</b> Feature Selection</a></li>
<li class="chapter" data-level="8.13.4" data-path="training-random-forest-contat-prior.html"><a href="training-random-forest-contat-prior.html#rf-with-pll-score"><i class="fa fa-check"></i><b>8.13.4</b> Using Pseudo-likelihood Coevolution Score as Additional Feature</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="abbrev.html"><a href="abbrev.html"><i class="fa fa-check"></i><b>A</b> Abbreviations</a><ul>
<li class="chapter" data-level="A.1" data-path="amino-acids.html"><a href="amino-acids.html"><i class="fa fa-check"></i><b>A.1</b> Amino Acid Alphabet</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="dataset-properties.html"><a href="dataset-properties.html"><i class="fa fa-check"></i><b>B</b> Dataset Properties</a><ul>
<li class="chapter" data-level="B.1" data-path="alignment-diversity.html"><a href="alignment-diversity.html"><i class="fa fa-check"></i><b>B.1</b> Alignment Diversity</a></li>
<li class="chapter" data-level="B.2" data-path="proportion-of-gaps-in-alignment.html"><a href="proportion-of-gaps-in-alignment.html"><i class="fa fa-check"></i><b>B.2</b> Proportion of Gaps in Alignment</a></li>
<li class="chapter" data-level="B.3" data-path="alignment-size-number-of-sequences.html"><a href="alignment-size-number-of-sequences.html"><i class="fa fa-check"></i><b>B.3</b> Alignment Size (number of sequences)</a></li>
<li class="chapter" data-level="B.4" data-path="protein-length.html"><a href="protein-length.html"><i class="fa fa-check"></i><b>B.4</b> Protein Length</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="amino-acid-interaction-preferences-reflected-in-coupling-matrices.html"><a href="amino-acid-interaction-preferences-reflected-in-coupling-matrices.html"><i class="fa fa-check"></i><b>C</b> Amino Acid Interaction Preferences Reflected in Coupling Matrices</a><ul>
<li class="chapter" data-level="C.1" data-path="pi-cation.html"><a href="pi-cation.html"><i class="fa fa-check"></i><b>C.1</b> Pi-Cation interactions</a></li>
<li class="chapter" data-level="C.2" data-path="disulfide.html"><a href="disulfide.html"><i class="fa fa-check"></i><b>C.2</b> Disulfide Bonds</a></li>
<li class="chapter" data-level="C.3" data-path="aromatic-proline.html"><a href="aromatic-proline.html"><i class="fa fa-check"></i><b>C.3</b> Aromatic-Proline Interactions</a></li>
<li class="chapter" data-level="C.4" data-path="aromatic-network.html"><a href="aromatic-network.html"><i class="fa fa-check"></i><b>C.4</b> Network-like structure of aromatic residues</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="optimizing-full-likelihood-with-gradient-descent.html"><a href="optimizing-full-likelihood-with-gradient-descent.html"><i class="fa fa-check"></i><b>D</b> Optimizing Full Likelihood with Gradient Descent</a><ul>
<li class="chapter" data-level="D.1" data-path="visualisation-of-learning-rate-schedules.html"><a href="visualisation-of-learning-rate-schedules.html"><i class="fa fa-check"></i><b>D.1</b> Visualisation of learning rate schedules</a></li>
<li class="chapter" data-level="D.2" data-path="benchmark-learning-rate-annealing-schedules.html"><a href="benchmark-learning-rate-annealing-schedules.html"><i class="fa fa-check"></i><b>D.2</b> Benchmarking learning rate schedules</a><ul>
<li class="chapter" data-level="D.2.1" data-path="benchmark-learning-rate-annealing-schedules.html"><a href="benchmark-learning-rate-annealing-schedules.html#linear-learning-rate-schedule"><i class="fa fa-check"></i><b>D.2.1</b> Linear learning rate schedule</a></li>
<li class="chapter" data-level="D.2.2" data-path="benchmark-learning-rate-annealing-schedules.html"><a href="benchmark-learning-rate-annealing-schedules.html#sigmoidal-learning-rate-schedule"><i class="fa fa-check"></i><b>D.2.2</b> Sigmoidal learning rate schedule</a></li>
<li class="chapter" data-level="D.2.3" data-path="benchmark-learning-rate-annealing-schedules.html"><a href="benchmark-learning-rate-annealing-schedules.html#square-root-learning-rate-schedule"><i class="fa fa-check"></i><b>D.2.3</b> Square root learning rate schedule</a></li>
<li class="chapter" data-level="D.2.4" data-path="benchmark-learning-rate-annealing-schedules.html"><a href="benchmark-learning-rate-annealing-schedules.html#exponential-learning-rate-schedule"><i class="fa fa-check"></i><b>D.2.4</b> Exponential learning rate schedule</a></li>
</ul></li>
<li class="chapter" data-level="D.3" data-path="learning-rate-schedules-distribution-iterations.html"><a href="learning-rate-schedules-distribution-iterations.html"><i class="fa fa-check"></i><b>D.3</b> Number of iterations until convergence for different learning rate schedules</a><ul>
<li class="chapter" data-level="D.3.1" data-path="learning-rate-schedules-distribution-iterations.html"><a href="learning-rate-schedules-distribution-iterations.html#linear-learning-rate-schedule-1"><i class="fa fa-check"></i><b>D.3.1</b> Linear learning rate schedule</a></li>
<li class="chapter" data-level="D.3.2" data-path="learning-rate-schedules-distribution-iterations.html"><a href="learning-rate-schedules-distribution-iterations.html#sigmoidal-learning-rate-schedule-1"><i class="fa fa-check"></i><b>D.3.2</b> Sigmoidal learning rate schedule</a></li>
<li class="chapter" data-level="D.3.3" data-path="learning-rate-schedules-distribution-iterations.html"><a href="learning-rate-schedules-distribution-iterations.html#square-root-learning-rate-schedule-1"><i class="fa fa-check"></i><b>D.3.3</b> Square root learning rate schedule</a></li>
<li class="chapter" data-level="D.3.4" data-path="learning-rate-schedules-distribution-iterations.html"><a href="learning-rate-schedules-distribution-iterations.html#exponential-learning-rate-schedule-1"><i class="fa fa-check"></i><b>D.3.4</b> Exponential learning rate schedule</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="fix-single-potentials-at-maximum-likelihood-estimate-v.html"><a href="fix-single-potentials-at-maximum-likelihood-estimate-v.html"><i class="fa fa-check"></i><b>D.4</b> Fix single potentials at maximum-likelihood estimate v*</a></li>
<li class="chapter" data-level="D.5" data-path="monitoring-optimization-for-different-sample-sizes.html"><a href="monitoring-optimization-for-different-sample-sizes.html"><i class="fa fa-check"></i><b>D.5</b> Monitoring Optimization for different Sample Sizes</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="training-of-the-random-forest-contact-prior.html"><a href="training-of-the-random-forest-contact-prior.html"><i class="fa fa-check"></i><b>E</b> Training of the Random Forest Contact Prior</a><ul>
<li class="chapter" data-level="E.1" data-path="rf-window-size.html"><a href="rf-window-size.html"><i class="fa fa-check"></i><b>E.1</b> Evaluating window size with 5-fold Cross-validation</a></li>
<li class="chapter" data-level="E.2" data-path="rf-noncontact-threshold.html"><a href="rf-noncontact-threshold.html"><i class="fa fa-check"></i><b>E.2</b> Evaluating non-contact threshold with 5-fold Cross-validation</a></li>
<li class="chapter" data-level="E.3" data-path="rf-ratio-noncontacts.html"><a href="rf-ratio-noncontacts.html"><i class="fa fa-check"></i><b>E.3</b> Evaluating ratio of non-contacts and contacts in the training set with 5-fold Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PhD thesis: residue-residue contact prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="training-random-forest-contat-prior" class="section level2">
<h2><span class="header-section-number">8.13</span> Training Random Forest Contat Prior</h2>
<div id="seq-features" class="section level3">
<h3><span class="header-section-number">8.13.1</span> Sequence Derived Features</h3>
<p>Given a multiple sequence alignment of a protein family, various sequence features can be derived that have been found to be informative of a residue-residue contact.</p>
<p>In total there are <strong>250</strong> features that can be divided into global, single position and pairwise features and are described in the following sections. If not stated otherwise, <em>weighted</em> features have been computed using amino acid counts or amino acid frequencies based on weighted sequences as described in section <a href="seq-reweighting.html#seq-reweighting">8.3</a>.</p>
<div id="seq-features-global" class="section level4">
<h4><span class="header-section-number">8.13.1.1</span> Global Features</h4>
<p>These features describe alignment characteristics. Every pair of residues <span class="math inline">\((i,j)\)</span> from the same protein will be attributed the same feature.</p>
<table>
<caption>Features characterizing the total alignment</caption>
<colgroup>
<col width="25%" />
<col width="55%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Feature</th>
<th align="left">Description</th>
<th align="center">No. Features per residue pair <span class="math inline">\((i, j)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">L</td>
<td align="left">log of protein length</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">N</td>
<td align="left">number of sequences</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="right">Neff</td>
<td align="left">number of effective sequences Neff computed as the sum over sequence weights (see section <a href="seq-reweighting.html#seq-reweighting">8.3</a>)</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">gaps</td>
<td align="left">average percentage of gaps over all positions</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="right">diversity</td>
<td align="left"><span class="math inline">\(\frac{\sqrt{N}}{L}\)</span>, N=number of sequences, L=protein length</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">amino acid composition</td>
<td align="left">weighted amino acid frequencies in alignment</td>
<td align="center">20</td>
</tr>
<tr class="odd">
<td align="right">secondary structure prediction</td>
<td align="left">average three state propensities PSIPRED (v4.0)<span class="citation">[<a href="#ref-Jones1999">180</a>]</span></td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="right">secondary structure prediction</td>
<td align="left">average three state propensities Netsurfp (v1.0)<span class="citation">[<a href="#ref-Petersen2009a">179</a>]</span></td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="right">contact prior protein length</td>
<td align="left">simple contact predictor based on expected number of contacts per protein with respect to protein length (see next subsection <a href="training-random-forest-contat-prior.html#contact-prior-protein-length">8.13.1.4</a>)</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>There are in total <strong>32</strong> global alignment features.</p>
</div>
<div id="seq-features-single" class="section level4">
<h4><span class="header-section-number">8.13.1.2</span> Single Position Features</h4>
<p>These features describe characteristics of a single alignment column. Every residue pair <span class="math inline">\((i,j)\)</span> will be described by two features, once for each position.</p>
<table>
<caption>Single Position Sequence Features</caption>
<colgroup>
<col width="25%" />
<col width="55%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Feature</th>
<th align="left">Description</th>
<th align="center">No. Features per residue pair <span class="math inline">\((i, j)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">shannon entropy (20 states)</td>
<td align="left"><span class="math inline">\(- \sum_{a=1}^{20} p_a \log p_a\)</span></td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">shannon entropy (21 states)</td>
<td align="left"><span class="math inline">\(- \sum_{a=1}^{21} p_a \log p_a\)</span></td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="right">kullback leibler divergence</td>
<td align="left">between weighted observed and background amino acid frequencies <span class="citation">[<a href="#ref-Robinson1991">188</a>]</span></td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">jennson shannon divergence</td>
<td align="left">between weighted observed and background amino acid frequencies <span class="citation">[<a href="#ref-Robinson1991">188</a>]</span></td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="right">PSSM</td>
<td align="left">log odds ratio of weighted observed and background amino acid frequencies <span class="citation">[<a href="#ref-Robinson1991">188</a>]</span></td>
<td align="center">40</td>
</tr>
<tr class="even">
<td align="right">secondary structure prediction</td>
<td align="left">three state propensities PSIPRED (v4.0) <span class="citation">[<a href="#ref-Jones1999">180</a>]</span></td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="right">secondary structure prediction</td>
<td align="left">three state propensities Netsurfp (v1.0) <span class="citation">[<a href="#ref-Petersen2009a">179</a>]</span></td>
<td align="center">6</td>
</tr>
<tr class="even">
<td align="right">solvent accessibility prediction</td>
<td align="left">RSA and RSA Z-score Netsurfp (v1.0) <span class="citation">[<a href="#ref-Petersen2009a">179</a>]</span></td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="right">relative position in sequence</td>
<td align="left"><span class="math inline">\(\frac{i}{L}\)</span> for a protien of length <span class="math inline">\(L\)</span></td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">number of ungapped sequences</td>
<td align="left"><span class="math inline">\(\sum_n w_n I(x_{ni} \neq 20)\)</span> for sequences <span class="math inline">\(x_n\)</span> and sequence weights <span class="math inline">\(w_n\)</span></td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="right">percentage of gaps</td>
<td align="left"><span class="math inline">\(\frac{\sum_n w_n I(x_{ni} = 20)}{N_{\text{eff}}}\)</span> for sequences <span class="math inline">\(x_n\)</span> and sequence weights <span class="math inline">\(w_n\)</span></td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">Average physico-chemical properties</td>
<td align="left">Atchley Factors 1-5 <span class="citation">[<a href="#ref-Atchley2005">189</a>]</span></td>
<td align="center">10</td>
</tr>
<tr class="odd">
<td align="right">Average physico-chemical properties</td>
<td align="left">Polarity according to Grantham, 1974. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:GRAR740102">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">Average physico-chemical properties</td>
<td align="left">Polarity according to Zimmermann et al., 1986. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:ZIMJ680103">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="right">Average physico-chemical properties</td>
<td align="left">Isoelectric point according to Zimmermann et al., 1968. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:ZIMJ680104">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">Average physico-chemical properties</td>
<td align="left">Hydrophobicity scale according to Wimley &amp; White, 1996. Data taken from <a href="https://www.cgl.ucsf.edu/chimera/docs/ContributedSoftware/defineattrib/wwHydrophobicity.txt">UCSF Chimera</a> <span class="citation">[<a href="#ref-Wimley1996">191</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="right">Average physico-chemical properties</td>
<td align="left">Hydrophobicity index according to Kyte &amp; Doolittle, 1982. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:KYTJ820101">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">Average physico-chemical properties</td>
<td align="left">Hydrophobicity according to Cornette <span class="citation">[<a href="#ref-Cornette1987">192</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="right">Average physico-chemical properties</td>
<td align="left">Bulkiness according to Zimmerman et al., 1968. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:ZIMJ680102">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="right">Average physico-chemical properties</td>
<td align="left">Average volumes of residues according to Pontius et al., 1996. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:PONJ960101">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>There are in total <strong>96</strong> single sequence features.</p>
<p>Additionally, all single features will be computed within a window of size 5. The window feature for center residue <span class="math inline">\(i\)</span> will be computed as the mean feature over residues <span class="math inline">\([i-2, \ldots, i, \ldots, i+2]\)</span>. Whenever the window extends the range of the sequence (for <span class="math inline">\(i\!&lt;\!2\)</span> and <span class="math inline">\(i\!&gt;\!(L-2)\)</span>), the window feature will be computed only for valid sequence positions. This results in additional <strong>96</strong> window features.</p>
</div>
<div id="seq-features-pairwise" class="section level4">
<h4><span class="header-section-number">8.13.1.3</span> Pairwise Features</h4>
<p>These features are computed for every pair of columns <span class="math inline">\((i, j)\)</span> in the alignment with <span class="math inline">\(i&lt;j\)</span>.</p>
<table>
<caption>Pairwise Sequence Features</caption>
<colgroup>
<col width="25%" />
<col width="55%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Feature</th>
<th align="left">Description</th>
<th align="center">No. Features per residue pair <span class="math inline">\((i, j)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">sequence separation</td>
<td align="left"><span class="math inline">\(j-i\)</span></td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">gaps</td>
<td align="left">pairwise percentage of gaps using weighted sequences</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="right">number of ungapped sequences</td>
<td align="left"><span class="math inline">\(\sum_n w_n I(x_{ni} \! \neq \! 20, x_{nj} \! \neq \! 20)\)</span> for sequences <span class="math inline">\(x_n\)</span> and sequence weights <span class="math inline">\(w_n\)</span></td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">correlation physico-chemical features</td>
<td align="left">pairwise correlation of all physico-chemical properties listed in <a href="training-random-forest-contat-prior.html#seq-features-single">8.13.1.2</a></td>
<td align="center">13</td>
</tr>
<tr class="odd">
<td align="right">pairwise potential</td>
<td align="left">Average quasi-chemical energy of interactions in an average buried environment. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:MIYS990107">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">pairwise potential</td>
<td align="left">Average quasi-chemical energy of transfer of amino acids from water to the protein environment. Data taken from <a href="http://www.genome.jp/dbget-bin/www_bget?aaindex:MIYS990106">AAindex Database</a> <span class="citation">[<a href="#ref-Kawashima2008">190</a>]</span>.</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="right">pairwise potential</td>
<td align="left">Average general contact potential by Li&amp;Fang <span class="citation">[<a href="#ref-Li2011">54</a>]</span></td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">pairwise potential</td>
<td align="left">Average statistical potential from residue pairs in beta-sheets by Zhu&amp;Braun <span class="citation">[<a href="#ref-Zhu1999">193</a>]</span></td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="right">joint_shannon_entropy (20 state)</td>
<td align="left"><span class="math inline">\(- \sum_{a=1}^{20}\sum_{b=1}^{20} p(a,b) \log p(a,b)\)</span></td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="right">joint_shannon_entropy (21 state)</td>
<td align="left"><span class="math inline">\(- \sum_{a=1}^{21}\sum_{b=1}^{21} p(a,b) \log p(a,b)\)</span></td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="right">mutual information (MI)</td>
<td align="left">mutual information of amino acid counts at two positions; several variants: MI with pseudo-counts, MI with pseudo-counts + <a href="abbrev.html#abbrev">APC</a>, normalized MI</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="right">OMES</td>
<td align="left">according to Fodor&amp;Aldrich <span class="citation">[<a href="#ref-Fodor2004a">177</a>]</span> with and without <a href="abbrev.html#abbrev">APC</a></td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>There are in total <strong>26</strong> pairwise sequence features.</p>
</div>
<div id="contact-prior-protein-length" class="section level4">
<h4><span class="header-section-number">8.13.1.4</span> Protein length dependent Contact Prior</h4>
<p>The average number of contats per residue, computed as the observed number of contacts divided by protein length L, has a non-linear relationship with protein length L as can be seen in Figure <a href="training-random-forest-contat-prior.html#fig:avg-nr-contacts-per-residue-vs-protein-length">8.16</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:avg-nr-contacts-per-residue-vs-protein-length"></span>
<iframe src="img/random_forest_contact_prior/no_contacts_per_residue_vs_protein_length_thr8.html" width="80%" height="500px">
</iframe>
<p class="caption">
Figure 8.16: Observed number of contacts per residue has a non-linear relationship with protein length. Distribution is shown for several thresholds of sequence separation.
</p>
</div>
<p>In log space, the average number of contats per residue can be fitted with a linear regression (see Figure <a href="training-random-forest-contat-prior.html#fig:avg-nr-contacts-per-residue-vs-log-protein-length-linfit">8.17</a>) and yields the following functions:</p>
<ul>
<li><span class="math inline">\(f(L) = 1.556 + 0.596 \log (L)\)</span> for sequence separation of 0 positions</li>
<li><span class="math inline">\(f(L) = -1.273 + 0.59 \log (L)\)</span> for sequence separation of 8 positions</li>
<li><span class="math inline">\(f(L) = -1.567 + 0.615 \log (L)\)</span> for sequence separation of 12 positions</li>
<li><span class="math inline">\(f(L) = -2.0 + 0.624 \log (L)\)</span> for sequence separation of 24 positions</li>
</ul>
<p>A simple contact predictor can be formulated as the ratio of the expected number of contacts per residue, given by <span class="math inline">\(f(L)\)</span>, and the possible number of contacts per residue which is <span class="math inline">\(L-1\)</span>,</p>
<p><span class="math display">\[
p(r_{ij} = 1 | L) = \frac{f(L)}{L-1} \; ,
\]</span></p>
<p>with <span class="math inline">\(r_{ij}=1\)</span> representing a contact between residue <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>.</p>

<div class="figure" style="text-align: center"><span id="fig:avg-nr-contacts-per-residue-vs-log-protein-length-linfit"></span>
<iframe src="img/random_forest_contact_prior/model_linreg_transformlogL_no_contacts_per_residue_vs_protein_length_thr8.html" width="90%" height="650px">
</iframe>
<p class="caption">
Figure 8.17: Linear regression fits for average number of contats per residue on logarithm of protein length. Distribution and linear regression fits are shown for different sequence separation thresholds.
</p>
</div>
</div>
</div>
<div id="rf-hyperparameter-optimization" class="section level3">
<h3><span class="header-section-number">8.13.2</span> Hyperparameter Optimization for Random Forest Prior</h3>
<p>There are several hyperparameters in a random forest model that need to be tuned to achieve best balance between predictive power and runtime. While more trees in the random forest generally improve performance of the model, they will slow down training and prediction. A crucial hyperparamter is the number of features that is randomly selected for a split at each node in a tree <span class="citation">[<a href="#ref-Bernard2009">194</a>]</span>. Stochasticity introduced by the random selection of features is a key characteristic of random forests as it reduces correlation between the trees and thus the variance of the predictor. Selecting many features typically increases performance as more options can be considered for each split, but at the same time increases risk of overfitting and decreases speed of the algorithm. In general, random forests are robust to overfitting, as long as there are enough trees in the ensemble and the selection of features for splitting a node introduces sufficient stochasticity. Overfitting can furthermore be prevented by restricting the depth of the trees, which is known as pruning or by enforcing a minimal node size with respect to the number of features per node. A positive side-effect of taking these measures is a speedup of the algorithm. <span class="citation">[<a href="#ref-Louppe2014">175</a>]</span></p>
<p>In the following, I use 5-fold cross-validation to identify the optimal architecture of the random forest. I used the module <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier">RandomForestClassifier</a> in the Python package <code>sklearn (v. 0.19)</code> <span class="citation">[<a href="#ref-Pedregosa2011">195</a>]</span> and trained the models on sequence features extracted from <a href="abbrev.html#abbrev">MSAs</a> as described in section <a href="training-random-forest-contat-prior.html#seq-features">8.13.1</a>. Single position features are computed with a window of size five as described in section <a href="training-random-forest-contat-prior.html#seq-features-single">8.13.1.2</a>.</p>
<p>Proteins constitute highly imbalanced datasets with respect to the number of residue pairs that form and form not physical contacts. As can be seen in Figure <a href="training-random-forest-contat-prior.html#fig:fraction-contacts-vs-protein-length">8.18</a>, depending on the enforced sequence separation threshold the percentage of contacts varies between approximately 1% and 5%.</p>

<div class="figure" style="text-align: center"><span id="fig:fraction-contacts-vs-protein-length"></span>
<iframe src="img/random_forest_contact_prior/fraction_contacts_vs_protein_length_thr8.html" width="80%" height="500px">
</iframe>
<p class="caption">
Figure 8.18: Fraction of contacts among all possible contacts (<span class="math inline">\(\frac{L(L-1)}{2}\)</span>) in a protein against protein length L. The distribution has a non-linear relationship. At a sequence separation threshold &gt;8 positions the fraction of contacts for intermediate size proteins with length &gt;100 is approximately 2%.
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:rf-gridsearch-nestimators-maxfeatures"></span>
<iframe src="img/random_forest_contact_prior/new_gridsearch/precision_vs_rank_cv_on_test_random_forest_nestimators_maxdepth_top5_notitle.html" width="100%" height="600px">
</iframe>
<p class="caption">
Figure 8.19: Mean precision over 200 proteins against highest scoring contact predictions from random forest models for different settings of <em>n_estimators</em> and <em>max_depth</em>. Dashed lines show the performance of models that have been learned on the five different subsets of training data. Solid lines give the mean precision over the five models. Only those models are shown that yielded the five highest mean precision values (given in parantheses in the legend). Random forest models with 1000 trees and maximum depth of trees of either 100, 1000 or unrestricted tree depth perform nearly identical (lines overlap). Random forest models with 500 trees and <em>max_depth</em>=10 or <em>max_depth</em>=100 perform slightly worse.
</p>
</div>
<p>Most studies applying machine learning algorithms to the problem of predicting residue-residue contacts, chose the standard approach of rebalancing the data set by undersampling of the majority class.</p>
<table>
<thead>
<tr class="header">
<th align="right">Study</th>
<th align="center">Proportion of Contacts</th>
<th align="center">Proportion of Non-contacts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Wu et al. (2008) <span class="citation">[<a href="#ref-Wu2008">53</a>]</span></td>
<td align="center">1</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="right">Li et al. (2011) <span class="citation">[<a href="#ref-Li2011">54</a>]</span></td>
<td align="center">1</td>
<td align="center">1, 2</td>
</tr>
<tr class="odd">
<td align="right">Wang et al. (2011) <span class="citation">[<a href="#ref-Wang2011">55</a>]</span></td>
<td align="center">1</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="right">DiLena et al. (2012) <span class="citation">[<a href="#ref-DiLena2012a">63</a>]</span></td>
<td align="center">1</td>
<td align="center">~4</td>
</tr>
<tr class="odd">
<td align="right">Wang et al. (2013) <span class="citation">[<a href="#ref-Wang2013">56</a>]</span></td>
<td align="center">1</td>
<td align="center">~4</td>
</tr>
</tbody>
</table>
<p>I followed the same strategy and undersampled residue pairs that are not physical contacts with a proportion of contacts to non-contacts of 1:5. The training set is comprised of 50.000 residue pairs <span class="math inline">\(&lt; 8 \angstrom\)</span> (“contacts”“) and 250.000 residue pairs <span class="math inline">\(&gt; 8 \angstrom\)</span> (”non-contacts“) so that each of the five cross-validation models will be trained on 40.000 contacts and 200.000 non-contacts. As the training set has been undersampled for non-contacts, it is not representative of real world proteins and the models should be validated on a more realistic validation set. Each of the five models is therefore cross-validated on an own independent dataset of residue pairs extracted from 40 proteins by means of the standard contact prediction benchmark (mean precision against top ranked contacts).</p>

<p>First I assessed performance of models for combinations of the parameter <em>n_estimators</em>, defining the number of trees in the forest and the parameter <em>max_depth</em> defining the maximum depth of the trees:</p>
<ul>
<li><em>n_estimators</em> <span class="math inline">\(\in \{100,500,1000\}\)</span></li>
<li><em>max_depth</em> <span class="math inline">\(\in \{10, 100, 1000, None\}\)</span></li>
</ul>
<p>Figure <a href="training-random-forest-contat-prior.html#fig:rf-gridsearch-nestimators-maxfeatures">8.19</a> shows that the top five parameter combinations perform nearly identical. Random forests with 1000 trees perform slightly better than models constituting 500 trees, irrespective of the depth of the trees. In order to keep model complexity small, <code>n_estimators=1000</code> and <code>max_depth=100</code> for further analysis.</p>
<p>Next, I optimized the parameters <em>min_samples_leaf</em>, defining the minimum number of samples required to be at a leaf node and <em>max_features</em>, defining the number of randomly selected features considered for each split using the following settings:</p>
<ul>
<li><em>min_samples_leaf</em> <span class="math inline">\(\in \{1, 10, 100\}\)</span></li>
<li><em>max_features</em> <span class="math inline">\(\in \{\text{sqrt}, \text{log2}, 0.15, 0.3\}\)</span></li>
</ul>
<p>Randomly selecting 39% of features (=75 features) and requiring at least 10 samples per leaf gives highest mean precision as can be seen in Figure <a href="training-random-forest-contat-prior.html#fig:rf-gridsearch-maxdepth-minsampleleaf">8.20</a>. I chose <code>max_features = 0.30</code> and <code>min_samples_leaf = 10</code> for further analysis. Tuning the hyperparameters in a different order or on a larger dataset gives similar results.</p>

<div class="figure" style="text-align: center"><span id="fig:rf-gridsearch-maxdepth-minsampleleaf"></span>
<iframe src="img/random_forest_contact_prior/new_gridsearch/precision_vs_rank_cv_on_test_random_forest_maxfeatures_minsampleleaf_top5_notitle.html" width="100%" height="600px">
</iframe>
<p class="caption">
Figure 8.20: Mean precision over 200 proteins against highest scoring contact predictions from random forest models with different settings of <em>min_samples_leaf</em> and <em>max_features</em>. Dashed lines show the performance of models that have been learned on the five different subsets of training data. Solid lines give the mean precision over the five models. Only those models are shown that yielded the five best mean precision values (given in parantheses in the legend).
</p>
</div>
<p>In a next step I assessed dataset specific settings, such as the window size over which single positions features will be computed, the distance threshold to define non-contacts and the optimal proportions of contacts and non-contacts in the training set. I used the previously identified settings of random forest hyperparameters (<code>n_estimators=1000, min_samples_leaf=10, max_depth=100, max_features=0.30</code>).</p>
<ul>
<li>ratio of non-contacts/contacts <span class="math inline">\(\in \{2, 5, 10, 20 \}\)</span> within a fixed total dataset size of 300 000 residue pairs</li>
<li>window size: <span class="math inline">\(\in \{5, 7, 9, 11\}\)</span></li>
<li>non-contact threshold <span class="math inline">\(\in \{8, 15, 20\}\)</span></li>
</ul>
<p>As can be seen in appendix <a href="rf-window-size.html#rf-window-size">E.1</a> and <a href="rf-noncontact-threshold.html#rf-noncontact-threshold">E.2</a>, the default choice of using a window size of five positions and the non-contact threshold of <span class="math inline">\(8 \angstrom\)</span> proves to be the optimal setting. Furthermore, using five-times as many non-contacts as contacts in the training set results in highest mean precision as can be seen in appendix <a href="rf-ratio-noncontacts.html#rf-ratio-noncontacts">E.3</a>. These estimates might be biased in a way since the random forest hyperparameters have been optimized on a dataset using exactly these optimal settings.</p>
</div>
<div id="rf-feature-selection" class="section level3">
<h3><span class="header-section-number">8.13.3</span> Feature Selection</h3>
<p>Many features obtain low <em>Gini importance</em> scores and can most likely be removed from the data set which will also reduce model complexity. It has been found, that prediction performance might even increase after removing the most irrelevant features <span class="citation">[<a href="#ref-Menze2009">174</a>]</span>. For example, during the development of <em>EPSILON-CP</em>, a deep neural network method for contact prediction, the authors performed feature selection using boosted trees. By removing 75% of the most non-informative features (mostly features related to amino acid composition), the performance of their predictor increased slightly <span class="citation">[<a href="#ref-Stahl2017">71</a>]</span>. Other studies have also emphasized the importance of feature selection to improve performance and reduce model complexity <span class="citation">[<a href="#ref-Cheng2007">52</a>,<a href="#ref-Li2011">54</a>]</span>.</p>
<p>I therefore developed a feature selection pipeline that retrains the random forest model on subsets of features. The subsets are composed of those features having <em>Gini importance</em> larger than the <span class="math inline">\(\{10, 30, 50, 70, 90\}\)</span>-percentile of the distribution of <em>Gini importance</em> values obtained by training a model on all features. Performance of the models trained on these subsets of features is evaluated on a validation set.</p>
</div>
<div id="rf-with-pll-score" class="section level3">
<h3><span class="header-section-number">8.13.4</span> Using Pseudo-likelihood Coevolution Score as Additional Feature</h3>
<p>Besides the 250 sequence derived features, the pseudo-likelihood contact score (<a href="abbrev.html#abbrev">APC</a> corrected Frobenius norm of couplings) is used as an additional feature. The random forest was trained on 100.000 residue pairs in physical contact (<span class="math inline">\(\Delta \Cb &lt; 8 \angstrom \; \;\)</span>) and 500.000 residue pairs not in physical contact (<span class="math inline">\(\Delta \Cb &gt; 8 \angstrom \; \;\)</span>) using the cross-validated hyperparameters as described earlier.</p>
<p>The pseudo-likelihood contact score comprises by far the most important feature as can be seen in the Figure <a href="training-random-forest-contat-prior.html#fig:feature-importance-rf-with-pll-score">8.21</a>. Other important features include the local statistical contact scores OMES and mutual information, the mean pairwise potentials according to Miyasawa &amp; Jernigan <span class="citation">[<a href="#ref-Miyazawa1999a">178</a>]</span> and Li &amp; Fang <span class="citation">[<a href="#ref-Li2011">54</a>]</span>, relative solvent accessibilty predictions (with NetsurfP <span class="citation">[<a href="#ref-Petersen2009a">179</a>]</span>). The most important features apart from the pseudo-likelihood contact score, are the same features that are highly relevant for the basic random forest model (see Figure <a href="evaluating-random-forest-model-as-contact-predictor.html#fig:rf-feature-importance">7.2</a>).</p>

<div class="figure" style="text-align: center"><span id="fig:feature-importance-rf-with-pll-score"></span>
<iframe src="img/random_forest_contact_prior/pll_feature/feature_random_forest_top_pLLfeature.html" width="100%" height="600px">
</iframe>
<p class="caption">
Figure 8.21: Top ten features ranked according to <em>Gini importance</em>. <strong>pseudo-likelihood</strong>: <a href="abbrev.html#abbrev">APC</a> corrected Frobenius norm of couplings computed with pseudo-likelihood. <strong>mean pair potential (Miyasawa &amp; Jernigan)</strong>: average quasi-chemical energy of transfer of amino acids from water to the protein environment <span class="citation">[<a href="#ref-Miyazawa1999a">178</a>]</span>. <strong>OMES+APC</strong>: <a href="abbrev.html#abbrev">APC</a> corrected OMES score according to Fodor&amp;Aldrich <span class="citation">[<a href="#ref-Fodor2004a">177</a>]</span>. <strong>mean pair potential (Li&amp;Fang)</strong>: average general contact potential by Li &amp; Fang <span class="citation">[<a href="#ref-Li2011">54</a>]</span>. <strong>rel. solvent accessibilty i(j)</strong>: RSA score computed with Netsurfp (v1.0) <span class="citation">[<a href="#ref-Petersen2009a">179</a>]</span> for position i(j). <strong>MI+APC</strong>: <a href="abbrev.html#abbrev">APC</a> corrected mutual information between amino acid counts (using pseudo-counts). <strong>contact prior wrt L</strong>: simple contact prior based on expected number of contacts wrt protein length (see methods section <a href="training-random-forest-contat-prior.html#contact-prior-protein-length">8.13.1.4</a>). <strong>log protein length</strong>: logarithm of protein length. <strong>beta sheet propensity window(i)</strong>: beta-sheet propensity according to Psipred <span class="citation">[<a href="#ref-Jones1999">180</a>]</span> computed within a window of five positions around i. Features are described in detail in methods section <a href="training-random-forest-contat-prior.html#seq-features">8.13.1</a>.
</p>
</div>
<p>Models that have been trained on subsets of features, comprising 226, 176, 126 or 76 of the most important features with respect to <em>Gini importance</em>, perform equally well as the model trained on the complete set of features (see Figure <a href="training-random-forest-contat-prior.html#fig:feature-selection-rf-with-pll-score">8.22</a>). Only the model trained on the 26 most important features has slighlty decreased precision for the top L/10 ranked contacts.</p>

<div class="figure" style="text-align: center"><span id="fig:feature-selection-rf-with-pll-score"></span>
<iframe src="img/random_forest_contact_prior/pll_feature/precision_vs_rank_featureselection_random_forest_nestimators1000_maxfeatures03_maxdepth100_minsamplesleaf10_pLLfeature.html" width="100%" height="500px">
</iframe>
<p class="caption">
Figure 8.22: Mean precision for top ranked contacts over 200 proteins for variaous random forest models trained on subsets of features. Subsets of features have been selected as described in section <a href="training-random-forest-contat-prior.html#rf-feature-selection">8.13.3</a>.
</p>
</div>

</div>
</div>
</div>


<!--  -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Jones1999">
<p>180. Jones, D.T. (1999). Protein secondary structure prediction based on position-specific scoring matrices 1 1Edited by G. Von Heijne. J. Mol. Biol. <em>292</em>, 195–202. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/10493868 http://linkinghub.elsevier.com/retrieve/pii/S0022283699930917" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/10493868 http://linkinghub.elsevier.com/retrieve/pii/S0022283699930917</a>.</p>
</div>
<div id="ref-Petersen2009a">
<p>179. Petersen, B., Petersen, T.N., Andersen, P., Nielsen, M., and Lundegaard, C. (2009). BMC Structural Biology A generic method for assignment of reliability scores applied to solvent accessibility predictions. BMC Struct. Biol. <em>9</em>. Available at: <a href="http://www.biomedcentral.com/1472-6807/9/51" class="uri">http://www.biomedcentral.com/1472-6807/9/51</a>.</p>
</div>
<div id="ref-Robinson1991">
<p>188. Robinson, A.B., and Robinson, L.R. (1991). Distribution of glutamine and asparagine residues and their near neighbors in peptides and proteins. Proc. Natl. Acad. Sci. U. S. A. <em>88</em>, 8880–4. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/1924347 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC52614" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/1924347 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC52614</a>.</p>
</div>
<div id="ref-Atchley2005">
<p>189. Atchley, W.R., Zhao, J., Fernandes, A.D., and Drüke, T. (2005). Solving the protein sequence metric problem. Proc. Natl. Acad. Sci. U. S. A. <em>102</em>, 6395–400. Available at: <a href="http://www.pnas.org/content/102/18/6395.abstract" class="uri">http://www.pnas.org/content/102/18/6395.abstract</a>.</p>
</div>
<div id="ref-Kawashima2008">
<p>190. Kawashima, S., Pokarowski, P., Pokarowska, M., Kolinski, A., Katayama, T., and Kanehisa, M. (2008). AAindex: amino acid index database, progress report 2008. Nucleic Acids Res. <em>36</em>, D202–5. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/17998252 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2238890" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/17998252 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2238890</a>.</p>
</div>
<div id="ref-Wimley1996">
<p>191. Wimley, W.C., and White, S.H. (1996). Experimentally determined hydrophobicity scale for proteins at membrane interfaces. Nat. Struct. Biol. <em>3</em>, 842–8. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/8836100" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/8836100</a>.</p>
</div>
<div id="ref-Cornette1987">
<p>192. Cornette, J.L., Cease, K.B., Margalit, H., Spouge, J.L., Berzofsky, J.A., and DeLisi, C. (1987). Hydrophobicity scales and computational techniques for detecting amphipathic structures in proteins. J. Mol. Biol. <em>195</em>, 659–685. Available at: <a href="http://linkinghub.elsevier.com/retrieve/pii/0022283687901896" class="uri">http://linkinghub.elsevier.com/retrieve/pii/0022283687901896</a>.</p>
</div>
<div id="ref-Li2011">
<p>54. Li, Y., Fang, Y., and Fang, J. (2011). Predicting residue-residue contacts using random forest models. Bioinformatics <em>27</em>, 3379–84. Available at: <a href="http://bioinformatics.oxfordjournals.org/content/27/24/3379.long" class="uri">http://bioinformatics.oxfordjournals.org/content/27/24/3379.long</a>.</p>
</div>
<div id="ref-Zhu1999">
<p>193. Zhu, H., and Braun, W. (1999). Sequence specificity, statistical potentials, and three-dimensional structure prediction with self-correcting distance geometry calculations of beta-sheet formation in proteins. Protein Sci. <em>8</em>, 326–42. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2144259{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2144259{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-Fodor2004a">
<p>177. Fodor, A.A., and Aldrich, R.W. (2004). Influence of conservation on calculations of amino acid covariance in multiple sequence alignments. Proteins <em>56</em>, 211–21. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/15211506" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/15211506</a>.</p>
</div>
<div id="ref-Bernard2009">
<p>194. Bernard, S., Heutte, L., and Adam, S. (2009). Influence of Hyperparameters on Random Forest Accuracy. In (Springer, Berlin, Heidelberg), pp. 171–180. Available at: <a href="http://link.springer.com/10.1007/978-3-642-02326-2{\_}18" class="uri">http://link.springer.com/10.1007/978-3-642-02326-2{\_}18</a>.</p>
</div>
<div id="ref-Louppe2014">
<p>175. Louppe, G. (2014). Understanding Random Forests: From Theory to Practice. Available at: <a href="http://arxiv.org/abs/1407.7502" class="uri">http://arxiv.org/abs/1407.7502</a>.</p>
</div>
<div id="ref-Pedregosa2011">
<p>195. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., and Dubourg, V. <em>et al.</em> (2011). Scikit-learn: Machine Learning in Python. J. Mach. Learn. Res. <em>12</em>, 2825–2830. Available at: <a href="http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html" class="uri">http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html</a>.</p>
</div>
<div id="ref-Wu2008">
<p>53. Wu, S., and Zhang, Y. (2008). A comprehensive assessment of sequence-based and template-based methods for protein contact prediction. Bioinformatics <em>24</em>, 924–31. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2648832{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2648832{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-Wang2011">
<p>55. Wang, X.-F., Chen, Z., Wang, C., Yan, R.-X., Zhang, Z., and Song, J. (2011). Predicting residue-residue contacts and helix-helix interactions in transmembrane proteins using an integrative feature-based random forest approach. PLoS One <em>6</em>, e26767. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3203928{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3203928{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-DiLena2012a">
<p>63. Di Lena, P., Nagata, K., and Baldi, P. (2012). Deep architectures for protein contact map prediction. Bioinformatics <em>28</em>, 2449–57. Available at: <a href="http://bioinformatics.oxfordjournals.org/content/28/19/2449.full{\#}sec-14" class="uri">http://bioinformatics.oxfordjournals.org/content/28/19/2449.full{\#}sec-14</a>.</p>
</div>
<div id="ref-Wang2013">
<p>56. Wang, Z., and Xu, J. (2013). Predicting protein contact map using evolutionary and physical constraints by integer programming. Bioinformatics <em>29</em>, i266–73. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3694661{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3694661{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-Menze2009">
<p>174. Menze, B.H., Kelm, B.M., Masuch, R., Himmelreich, U., Bachert, P., Petrich, W., and Hamprecht, F.A. (2009). A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data. BMC Bioinformatics <em>10</em>, 213. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/19591666 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2724423" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/19591666 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2724423</a>.</p>
</div>
<div id="ref-Stahl2017">
<p>71. Stahl, K., Schneider, M., and Brock, O. (2017). EPSILON-CP: using deep learning to combine information from multiple sources for protein contact prediction. BMC Bioinformatics <em>18</em>, 303. Available at: <a href="http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1713-x" class="uri">http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1713-x</a>.</p>
</div>
<div id="ref-Cheng2007">
<p>52. Cheng, J., and Baldi, P. (2007). Improved residue contact prediction using support vector machines and a large feature set. BMC Bioinformatics <em>8</em>, 113. Available at: <a href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1852326{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract" class="uri">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1852326{\&amp;}tool=pmcentrez{\&amp;}rendertype=abstract</a>.</p>
</div>
<div id="ref-Miyazawa1999a">
<p>178. Miyazawa, S., and Jernigan, R.L. (1999). Self-consistent estimation of inter-residue protein contact energies based on an equilibrium mixture approximation of residues. Proteins <em>34</em>, 49–68. Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/10336383" class="uri">http://www.ncbi.nlm.nih.gov/pubmed/10336383</a>.</p>
</div>
</div>
<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://contactpredictionthesis.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="abbrev.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/susannvorberg/phd_thesis/edit/master/04-methods.Rmd",
"text": "Edit"
},
"download": ["PhD_thesis_Susann_Vorberg.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
