<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>PhD thesis: residue-residue contact prediction</title>
  <meta name="description" content="This is my PhD thesis on residue-residue contact prediction.">
  <meta name="generator" content="bookdown 0.3.9 and GitBook 2.6.7">

  <meta property="og:title" content="PhD thesis: residue-residue contact prediction" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is my PhD thesis on residue-residue contact prediction." />
  <meta name="github-repo" content="susannvorberg/phd_thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="PhD thesis: residue-residue contact prediction" />
  
  <meta name="twitter:description" content="This is my PhD thesis on residue-residue contact prediction." />
  

<meta name="author" content="Susann Vorberg">


<meta name="date" content="2017-10-29">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="training-hyperparameters-for-a-gaussian-mixture-with-three-components.html">
<link rel="next" href="posterior-of-rij.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />








<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
  tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]},
  TeX: { 
    extensions: ["mediawiki-texvc.js", "sinuitx.js"],
    Macros: {
      Cb: "C_\\beta",
      eq: "\\!=\\!",
      Gauss: "\\mathcal{N}",
      H: "\\mathbf{H}",
      Hij : "\\H_{ij}",
      I: "\\mathbf{I}",
      Lijk: "\\mathbf{\\Lambda}_{ij,k}",
      Lk: "\\mathbf{\\Lambda}_k",
      LL: "L\\!L(\\mathbf{v}, \\mathbf{w})",
      LLreg: "L\\!L_\\mathrm{reg}",
      muijk: "\\mathbf{\\mu}_{ij,k}",
      muk: "\\mathbf{\\mu}_k",
      neff: "N_\\mathrm{eff}",
      r: "\\mathbf{r}",
      rij: "r_{ij}",
      c: "\\mathbf{c}",
      cij: "c_{ij}",
      seq: "\\mathbf{x}",
      Qij: "\\mathbf{Q}_{ij}",
      q: "\\mathbf{q}",
      qij: "\\mathbf{q'}_{ij}",
      Sn: "\\mathcal{S}_n",
      v: "\\mathbf{v}",
      vi: "\\mathcal{v}_{i}",
      vj: "\\mathcal{v}_{j}",
      via: "\\mathcal{v}_{ia}",
      vja: "\\mathcal{v}_{ja}",
      w: "\\mathbf{w}",
      wij: "\\mathbf{w}_{ij}",
      wijab: "\\mathcal{w}_{ijab}",
      wijcd: "\\mathcal{w}_{ijcd}",
      wklcd: "\\mathcal{w}_{klcd}",
      X: "\\mathbf{X}",
      angstrom: "\\AA \\; \\;"
      }
  }
});
</script>


 
<!--
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js", "[siunitx]/siunitx.js"],
  TeX: { TagSide: "left" }
});
MathJax.Ajax.config.path['siunitx']  = '../latex/MathJax-siunitx-master/';
</script>
//-->



<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">PhD Thesis Susann Vorberg</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>1</b> Background</a><ul>
<li class="chapter" data-level="1.1" data-path="general-intro.html"><a href="general-intro.html"><i class="fa fa-check"></i><b>1.1</b> Biological Background</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html"><i class="fa fa-check"></i><b>1.2</b> Introduction to Contact Prediction</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html#local-methods"><i class="fa fa-check"></i><b>1.2.1</b> Local Statistical Models</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html#global-methods"><i class="fa fa-check"></i><b>1.2.2</b> Global Statistical Models</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html#meta-predictors"><i class="fa fa-check"></i><b>1.2.3</b> Machine Learning Methods and Meta-Predictors</a></li>
<li class="chapter" data-level="1.2.4" data-path="introduction-to-contact-prediction.html"><a href="introduction-to-contact-prediction.html#maxent"><i class="fa fa-check"></i><b>1.2.4</b> Modelling Protein Families with Potts Model</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="application-contact-prediction.html"><a href="application-contact-prediction.html"><i class="fa fa-check"></i><b>1.3</b> Applications</a></li>
<li class="chapter" data-level="1.4" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html"><i class="fa fa-check"></i><b>1.4</b> Evaluating Contact Prediction Methods</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html#seq-sep"><i class="fa fa-check"></i><b>1.4.1</b> Sequence Separation</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro-cp-evaluation.html"><a href="intro-cp-evaluation.html#interpretation-of-evaluation-results"><i class="fa fa-check"></i><b>1.4.2</b> Interpretation of Evaluation Results</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="challenges.html"><a href="challenges.html"><i class="fa fa-check"></i><b>1.5</b> Challenges for Coevolutionary Inference</a><ul>
<li class="chapter" data-level="1.5.1" data-path="challenges.html"><a href="challenges.html#phylogenetic-noise"><i class="fa fa-check"></i><b>1.5.1</b> Phylogenetic Effects as a Source of Noise</a></li>
<li class="chapter" data-level="1.5.2" data-path="challenges.html"><a href="challenges.html#entropic-effects-as-a-source-of-noise"><i class="fa fa-check"></i><b>1.5.2</b> Entropic Effects as a Source of Noise</a></li>
<li class="chapter" data-level="1.5.3" data-path="challenges.html"><a href="challenges.html#finite-sampling-effects"><i class="fa fa-check"></i><b>1.5.3</b> Finite Sampling Effects</a></li>
<li class="chapter" data-level="1.5.4" data-path="challenges.html"><a href="challenges.html#multiple-sequence-alignments"><i class="fa fa-check"></i><b>1.5.4</b> Multiple Sequence Alignments</a></li>
<li class="chapter" data-level="1.5.5" data-path="challenges.html"><a href="challenges.html#alternative-sources-of-coevolution"><i class="fa fa-check"></i><b>1.5.5</b> Alternative Sources of Coevolution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpreting-coupling-matrices.html"><a href="interpreting-coupling-matrices.html"><i class="fa fa-check"></i><b>2</b> Interpretation of Coupling Matrices</a><ul>
<li class="chapter" data-level="2.1" data-path="correlation-between-couplings-and-class.html"><a href="correlation-between-couplings-and-class.html"><i class="fa fa-check"></i><b>2.1</b> Single Coupling Values Carry Evidence of Contacts</a></li>
<li class="chapter" data-level="2.2" data-path="coupling-profiles.html"><a href="coupling-profiles.html"><i class="fa fa-check"></i><b>2.2</b> Coupling Profiles Vary with Distance</a></li>
<li class="chapter" data-level="2.3" data-path="physico-chemical-fingerprints-in-coupling-matrices.html"><a href="physico-chemical-fingerprints-in-coupling-matrices.html"><i class="fa fa-check"></i><b>2.3</b> Physico-Chemical Fingerprints in Coupling Matrices</a></li>
<li class="chapter" data-level="2.4" data-path="higher-order-coupling-profiles.html"><a href="higher-order-coupling-profiles.html"><i class="fa fa-check"></i><b>2.4</b> Higher Order Dependencies Between Couplings</a></li>
<li class="chapter" data-level="2.5" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>2.5</b> Discussion</a></li>
<li class="chapter" data-level="2.6" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2.6</b> Methods</a><ul>
<li class="chapter" data-level="2.6.1" data-path="methods.html"><a href="methods.html#dataset"><i class="fa fa-check"></i><b>2.6.1</b> Dataset</a></li>
<li class="chapter" data-level="2.6.2" data-path="methods.html"><a href="methods.html#diff-ccmpred-ccmpredpy"><i class="fa fa-check"></i><b>2.6.2</b> Computing Pseudo-Likelihood Couplings</a></li>
<li class="chapter" data-level="2.6.3" data-path="methods.html"><a href="methods.html#seq-reweighting"><i class="fa fa-check"></i><b>2.6.3</b> Sequence Reweighting</a></li>
<li class="chapter" data-level="2.6.4" data-path="methods.html"><a href="methods.html#amino-acid-frequencies"><i class="fa fa-check"></i><b>2.6.4</b> Computing Amino Acid Frequencies</a></li>
<li class="chapter" data-level="2.6.5" data-path="methods.html"><a href="methods.html#methods-regularization"><i class="fa fa-check"></i><b>2.6.5</b> Regularization</a></li>
<li class="chapter" data-level="2.6.6" data-path="methods.html"><a href="methods.html#method-coupling-correlation"><i class="fa fa-check"></i><b>2.6.6</b> Correlation of Couplings with Contact Class</a></li>
<li class="chapter" data-level="2.6.7" data-path="methods.html"><a href="methods.html#method-coupling-profile"><i class="fa fa-check"></i><b>2.6.7</b> Coupling Distribution Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="optimizing-full-likelihood.html"><a href="optimizing-full-likelihood.html"><i class="fa fa-check"></i><b>3</b> Optimizing the Full Likelihood</a><ul>
<li class="chapter" data-level="3.1" data-path="full-likelihood-gradient.html"><a href="full-likelihood-gradient.html"><i class="fa fa-check"></i><b>3.1</b> Approximating the Gradient of the Full Likelihood with Contrastive Divergence</a></li>
<li class="chapter" data-level="3.2" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html"><i class="fa fa-check"></i><b>3.2</b> Optimizing the Full Likelihood</a><ul>
<li class="chapter" data-level="3.2.1" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html#convergence-criteria-sgd"><i class="fa fa-check"></i><b>3.2.1</b> Convergence Criterion for Stochastic Gradient Descent</a></li>
<li class="chapter" data-level="3.2.2" data-path="full-likelihood-optimization.html"><a href="full-likelihood-optimization.html#sgd-hyperparameter-tuning"><i class="fa fa-check"></i><b>3.2.2</b> Tuning Hyperparameters of Stochastic Gradient Descent Optimizer</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html"><i class="fa fa-check"></i><b>3.3</b> Tuning the Gibbs Sampling Scheme for Contrastive Divergence</a><ul>
<li class="chapter" data-level="3.3.1" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#regularization-for-cd-with-sgd"><i class="fa fa-check"></i><b>3.3.1</b> Tuning Regularization Coefficients for Contrastive Divergence</a></li>
<li class="chapter" data-level="3.3.2" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-sampling-size"><i class="fa fa-check"></i><b>3.3.2</b> Varying the Sample Size</a></li>
<li class="chapter" data-level="3.3.3" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-gibbs-steps"><i class="fa fa-check"></i><b>3.3.3</b> Varying the number of Gibbs Steps</a></li>
<li class="chapter" data-level="3.3.4" data-path="cd-sampling-optimization.html"><a href="cd-sampling-optimization.html#cd-gibbs-steps"><i class="fa fa-check"></i><b>3.3.4</b> Persistent Contrastive Divergence</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="adam-results.html"><a href="adam-results.html"><i class="fa fa-check"></i><b>3.4</b> Using ADAM to Optimize Contrastive Divergence</a><ul>
<li class="chapter" data-level="3.4.1" data-path="adam-results.html"><a href="adam-results.html#adam-violates-sum-wij"><i class="fa fa-check"></i><b>3.4.1</b> A <em>Potts</em> model specific convergence criterion</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="comparing-pll-cd.html"><a href="comparing-pll-cd.html"><i class="fa fa-check"></i><b>3.5</b> Comparing CD couplings to pLL couplings</a><ul>
<li class="chapter" data-level="3.5.1" data-path="comparing-pll-cd.html"><a href="comparing-pll-cd.html#protein-1c75a00"><i class="fa fa-check"></i><b>3.5.1</b> Protein 1c75A00</a></li>
<li class="chapter" data-level="3.5.2" data-path="comparing-pll-cd.html"><a href="comparing-pll-cd.html#protein-1ss3a00-and-1c55a00"><i class="fa fa-check"></i><b>3.5.2</b> Protein 1ss3A00 and 1c55A00</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="discussion-1.html"><a href="discussion-1.html"><i class="fa fa-check"></i><b>3.6</b> Discussion</a></li>
<li class="chapter" data-level="3.7" data-path="methods-1.html"><a href="methods-1.html"><i class="fa fa-check"></i><b>3.7</b> Methods</a><ul>
<li class="chapter" data-level="3.7.1" data-path="methods-1.html"><a href="methods-1.html#potts-full-likelihood"><i class="fa fa-check"></i><b>3.7.1</b> The Potts Model</a></li>
<li class="chapter" data-level="3.7.2" data-path="methods-1.html"><a href="methods-1.html#gap-treatment"><i class="fa fa-check"></i><b>3.7.2</b> Treating Gaps as Missing Information</a></li>
<li class="chapter" data-level="3.7.3" data-path="methods-1.html"><a href="methods-1.html#the-regularized-full-log-likelihood-and-its-gradient-with-gap-treatment"><i class="fa fa-check"></i><b>3.7.3</b> The Regularized Full Log Likelihood and its Gradient With Gap Treatment</a></li>
<li class="chapter" data-level="3.7.4" data-path="methods-1.html"><a href="methods-1.html#prior-v"><i class="fa fa-check"></i><b>3.7.4</b> The prior on single potentials</a></li>
<li class="chapter" data-level="3.7.5" data-path="methods-1.html"><a href="methods-1.html#methods-sgd"><i class="fa fa-check"></i><b>3.7.5</b> Stochastic Gradien Descent</a></li>
<li class="chapter" data-level="3.7.6" data-path="methods-1.html"><a href="methods-1.html#methods-cd-sampling"><i class="fa fa-check"></i><b>3.7.6</b> Computing the Gradient with Contrastive Divergence</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="contact-prior.html"><a href="contact-prior.html"><i class="fa fa-check"></i><b>4</b> Random Forest Contact Prior</a><ul>
<li class="chapter" data-level="4.1" data-path="random-forest-classifiers.html"><a href="random-forest-classifiers.html"><i class="fa fa-check"></i><b>4.1</b> Random Forest Classifiers</a></li>
<li class="chapter" data-level="4.2" data-path="hyperparameter-optimization-for-random-forest.html"><a href="hyperparameter-optimization-for-random-forest.html"><i class="fa fa-check"></i><b>4.2</b> Hyperparameter Optimization for Random Forest</a></li>
<li class="chapter" data-level="4.3" data-path="evaluating-random-forest-model-as-contact-predictor.html"><a href="evaluating-random-forest-model-as-contact-predictor.html"><i class="fa fa-check"></i><b>4.3</b> Evaluating Random Forest Model as Contact Predictor</a></li>
<li class="chapter" data-level="4.4" data-path="using-contact-scores-as-additional-features.html"><a href="using-contact-scores-as-additional-features.html"><i class="fa fa-check"></i><b>4.4</b> Using Contact Scores as Additional Features</a></li>
<li class="chapter" data-level="4.5" data-path="discussion-2.html"><a href="discussion-2.html"><i class="fa fa-check"></i><b>4.5</b> Discussion</a></li>
<li class="chapter" data-level="4.6" data-path="methods-2.html"><a href="methods-2.html"><i class="fa fa-check"></i><b>4.6</b> Methods</a><ul>
<li class="chapter" data-level="4.6.1" data-path="methods-2.html"><a href="methods-2.html#seq-features"><i class="fa fa-check"></i><b>4.6.1</b> Features used to train Random Forest Model</a></li>
<li class="chapter" data-level="4.6.2" data-path="methods-2.html"><a href="methods-2.html#simple-contact-prior-with-respect-to-protein-length"><i class="fa fa-check"></i><b>4.6.2</b> Simple Contact Prior with Respect to Protein Length</a></li>
<li class="chapter" data-level="4.6.3" data-path="methods-2.html"><a href="methods-2.html#rf-training"><i class="fa fa-check"></i><b>4.6.3</b> Cross-validation for Random Forest Training</a></li>
<li class="chapter" data-level="4.6.4" data-path="methods-2.html"><a href="methods-2.html#rf-feature-selection"><i class="fa fa-check"></i><b>4.6.4</b> Feature Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayesian-approach.html"><a href="bayesian-approach.html"><i class="fa fa-check"></i><b>5</b> A Bayesian Statistical Model for Residue-Residue Contact Prediction</a><ul>
<li class="chapter" data-level="5.1" data-path="overview-posterior-distances.html"><a href="overview-posterior-distances.html"><i class="fa fa-check"></i><b>5.1</b> Computing the Posterior Probabiilty of a Contact</a></li>
<li class="chapter" data-level="5.2" data-path="coupling-prior.html"><a href="coupling-prior.html"><i class="fa fa-check"></i><b>5.2</b> Modelling the Prior Over Couplings Depending on Contact States</a></li>
<li class="chapter" data-level="5.3" data-path="bayesian-model-training-hyperparameters.html"><a href="bayesian-model-training-hyperparameters.html"><i class="fa fa-check"></i><b>5.3</b> Training the Hyperparameters in the Likelihood Function of Contact States</a></li>
<li class="chapter" data-level="5.4" data-path="training-hyperparameters-for-a-gaussian-mixture-with-three-components.html"><a href="training-hyperparameters-for-a-gaussian-mixture-with-three-components.html"><i class="fa fa-check"></i><b>5.4</b> Training Hyperparameters for a Gaussian Mixture with Three Components</a></li>
<li class="chapter" data-level="5.5" data-path="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components.html"><a href="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components.html"><i class="fa fa-check"></i><b>5.5</b> Training Hyperparameters for a Gaussian Mixture with Five and Ten Components</a></li>
<li class="chapter" data-level="5.6" data-path="posterior-of-rij.html"><a href="posterior-of-rij.html"><i class="fa fa-check"></i><b>5.6</b> Computing The Posterior Probability of Contacts</a><ul>
<li class="chapter" data-level="5.6.1" data-path="posterior-of-rij.html"><a href="posterior-of-rij.html#evaluation-of-the-bayesian-models-for-contact-prediction"><i class="fa fa-check"></i><b>5.6.1</b> Evaluation of the Bayesian models for contact-prediction</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="analysing-contact-maps.html"><a href="analysing-contact-maps.html"><i class="fa fa-check"></i><b>5.7</b> Analysing Contact Maps</a></li>
<li class="chapter" data-level="5.8" data-path="discussion-3.html"><a href="discussion-3.html"><i class="fa fa-check"></i><b>5.8</b> Discussion</a></li>
<li class="chapter" data-level="5.9" data-path="methods-3.html"><a href="methods-3.html"><i class="fa fa-check"></i><b>5.9</b> Methods</a><ul>
<li class="chapter" data-level="5.9.1" data-path="methods-3.html"><a href="methods-3.html#methods-coupling-prior"><i class="fa fa-check"></i><b>5.9.1</b> Modelling the Prior Over Couplings Depending on Contact States</a></li>
<li class="chapter" data-level="5.9.2" data-path="methods-3.html"><a href="methods-3.html#laplace-approx"><i class="fa fa-check"></i><b>5.9.2</b> Gaussian Approximation to the Posterior of Couplings</a></li>
<li class="chapter" data-level="5.9.3" data-path="methods-3.html"><a href="methods-3.html#likelihood-fct-distances"><i class="fa fa-check"></i><b>5.9.3</b> Integrating out the Hidden Variables to Obtain the Likelihood Function of the Contact States</a></li>
<li class="chapter" data-level="5.9.4" data-path="methods-3.html"><a href="methods-3.html#Hessian-offdiagonal"><i class="fa fa-check"></i><b>5.9.4</b> The Hessian off-diagonal Elements Carry a Negligible Signal</a></li>
<li class="chapter" data-level="5.9.5" data-path="methods-3.html"><a href="methods-3.html#neg-Hessian-computation"><i class="fa fa-check"></i><b>5.9.5</b> Efficiently Computing the negative Hessian of the regularized log-likelihood</a></li>
<li class="chapter" data-level="5.9.6" data-path="methods-3.html"><a href="methods-3.html#inv-lambda-ij-k"><i class="fa fa-check"></i><b>5.9.6</b> Efficiently Computing the Inverse of Matrix <span class="math inline">\(\Lijk\)</span></a></li>
<li class="chapter" data-level="5.9.7" data-path="methods-3.html"><a href="methods-3.html#gradient-muk"><i class="fa fa-check"></i><b>5.9.7</b> The gradient of the log likelihood with respect to <span class="math inline">\(\muk\)</span></a></li>
<li class="chapter" data-level="5.9.8" data-path="methods-3.html"><a href="methods-3.html#gradient-lambdak"><i class="fa fa-check"></i><b>5.9.8</b> The gradient of the log likelihood with respect to <span class="math inline">\(\Lk\)</span></a></li>
<li class="chapter" data-level="5.9.9" data-path="methods-3.html"><a href="methods-3.html#the-gradient-of-the-log-likelihood-with-respect-to-gamma_k"><i class="fa fa-check"></i><b>5.9.9</b> The gradient of the log likelihood with respect to <span class="math inline">\(\gamma_k\)</span></a></li>
<li class="chapter" data-level="5.9.10" data-path="methods-3.html"><a href="methods-3.html#bayesian-model-distances"><i class="fa fa-check"></i><b>5.9.10</b> Extending the Bayesian Statistical Model for the Prediction of Protein Residue-Residue Distances</a></li>
<li class="chapter" data-level="5.9.11" data-path="methods-3.html"><a href="methods-3.html#training-hyperparameters-bayesian-model"><i class="fa fa-check"></i><b>5.9.11</b> Training the Hyperparameters in the Likelihood Function of Contact States</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="conclusion-and-outlook.html"><a href="conclusion-and-outlook.html"><i class="fa fa-check"></i><b>6</b> Conclusion and Outlook</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="abbrev.html"><a href="abbrev.html"><i class="fa fa-check"></i><b>A</b> Abbreviations</a></li>
<li class="chapter" data-level="B" data-path="amino-acids.html"><a href="amino-acids.html"><i class="fa fa-check"></i><b>B</b> Amino Acid Alphabet</a></li>
<li class="chapter" data-level="C" data-path="dataset-properties.html"><a href="dataset-properties.html"><i class="fa fa-check"></i><b>C</b> Dataset Properties</a></li>
<li class="chapter" data-level="D" data-path="interpretation-of-coupling-matrices.html"><a href="interpretation-of-coupling-matrices.html"><i class="fa fa-check"></i><b>D</b> Interpretation of Coupling Matrices</a></li>
<li class="chapter" data-level="E" data-path="optimizing-full-likelihood-with-gradient-descent.html"><a href="optimizing-full-likelihood-with-gradient-descent.html"><i class="fa fa-check"></i><b>E</b> Optimizing Full Likelihood with Gradient Descent</a></li>
<li class="chapter" data-level="F" data-path="training-of-the-random-forest-contact-prior.html"><a href="training-of-the-random-forest-contact-prior.html"><i class="fa fa-check"></i><b>F</b> Training of the Random Forest Contact Prior</a></li>
<li class="chapter" data-level="G" data-path="bayesian-statistical-model-for-contact-prediction.html"><a href="bayesian-statistical-model-for-contact-prediction.html"><i class="fa fa-check"></i><b>G</b> Bayesian statistical model for contact prediction</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PhD thesis: residue-residue contact prediction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components" class="section level2">
<h2><span class="header-section-number">5.5</span> Training Hyperparameters for a Gaussian Mixture with Five and Ten Components</h2>
<p>The increased complexity of training five or even ten instead of three component Gaussian mixtures does not only result in longer runtimes until convergence but also slows down runtime per iteration. The optimization runs for five and ten component Gaussian mixtures did not converge within 2000 iterations. Nevertheless, the obtained hyperparameters and resulting Gaussian mixture are consistent.</p>
<p>Figure <a href="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components.html#fig:stats-pll-5comp-300k">5.4</a> and <a href="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components.html#fig:stats-pll-10comp-300k">5.5</a> show the statistics of the inferred hyperparameters for a five and ten component Gaussian mixture respectively. Similary to three component Gaussian mixtures, the zeroth component receives a high weight for couplings from residue pairs that are not in physical contact (<span class="math inline">\(g_0(0) \eq 0.93\)</span> for five component mixture and <span class="math inline">\(g_0(0) \eq 0.87\)</span> for ten component mixture). There is a second component with a noteworthy contribution to the Gaussian mixture for non-contact couplings (component 3 with <span class="math inline">\(g_1(0) \eq 0.07\)</span> for five component mixture and component 9 with <span class="math inline">\(g_1(0) \eq 0.13\)</span> for ten component mixture). These two components are also the strongest components for the Gaussian mixture representing couplings from contacting residue pairs. Furthermore, hyperparameters inferred using contrastive divergence couplings are again similar to those based on pseudo-likelihood couplings and statistics of hyperparameter are visualized in Appendix Figures <a href="bayesian-statistical-model-for-contact-prediction.html#fig:stats-cd-5comp-100k">G.10</a> and <a href="bayesian-statistical-model-for-contact-prediction.html#fig:stats-cd-5comp-300k">G.11</a>.</p>

<div class="figure"><span id="fig:stats-pll-5comp-300k"></span>
<img src="img/bayesian_model/pll/5/stats-pll-5comp-300k_contactthr25.png" alt="Statistics for the hyperparameters, \(\gamma_k(\cij)\), \(\muk\) and \(\Lk\) obtained after 1134 iterations for a five component Guassian mixture. Trained on 300,000 residue pairs per contact class for a five component Gaussian mixture and using pseudo-likelihood couplings to estimate the Hessian. Left Component weights \(\gamma_k(\cij)\) for residue pairs not in physical contact (\(\cij \eq 0\)) and true contacts (\(\cij \eq 1\)). Center Distribution of the 400 elements in the mean vectors \(\muk\). Right Distribution of the 400 standard deviations corresponding to the square root of the diagonal of \(\Lk^{-1}\)." width="100%" />
<p class="caption">
Figure 5.4: Statistics for the hyperparameters, <span class="math inline">\(\gamma_k(\cij)\)</span>, <span class="math inline">\(\muk\)</span> and <span class="math inline">\(\Lk\)</span> obtained after 1134 iterations for a five component Guassian mixture. Trained on 300,000 residue pairs per contact class for a five component Gaussian mixture and using <em>pseudo-likelihood</em> couplings to estimate the Hessian. <strong>Left</strong> Component weights <span class="math inline">\(\gamma_k(\cij)\)</span> for residue pairs not in physical contact (<span class="math inline">\(\cij \eq 0\)</span>) and true contacts (<span class="math inline">\(\cij \eq 1\)</span>). <strong>Center</strong> Distribution of the 400 elements in the mean vectors <span class="math inline">\(\muk\)</span>. <strong>Right</strong> Distribution of the 400 standard deviations corresponding to the square root of the diagonal of <span class="math inline">\(\Lk^{-1}\)</span>.
</p>
</div>

<div class="figure"><span id="fig:stats-pll-10comp-300k"></span>
<img src="img/bayesian_model/pll/10/300k_weights_noncontacththr25.png" alt="Statistics for the hyperparameters, \(\gamma_k(\cij)\), \(\muk\) and \(\Lk\) obtained after 700 iterations for a ten component Gaussian mixture. Trained on 300,000 residue pairs per contact class for a five component Gaussian mixture and using pseudo-likelihood couplings to estimate the Hessian. Top Component weights \(\gamma_k(\cij)\) for residue pairs not in physical contact (\(\cij \eq 0\)) and true contacts (\(\cij \eq 1\)). Middle Distribution of the 400 elements in the mean vectors \(\muk\). Bottom Distribution of the 400 standard deviations corresponding to the square root of the diagonal of \(\Lk^{-1}\)." width="90%" /><img src="img/bayesian_model/pll/10/300k_mus_noncontactthr25.png" alt="Statistics for the hyperparameters, \(\gamma_k(\cij)\), \(\muk\) and \(\Lk\) obtained after 700 iterations for a ten component Gaussian mixture. Trained on 300,000 residue pairs per contact class for a five component Gaussian mixture and using pseudo-likelihood couplings to estimate the Hessian. Top Component weights \(\gamma_k(\cij)\) for residue pairs not in physical contact (\(\cij \eq 0\)) and true contacts (\(\cij \eq 1\)). Middle Distribution of the 400 elements in the mean vectors \(\muk\). Bottom Distribution of the 400 standard deviations corresponding to the square root of the diagonal of \(\Lk^{-1}\)." width="90%" /><img src="img/bayesian_model/pll/10/300k_std_noncontactthr25.png" alt="Statistics for the hyperparameters, \(\gamma_k(\cij)\), \(\muk\) and \(\Lk\) obtained after 700 iterations for a ten component Gaussian mixture. Trained on 300,000 residue pairs per contact class for a five component Gaussian mixture and using pseudo-likelihood couplings to estimate the Hessian. Top Component weights \(\gamma_k(\cij)\) for residue pairs not in physical contact (\(\cij \eq 0\)) and true contacts (\(\cij \eq 1\)). Middle Distribution of the 400 elements in the mean vectors \(\muk\). Bottom Distribution of the 400 standard deviations corresponding to the square root of the diagonal of \(\Lk^{-1}\)." width="90%" />
<p class="caption">
Figure 5.5: Statistics for the hyperparameters, <span class="math inline">\(\gamma_k(\cij)\)</span>, <span class="math inline">\(\muk\)</span> and <span class="math inline">\(\Lk\)</span> obtained after 700 iterations for a ten component Gaussian mixture. Trained on 300,000 residue pairs per contact class for a five component Gaussian mixture and using <em>pseudo-likelihood</em> couplings to estimate the Hessian. <strong>Top</strong> Component weights <span class="math inline">\(\gamma_k(\cij)\)</span> for residue pairs not in physical contact (<span class="math inline">\(\cij \eq 0\)</span>) and true contacts (<span class="math inline">\(\cij \eq 1\)</span>). <strong>Middle</strong> Distribution of the 400 elements in the mean vectors <span class="math inline">\(\muk\)</span>. <strong>Bottom</strong> Distribution of the 400 standard deviations corresponding to the square root of the diagonal of <span class="math inline">\(\Lk^{-1}\)</span>.
</p>
</div>
<p>Figure <a href="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components.html#fig:vis1d-pll-5-10-comp-300k">5.6</a> compares the one-dimensional projections of the 400 dimensionl Gaussian mixtures with five and ten components for the amino acid pair V-I and E-R. The general observations regarding the shape of the Gaussian mixture for couplings from contacts and non-contacts that have been found for the three component mixture also apply here. Generally, the Gaussian mixture for couplings from non-contacts is narrower in the five and ten component mixtures than in the three component Gaussian mixture model. Thereby, the differentiation between contacts and non-contacts is enhanced because the ratio between the Gaussian mixture probability distribution for contacts and non-contacts increases. Furthermore, whereas in the three component model only two components would contribute to defining the tails of the distribution for couplings from contacts, now there are more components that can refine the tails. For example, in the case of amino acid pair E-R all but the zeroth component, which is fixed at zero, are shifted towards positive values. In the case of amino acid pair V-I the components are shifted towards both positive and negative values. Overall, the Gaussian mixtures with five and ten components seem to refine the modelling of the coupling distributions compared to the simpler three component model. The same observations apply to the Gaussian mixtures inferred based on contrastive divergence couplings only that the resultant mixtures are narrower (see Appendix Figure <a href="bayesian-statistical-model-for-contact-prediction.html#fig:vis1d-cd-5comp-300k">G.12</a>).</p>

<div class="figure"><span id="fig:vis1d-pll-5-10-comp-300k"></span>
<img src="img/bayesian_model/pll/1dvis_combined_5comp_10comp_300k.png" alt="Visualisation of one-dimensional projections of the five and ten component Gaussian mixture model for the contact-dependent coupling prior. Hyperparameters, \(\gamma_k(\cij)\), \(\muk\) and \(\Lk\), have been trained on 300,000 residue pairs per contact class and using pseudo-likelihood couplings to estimate the Hessian. Green solid line: Gaussian mixture for contacts. Blue solid line: Gaussian mixture for non-contacts. Black solid line: regularization prior with \(\lambda_1 \eq 0.2L\) with L being protein length and assumed \(L\eq150\). Dashed lines represent the unweighted Gaussian mixture components. Top Left One dimensional projection for pair (V,I) from the five component model. Top Right One dimensional projection for pair (V,I) from the ten component model. Bottom Left One dimensional projection for pair (E,R) from the five component model. Bottom Right One dimensional projection for pair (E,R) from the ten component model." width="100%" />
<p class="caption">
Figure 5.6: Visualisation of one-dimensional projections of the five and ten component Gaussian mixture model for the contact-dependent coupling prior. Hyperparameters, <span class="math inline">\(\gamma_k(\cij)\)</span>, <span class="math inline">\(\muk\)</span> and <span class="math inline">\(\Lk\)</span>, have been trained on 300,000 residue pairs per contact class and using <em>pseudo-likelihood</em> couplings to estimate the Hessian. Green solid line: Gaussian mixture for contacts. Blue solid line: Gaussian mixture for non-contacts. Black solid line: regularization prior with <span class="math inline">\(\lambda_1 \eq 0.2L\)</span> with L being protein length and assumed <span class="math inline">\(L\eq150\)</span>. Dashed lines represent the unweighted Gaussian mixture components. <strong>Top Left</strong> One dimensional projection for pair (V,I) from the five component model. <strong>Top Right</strong> One dimensional projection for pair (V,I) from the ten component model. <strong>Bottom Left</strong> One dimensional projection for pair (E,R) from the five component model. <strong>Bottom Right</strong> One dimensional projection for pair (E,R) from the ten component model.
</p>
</div>
<p>Two-dimensional projections of the Gaussian mixture with five and ten components are shown in Figure <a href="training-hyperparameters-for-a-gaussian-mixture-with-five-and-ten-components.html#fig:vis2d-pll-5-10-comp-300k">5.7</a> for different pairs of couplings. The distributions resemble the ones learned for the Gaussian mixture with three components. However, it is visible that the zeroth component is narrower for the five and ten component Gaussian mixture and that the additional components model particular parts of the distribution. The optimized coupling prior model that has been learned based on couplings computed with contrastive-divergence in general produces distributions that are narrower which is expected given the hyperparameter statistics and the observations from the univariate distributions.</p>

<div class="figure"><span id="fig:vis2d-pll-5-10-comp-300k"></span>
<img src="img/bayesian_model/pll/2dvis_combined_5comp_10comp_300k.png" alt="Visualisation of two-dimensional projections of the five and ten component Gaussian mixture model for the contact-dependent coupling prior. Hyperparameters, \(\gamma_k(\cij)\), \(\muk\) and \(\Lk\), have been trained on 300,000 residue pairs per contact class. 10,000 values have been samples from the Gaussian mixture model. The color of a sampled coupling pair represents the Gaussian mixture component that has generated this sample point. Color code is specified in the legend. Top Left Two-dimensional projection for pairs (E,R) and (R-E) for contacts (using component weight \(g_k(1)\)) from the five component Gaussian mixture model. Top Right Two-dimensional projection for pairs (E,R) and (R-E) for contacts (using component weight \(g_k(1)\)) from the ten component Gaussian mixture model. Bottom Left Two-dimensional projection for pair (I,L) and (V,I) for non-contacts (using component weight \(g_k(0)\)) from the five component Gaussian mixture model. Bottom Right Two-dimensional projection for pair (I,L) and (V,I) for non-contacts (using component weight \(g_k(0)\)) from the ten component Gaussian mixture model." width="100%" />
<p class="caption">
Figure 5.7: Visualisation of two-dimensional projections of the five and ten component Gaussian mixture model for the contact-dependent coupling prior. Hyperparameters, <span class="math inline">\(\gamma_k(\cij)\)</span>, <span class="math inline">\(\muk\)</span> and <span class="math inline">\(\Lk\)</span>, have been trained on 300,000 residue pairs per contact class. 10,000 values have been samples from the Gaussian mixture model. The color of a sampled coupling pair represents the Gaussian mixture component that has generated this sample point. Color code is specified in the legend. <strong>Top Left</strong> Two-dimensional projection for pairs (E,R) and (R-E) for contacts (using component weight <span class="math inline">\(g_k(1)\)</span>) from the five component Gaussian mixture model. <strong>Top Right</strong> Two-dimensional projection for pairs (E,R) and (R-E) for contacts (using component weight <span class="math inline">\(g_k(1)\)</span>) from the ten component Gaussian mixture model. <strong>Bottom Left</strong> Two-dimensional projection for pair (I,L) and (V,I) for non-contacts (using component weight <span class="math inline">\(g_k(0)\)</span>) from the five component Gaussian mixture model. <strong>Bottom Right</strong> Two-dimensional projection for pair (I,L) and (V,I) for non-contacts (using component weight <span class="math inline">\(g_k(0)\)</span>) from the ten component Gaussian mixture model.
</p>
</div>
<p>In conclusion it can be found that the learned Gaussian mixtures for the contact-dependent couplig prior seem to reproduce the empirical distribution of couplings in Figure <a href="higher-order-coupling-profiles.html#fig:2d-coupling-profiles-0-8">2.13</a> very well. Of course it must be noted that the empirical distributions do not take the uncertainty of the inferred couplings into account. They are computed for high evidence couplings as explained in method section <a href="methods.html#method-coupling-profile">2.6.7</a> and therefore do not provide a completely correct reference. The more components define the Gaussian mixture, the longer it takes to train the model per iteration and the more iterations it takes to reach convergence. Eventhough, training the five and ten component Gaussian mixtures could not be continued until convergence because of time requirements, the resulting models seem robust and consistently produce similar distributions regardless of the dataset size and repeated independent runs.</p>
</div>
<div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://contactpredictionthesis.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="training-hyperparameters-for-a-gaussian-mixture-with-three-components.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="posterior-of-rij.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/susannvorberg/phd_thesis/edit/master/07-posterior-distribution.Rmd",
"text": "Edit"
},
"download": ["PhD_thesis_Susann_Vorberg.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
