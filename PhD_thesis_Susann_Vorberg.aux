\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/r>>}
\HyPL@Entry{6<</S/r>>}
\newlabel{summary}{{}{i}{Summary}{chapter*.1}{}}
\@writefile{toc}{\contentsline {chapter}{Summary}{i}{chapter*.1}}
\newlabel{acknowledgements}{{}{iii}{Acknowledgements}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{iii}{chapter*.2}}
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{v}{chapter*.3}}
\HyPL@Entry{12<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Interpretation of Coupling Matrices}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{interpreting-coupling-matrices}{{1}{1}{Interpretation of Coupling Matrices}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Single Coupling Values Carry Evidence of Contacts}{1}{section.1.1}}
\newlabel{correlation-between-couplings-and-class}{{1.1}{1}{Single Coupling Values Carry Evidence of Contacts}{section.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf  {Left} Pearson correlation of squared coupling values \((w_{ijab})^2\) with contact class (contact=1, non-contact=0). \textbf  {Right} Standard deviation of squared coupling values. Dataset contains 100.000 residue pairs per class (for details see methods section \ref  {method-coupling-correlation}). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref  {amino-acids}.}}{2}{figure.1.1}}
\newlabel{fig:sq-coupling-correlation}{{1.1}{2}{\textbf {Left} Pearson correlation of squared coupling values \((\wijab )^2\) with contact class (contact=1, non-contact=0). \textbf {Right} Standard deviation of squared coupling values. Dataset contains 100.000 residue pairs per class (for details see methods section \ref {method-coupling-correlation}). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref {amino-acids}}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces \textbf  {Left} Pearson correlation of raw signed coupling values \(w_{ijab}\) with contact class (contact=1, non-contact=0). \textbf  {Right} Standard deviation of coupling values. Dataset contains 100.000 residue pairs per class (for details see section \ref  {method-coupling-correlation}). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref  {amino-acids}.}}{3}{figure.1.2}}
\newlabel{fig:coupling-correlation}{{1.2}{3}{\textbf {Left} Pearson correlation of raw signed coupling values \(\wijab \) with contact class (contact=1, non-contact=0). \textbf {Right} Standard deviation of coupling values. Dataset contains 100.000 residue pairs per class (for details see section \ref {method-coupling-correlation}). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref {amino-acids}}{figure.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Physico-Chemical Fingerprints in Coupling Matrices}{3}{section.1.2}}
\newlabel{physico-chemical-fingerprints-in-coupling-matrices}{{1.2}{3}{Physico-Chemical Fingerprints in Coupling Matrices}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Coupling matrix computed with pseudo-likelihood for residues 6 and 82 in protein chain 1a9x\_A\_05. Color represents coupling strength and direction (red = positive coupling value, blue = negative coupling value) and diameter of bubbles represents absolute coupling value \(|w_{ijab}|\). Bars at the x-axis and y-axis correspond to the \emph  {Potts model} single potentials \(v_{i}\) and \(v_{j}\). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref  {amino-acids}.}}{4}{figure.1.3}}
\newlabel{fig:coupling-matrix-ionic-interaction}{{1.3}{4}{Coupling matrix computed with pseudo-likelihood for residues 6 and 82 in protein chain 1a9x\_A\_05. Color represents coupling strength and direction (red = positive coupling value, blue = negative coupling value) and diameter of bubbles represents absolute coupling value \(|\wijab |\). Bars at the x-axis and y-axis correspond to the \emph {Potts model} single potentials \(\vi \) and \(\vj \). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref {amino-acids}}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Coupling matrix computed with pseudo-likelihood for residues 29 and 39 in protein chain 1ae9\_A\_00. Color represents coupling strength and direction (red = positive coupling value, blue = negative coupling value) and diameter of bubbles represents absolute coupling value \(|w_{ijab}|\). Bars at the x-axis and y-axis correspond to the \emph  {Potts model} single potentials \(v_{i}\) and \(v_{j}\). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref  {amino-acids}.}}{5}{figure.1.4}}
\newlabel{fig:coupling-matrix-hydrophobic-interaction}{{1.4}{5}{Coupling matrix computed with pseudo-likelihood for residues 29 and 39 in protein chain 1ae9\_A\_00. Color represents coupling strength and direction (red = positive coupling value, blue = negative coupling value) and diameter of bubbles represents absolute coupling value \(|\wijab |\). Bars at the x-axis and y-axis correspond to the \emph {Potts model} single potentials \(\vi \) and \(\vj \). Amino acids are abbreviated with one-letter code and they are broadly grouped with respect to physico-chemical properties listed in Appendix \ref {amino-acids}}{figure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Interactions between protein side chains. \textbf  {Left}: residue 6 (E) forms a salt bridge with residue 82 (R) in protein chain 1a9x\_A\_05. \textbf  {Right}: residue 29 (A) and residue 39 (L) within the hydrophobic core of protein chain 1ae9\_A\_00.}}{6}{figure.1.5}}
\newlabel{fig:coupling-matrix-pymol}{{1.5}{6}{Interactions between protein side chains. \textbf {Left}: residue 6 (E) forms a salt bridge with residue 82 (R) in protein chain 1a9x\_A\_05. \textbf {Right}: residue 29 (A) and residue 39 (L) within the hydrophobic core of protein chain 1ae9\_A\_00}{figure.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Coupling Profiles Vary with Distance}{6}{section.1.3}}
\newlabel{coupling-profiles-vary-with-distance}{{1.3}{6}{Coupling Profiles Vary with Distance}{section.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Distribution of selected couplings for filtered residue pairs with \(C_\beta -C_\beta \) distances \(< 5\angstrom \) (see methods section \ref  {method-coupling-profile} for details). Number of coupling values used to determine the distribution is given in brackets in the legend. R-E = couplings for arginine and glutamic acid pairs, C-C = coupling for cystein residue pairs, V-I = coupling for valine and isoleucine pairs, F-W = coupling for phenylalanine and tryptophane pairs, E-E = coupling for glutamic acid residue pairs.}}{7}{figure.1.6}}
\newlabel{fig:1d-coupling-profile-0-5}{{1.6}{7}{Distribution of selected couplings for filtered residue pairs with \(\Cb -\Cb \) distances \(< 5\angstrom \) (see methods section \ref {method-coupling-profile} for details). Number of coupling values used to determine the distribution is given in brackets in the legend. R-E = couplings for arginine and glutamic acid pairs, C-C = coupling for cystein residue pairs, V-I = coupling for valine and isoleucine pairs, F-W = coupling for phenylalanine and tryptophane pairs, E-E = coupling for glutamic acid residue pairs}{figure.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Distribution of selected couplings for filtered residue pairs with \(C_\beta -C_\beta \) distances between \(8\angstrom \) and \(12 \angstrom \) (see methods section \ref  {method-coupling-profile} for details). Number of coupling values used to determine the distribution is given in brackets in the legend. Couplings are the same as in Figure \ref  {fig:1d-coupling-profile-0-5}.}}{8}{figure.1.7}}
\newlabel{fig:1d-coupling-profile-8-12}{{1.7}{8}{Distribution of selected couplings for filtered residue pairs with \(\Cb -\Cb \) distances between \(8\angstrom \) and \(12 \angstrom \) (see methods section \ref {method-coupling-profile} for details). Number of coupling values used to determine the distribution is given in brackets in the legend. Couplings are the same as in Figure \ref {fig:1d-coupling-profile-0-5}}{figure.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Distribution of selected couplings for filtered residue pairs with \(C_\beta -C_\beta \) distances between \(20\angstrom \) and \(50\angstrom \) (see methods section \ref  {method-coupling-profile} for details). Number of coupling values used to determine the distribution is given in brackets in the legend. Couplings are the same as in Figure \ref  {fig:1d-coupling-profile-0-5}.}}{8}{figure.1.8}}
\newlabel{fig:1d-coupling-profile-20-50}{{1.8}{8}{Distribution of selected couplings for filtered residue pairs with \(\Cb -\Cb \) distances between \(20\angstrom \) and \(50\angstrom \) (see methods section \ref {method-coupling-profile} for details). Number of coupling values used to determine the distribution is given in brackets in the legend. Couplings are the same as in Figure \ref {fig:1d-coupling-profile-0-5}}{figure.1.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Higher Order Dependencies Between Couplings}{9}{section.1.4}}
\newlabel{higher-order-dependencies-between-couplings}{{1.4}{9}{Higher Order Dependencies Between Couplings}{section.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Two-dimensional distribution of approximately 10000 coupling values computed with pseudo-likelihood. \textbf  {Top Left} The 2-dimensional distribution of couplings E-R and R-E for residue pairs with \(C_\beta -C_\beta \) distances \(< 8 \angstrom \) is almost symmetric and the coupling values are positively correlated. \textbf  {Top Right} The 2-dimensional distribution of couplings E-R and E-E for residue pairs with \(C_\beta -C_\beta \) distances \(< 8 \angstrom \) is almost symmetric and the coupling values are negatively correlated. \textbf  {Bottom Left} The 2-dimensional distribution of couplings I-L and V-I for residue pairs with \(C_\beta -C_\beta \) distances \(< 8 \angstrom \) is symmetrically distributed around zero without visible correlation. \textbf  {Bottom Right} The 2-dimensional distribution of couplings I-L and V-I for residue pairs with \(C_\beta -C_\beta \) distances \(> 20 \angstrom \) is tighly distributed around zero. .}}{10}{figure.1.9}}
\newlabel{fig:2d-coupling-profiles-0-8}{{1.9}{10}{Two-dimensional distribution of approximately 10000 coupling values computed with pseudo-likelihood. \textbf {Top Left} The 2-dimensional distribution of couplings E-R and R-E for residue pairs with \(\Cb -\Cb \) distances \(< 8 \angstrom \) is almost symmetric and the coupling values are positively correlated. \textbf {Top Right} The 2-dimensional distribution of couplings E-R and E-E for residue pairs with \(\Cb -\Cb \) distances \(< 8 \angstrom \) is almost symmetric and the coupling values are negatively correlated. \textbf {Bottom Left} The 2-dimensional distribution of couplings I-L and V-I for residue pairs with \(\Cb -\Cb \) distances \(< 8 \angstrom \) is symmetrically distributed around zero without visible correlation. \textbf {Bottom Right} The 2-dimensional distribution of couplings I-L and V-I for residue pairs with \(\Cb -\Cb \) distances \(> 20 \angstrom \) is tighly distributed around zero. }{figure.1.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Contact Prior}{11}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{contact-prior}{{2}{11}{Contact Prior}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Random Forest Classifiers}{11}{section.2.1}}
\newlabel{random-forest-classifiers}{{2.1}{11}{Random Forest Classifiers}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Classifying new data with random forests. A new data sample is run down every tree in the forest until it ends up in a leaf node. Every leaf node has associated class probabilities \(p(c)\) reflecting the fraction of training samples belonging to every class \(c\). The color of the leaf nodes reflects the class with highest probability. The predictions from all trees in form of the class probabilties are averaged over all trees and yield the final prediction.}}{12}{figure.2.1}}
\newlabel{fig:rf-intro}{{2.1}{12}{Classifying new data with random forests. A new data sample is run down every tree in the forest until it ends up in a leaf node. Every leaf node has associated class probabilities \(p(c)\) reflecting the fraction of training samples belonging to every class \(c\). The color of the leaf nodes reflects the class with highest probability. The predictions from all trees in form of the class probabilties are averaged over all trees and yield the final prediction}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Evaluating Random Forest Model as Contact Predictor}{13}{section.2.2}}
\newlabel{evaluating-random-forest-model-as-contact-predictor}{{2.2}{13}{Evaluating Random Forest Model as Contact Predictor}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Top ten features ranked according to \emph  {Gini importance}. \textbf  {OMES+APC}: \hyperlink {abbrev}{APC} corrected OMES score according to Fodor\&Aldrich {[}\hyperlink {ref-Fodor2004a}{14}{]}. \textbf  {mean pair potential (Miyasawa \& Jernigan)}: average quasi-chemical energy of transfer of amino acids from water to the protein environment {[}\hyperlink {ref-Miyazawa1999a}{15}{]}. \textbf  {MI+APC}: \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts). \textbf  {mean pair potential (Li\&Fang)}: average general contact potential by Li \& Fang {[}\hyperlink {ref-Li2011}{16}{]}. \textbf  {rel. solvent accessibilty i(j)}: RSA score computed with Netsurfp (v1.0) {[}\hyperlink {ref-Petersen2009a}{17}{]} for position i(j). \textbf  {pairwise gap\%}: percentage of gapped sequences at either position i and j. \textbf  {correlation mean isoelectric feature}: Pearson correlation between the mean isoelectric point feature (according to Zimmermann et al., 1968) for positions i and j. \textbf  {sequence separation}: \textbar {}j-i\textbar {}. \textbf  {beta sheet propensity window(i)}: beta-sheet propensity according to Psipred {[}\hyperlink {ref-Jones1999}{18}{]} computed within a window of five positions around i. eatures are described in detail in methods section \ref  {seq-features}.}}{14}{figure.2.2}}
\newlabel{fig:rf-feature-importance}{{2.2}{14}{Top ten features ranked according to \emph {Gini importance}. \textbf {OMES+APC}: \protect \hyperlink {abbrev}{APC} corrected OMES score according to Fodor\&Aldrich {[}\protect \hyperlink {ref-Fodor2004a}{14}{]}. \textbf {mean pair potential (Miyasawa \& Jernigan)}: average quasi-chemical energy of transfer of amino acids from water to the protein environment {[}\protect \hyperlink {ref-Miyazawa1999a}{15}{]}. \textbf {MI+APC}: \protect \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts). \textbf {mean pair potential (Li\&Fang)}: average general contact potential by Li \& Fang {[}\protect \hyperlink {ref-Li2011}{16}{]}. \textbf {rel. solvent accessibilty i(j)}: RSA score computed with Netsurfp (v1.0) {[}\protect \hyperlink {ref-Petersen2009a}{17}{]} for position i(j). \textbf {pairwise gap\%}: percentage of gapped sequences at either position i and j. \textbf {correlation mean isoelectric feature}: Pearson correlation between the mean isoelectric point feature (according to Zimmermann et al., 1968) for positions i and j. \textbf {sequence separation}: \textbar {}j-i\textbar {}. \textbf {beta sheet propensity window(i)}: beta-sheet propensity according to Psipred {[}\protect \hyperlink {ref-Jones1999}{18}{]} computed within a window of five positions around i. eatures are described in detail in methods section \ref {seq-features}}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Mean precision of top ranked predictions over 200 proteins for random forest models trained on subsets of features of decreasing importance. Subsets of features have been selected as described in methods section \ref  {rf-feature-selection}.}}{15}{figure.2.3}}
\newlabel{fig:rf-feature-selection-performance}{{2.3}{15}{Mean precision of top ranked predictions over 200 proteins for random forest models trained on subsets of features of decreasing importance. Subsets of features have been selected as described in methods section \ref {rf-feature-selection}}{figure.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Mean precision for top ranked contacts on a test set of 774 proteins. \textbf  {random forest (pLL)} = random forest model using sequence derived features and pseudo-likelihood contact score (\hyperlink {abbrev}{APC} corrected Frobenius norm of couplings). \textbf  {pseudo-likelihood} = \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings computed with pseudo-likelihood. \textbf  {random forest} = random forest model trained on 75 sequence derived features. \textbf  {OMES} = \hyperlink {abbrev}{APC} corrected \emph  {OMES} contact score according to Fodor\&Aldrich {[}\hyperlink {ref-Fodor2004a}{14}{]}. \textbf  {mutual information} = \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts).}}{16}{figure.2.4}}
\newlabel{fig:performance-rf}{{2.4}{16}{Mean precision for top ranked contacts on a test set of 774 proteins. \textbf {random forest (pLL)} = random forest model using sequence derived features and pseudo-likelihood contact score (\protect \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings). \textbf {pseudo-likelihood} = \protect \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings computed with pseudo-likelihood. \textbf {random forest} = random forest model trained on 75 sequence derived features. \textbf {OMES} = \protect \hyperlink {abbrev}{APC} corrected \emph {OMES} contact score according to Fodor\&Aldrich {[}\protect \hyperlink {ref-Fodor2004a}{14}{]}. \textbf {mutual information} = \protect \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts)}{figure.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Mean precision for top ranked contacts on a test set of 774 proteins splitted into four equally sized subsets with respect to \hyperlink {abbrev}{Neff}. Subsets are defined according to quantiles of \hyperlink {abbrev}{Neff} values. Upper left: Subset of proteins with \hyperlink {abbrev}{Neff} \textless {} Q1. Upper right: Subset of proteins with Q1 \textless {}= \hyperlink {abbrev}{Neff} \textless {} Q2. Lower left: Subset of proteins with Q2 \textless {}= \hyperlink {abbrev}{Neff} \textless {} Q3. Lower right: Subset of proteins with Q3 \textless {}= \hyperlink {abbrev}{Neff} \textless {} Q4. \textbf  {random forest (pLL)} = random forest model using sequence derived features and pseudo-likelihood contact score (\hyperlink {abbrev}{APC} corrected Frobenius norm of couplings). \textbf  {pseudo-likelihood} = \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings computed with pseudo-likelihood. \textbf  {random forest} = random forest model trained on 75 sequence derived features. \textbf  {OMES} = \hyperlink {abbrev}{APC} corrected \emph  {OMES} contact score according to Fodor\&Aldrich {[}\hyperlink {ref-Fodor2004a}{14}{]}. \textbf  {mutual information} = \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts).}}{17}{figure.2.5}}
\newlabel{fig:performance-neff-rf}{{2.5}{17}{Mean precision for top ranked contacts on a test set of 774 proteins splitted into four equally sized subsets with respect to \protect \hyperlink {abbrev}{Neff}. Subsets are defined according to quantiles of \protect \hyperlink {abbrev}{Neff} values. Upper left: Subset of proteins with \protect \hyperlink {abbrev}{Neff} \textless {} Q1. Upper right: Subset of proteins with Q1 \textless {}= \protect \hyperlink {abbrev}{Neff} \textless {} Q2. Lower left: Subset of proteins with Q2 \textless {}= \protect \hyperlink {abbrev}{Neff} \textless {} Q3. Lower right: Subset of proteins with Q3 \textless {}= \protect \hyperlink {abbrev}{Neff} \textless {} Q4. \textbf {random forest (pLL)} = random forest model using sequence derived features and pseudo-likelihood contact score (\protect \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings). \textbf {pseudo-likelihood} = \protect \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings computed with pseudo-likelihood. \textbf {random forest} = random forest model trained on 75 sequence derived features. \textbf {OMES} = \protect \hyperlink {abbrev}{APC} corrected \emph {OMES} contact score according to Fodor\&Aldrich {[}\protect \hyperlink {ref-Fodor2004a}{14}{]}. \textbf {mutual information} = \protect \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts)}{figure.2.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methods}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{methods}{{3}{19}{Methods}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Dataset}{19}{section.3.1}}
\newlabel{dataset}{{3.1}{19}{Dataset}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Distribution of CATH classes (1=mainly \(\alpha \), 2=mainly \(\beta \), 3=\(\alpha -\beta \)) in the dataset and the ten subsets. }}{20}{figure.3.1}}
\newlabel{fig:dataset-cath-topologies}{{3.1}{20}{Distribution of CATH classes (1=mainly \(\alpha \), 2=mainly \(\beta \), 3=\(\alpha -\beta \)) in the dataset and the ten subsets}{figure.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Optimizing Pseudo-Likelihood}{20}{section.3.2}}
\newlabel{optimizing-pseudo-likelihood}{{3.2}{20}{Optimizing Pseudo-Likelihood}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Pseudo-Likelihood Objective Function and its Gradients}{21}{subsection.3.2.1}}
\newlabel{pseudo-likelihood-objective-function-and-its-gradients}{{3.2.1}{21}{Pseudo-Likelihood Objective Function and its Gradients}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Differences between CCMpred and CCMpredpy}{21}{subsection.3.2.2}}
\newlabel{diff-ccmpred-ccmpredpy}{{3.2.2}{21}{Differences between CCMpred and CCMpredpy}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Sequence Reweighting}{22}{subsection.3.2.3}}
\newlabel{seq-reweighting}{{3.2.3}{22}{Sequence Reweighting}{subsection.3.2.3}{}}
\newlabel{eq:seqweight}{{3.3}{22}{Sequence Reweighting}{equation.3.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Benchmark for CCMpred and CCMpredPy on a dataset of 3124 proteins. ccmpred-vanilla+apc: CCMpred {[}\hyperlink {ref-Seemayer2014}{21}{]} with \hyperlink {abbrev}{APC}. ccmpred-pll-centerv+apc: CCMpredPy with \hyperlink {abbrev}{APC}. Specific flags that have been used to run both methods are described in detail in the text (see section \ref  {diff-ccmpred-ccmpredpy}).}}{23}{figure.3.2}}
\newlabel{fig:cmmpredvanilla-vs-ccmpredpy}{{3.2}{23}{Benchmark for CCMpred and CCMpredPy on a dataset of 3124 proteins. ccmpred-vanilla+apc: CCMpred {[}\protect \hyperlink {ref-Seemayer2014}{21}{]} with \protect \hyperlink {abbrev}{APC}. ccmpred-pll-centerv+apc: CCMpredPy with \protect \hyperlink {abbrev}{APC}. Specific flags that have been used to run both methods are described in detail in the text (see section \ref {diff-ccmpred-ccmpredpy})}{figure.3.2}{}}
\newlabel{eq:neff}{{3.4}{24}{Sequence Reweighting}{equation.3.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Computing Amino Acid Frequencies}{24}{subsection.3.2.4}}
\newlabel{amino-acid-frequencies}{{3.2.4}{24}{Computing Amino Acid Frequencies}{subsection.3.2.4}{}}
\newlabel{eq:pseudocounts}{{3.7}{24}{Computing Amino Acid Frequencies}{equation.3.2.7}{}}
\newlabel{eq:tau}{{3.8}{24}{Computing Amino Acid Frequencies}{equation.3.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Analysis of Coupling Matrices}{24}{section.3.3}}
\newlabel{analysis-of-coupling-matrices}{{3.3}{24}{Analysis of Coupling Matrices}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Correlation of Couplings with Contact Class}{24}{subsection.3.3.1}}
\newlabel{method-coupling-correlation}{{3.3.1}{24}{Correlation of Couplings with Contact Class}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Coupling Distribution Plots}{25}{subsection.3.3.2}}
\newlabel{method-coupling-profile}{{3.3.2}{25}{Coupling Distribution Plots}{subsection.3.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Optimizing the Full-Likelihood}{25}{section.3.4}}
\newlabel{methods-optimizing-full-likelihood}{{3.4}{25}{Optimizing the Full-Likelihood}{section.3.4}{}}
\newlabel{eq:gradient-convergence-criterion}{{3.9}{26}{Optimizing the Full-Likelihood}{equation.3.4.9}{}}
\newlabel{eq:parameter-convergence-criterion}{{3.10}{26}{Optimizing the Full-Likelihood}{equation.3.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Full Likelihood Optimization with \emph  {ADAM}}{27}{subsection.3.4.1}}
\newlabel{methods-full-likelihood-adam}{{3.4.1}{27}{\texorpdfstring {Full Likelihood Optimization with \emph {ADAM}}{Full Likelihood Optimization with ADAM}}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Full Likelihood Optimization with Stochastic Gradient Descent}{28}{subsection.3.4.2}}
\newlabel{full-likelihood-optimization-with-stochastic-gradient-descent}{{3.4.2}{28}{Full Likelihood Optimization with Stochastic Gradient Descent}{subsection.3.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Mean precision for top ranked contact predictions over 286 proteins. Contact scores are computed as the \hyperlink {abbrev}{APC} corrected Frobenius norm of the couplings \(\mathbf  {w}_{ij}\). pseudo-likelihood: Contact scores computed from pseudo-likelihood. The other methods derive contact scores from couplings computed from \hyperlink {abbrev}{CD} using stochastic gradient descent with different initial learning rates \(\alpha _0\) as specified in the legend.}}{29}{figure.3.3}}
\newlabel{fig:performance-cd-alphaopt}{{3.3}{29}{Mean precision for top ranked contact predictions over 286 proteins. Contact scores are computed as the \protect \hyperlink {abbrev}{APC} corrected Frobenius norm of the couplings \(\wij \). pseudo-likelihood: Contact scores computed from pseudo-likelihood. The other methods derive contact scores from couplings computed from \protect \hyperlink {abbrev}{CD} using stochastic gradient descent with different initial learning rates \(\alpha _0\) as specified in the legend}{figure.3.3}{}}
\newlabel{eq:learning-rate-wrt-neff}{{3.18}{29}{Full Likelihood Optimization with Stochastic Gradient Descent}{equation.3.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces L2-norm of the coupling parameters \(||\mathbf  {w}||_2\) during stochastic gradient descent optimization with different learning rates. Linear learning rate annealing schedule has been used with decay rate \(\gamma =0.01\) and initial learning rates \(\alpha _0\) as stated in the legend. \textbf  {Left} Convergence plot for protein 1mkc\_A\_00 having protein length L=43 and 142 sequences in the alignment (\hyperlink {abbrev}{Neff}=96). \textbf  {Right} Convergence plot for protein 1c75\_A\_00 having protein length L=71 and 28078 sequences in the alignment (\hyperlink {abbrev}{Neff}=16808). Figure is cut at the yaxis at \(||\mathbf  {w}||_2=1500\), but learning rate of \(5\mathrm  {e}{-3}\) reaches \(||\mathbf  {w}||_2 \approx 13000\).}}{30}{figure.3.4}}
\newlabel{fig:sgd-single-proteins-initial-learning-rate}{{3.4}{30}{L2-norm of the coupling parameters \(||\w ||_2\) during stochastic gradient descent optimization with different learning rates. Linear learning rate annealing schedule has been used with decay rate \(\gamma =0.01\) and initial learning rates \(\alpha _0\) as stated in the legend. \textbf {Left} Convergence plot for protein 1mkc\_A\_00 having protein length L=43 and 142 sequences in the alignment (\protect \hyperlink {abbrev}{Neff}=96). \textbf {Right} Convergence plot for protein 1c75\_A\_00 having protein length L=71 and 28078 sequences in the alignment (\protect \hyperlink {abbrev}{Neff}=16808). Figure is cut at the yaxis at \(||\w ||_2=1500\), but learning rate of \(5\mathrm {e}{-3}\) reaches \(||\w ||_2 \approx 13000\)}{figure.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Optimizing Regularization Coefficients for Contrastive Divergence}{31}{subsection.3.4.3}}
\newlabel{optimizing-regularization-coefficients-for-contrastive-divergence}{{3.4.3}{31}{Optimizing Regularization Coefficients for Contrastive Divergence}{subsection.3.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces L2-norm of the coupling parameters \(||\mathbf  {w}||_2\) during stochastic gradient descent optimization with different learning rates schedules. The initial learning rate \(\alpha _0\) is defined with respect to \hyperlink {abbrev}{Neff} as given in eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:learning-rate-wrt-neff}\unskip \@@italiccorr )}}. Learning rate schedules and decay rates are used according to the legend. \textbf  {Left} Convergence plot for protein 1mkc\_A\_00 having protein length L=43 and 142 sequences in the alignment (\hyperlink {abbrev}{Neff}=96). \textbf  {Right} Convergence plot for protein 1c75\_A\_00 having protein length L=71 and 28078 sequences in the alignment (\hyperlink {abbrev}{Neff}=16808).}}{32}{figure.3.5}}
\newlabel{fig:sgd-single-proteins-learning-rate-schedule}{{3.5}{32}{L2-norm of the coupling parameters \(||\w ||_2\) during stochastic gradient descent optimization with different learning rates schedules. The initial learning rate \(\alpha _0\) is defined with respect to \protect \hyperlink {abbrev}{Neff} as given in eq. \eqref {eq:learning-rate-wrt-neff}. Learning rate schedules and decay rates are used according to the legend. \textbf {Left} Convergence plot for protein 1mkc\_A\_00 having protein length L=43 and 142 sequences in the alignment (\protect \hyperlink {abbrev}{Neff}=96). \textbf {Right} Convergence plot for protein 1c75\_A\_00 having protein length L=71 and 28078 sequences in the alignment (\protect \hyperlink {abbrev}{Neff}=16808)}{figure.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Distribution of the number of iterations until convergence for \hyperlink {abbrev}{SGD} optimizations of the full likelihood for different learning rate schedules. Convergence is reached when the relative difference of parameter norms \(||\mathbf  {w}||_2\) falls below \(\epsilon \tmspace  -\thinmuskip {.1667em}=\tmspace  -\thinmuskip {.1667em}1e-8\). Initial learning rate \(\alpha _0\) is defined with respect to \hyperlink {abbrev}{Neff} as given in eq. \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:learning-rate-wrt-neff}\unskip \@@italiccorr )}} and maximum number of iterations is set to 5000. Learning rate schedules and decay rates are used according to the legend.}}{33}{figure.3.6}}
\newlabel{fig:distribution-num-iterations}{{3.6}{33}{Distribution of the number of iterations until convergence for \protect \hyperlink {abbrev}{SGD} optimizations of the full likelihood for different learning rate schedules. Convergence is reached when the relative difference of parameter norms \(||\w ||_2\) falls below \(\epsilon \eq 1e-8\). Initial learning rate \(\alpha _0\) is defined with respect to \protect \hyperlink {abbrev}{Neff} as given in eq. \eqref {eq:learning-rate-wrt-neff} and maximum number of iterations is set to 5000. Learning rate schedules and decay rates are used according to the legend}{figure.3.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Number of contacts (\(C_\beta < 8 \angstrom \)) with respect to protein length and sequence separation has a linear relationship.}}{33}{figure.3.7}}
\newlabel{fig:number-contacts-against-L}{{3.7}{33}{Number of contacts (\(\Cb < 8 \angstrom \)) with respect to protein length and sequence separation has a linear relationship}{figure.3.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Performance of contrastive divergence optimization of the full likelihood with different regularization settings compared to pseudo-likelihood (blue) for 280 proteins. Contact scores are computed as the \hyperlink {abbrev}{APC} corrected Frobenius norm of the couplings \(\mathbf  {w}_{ij}\). Default regularization coefficients as used with pseudo-likelihood are \(\lambda _v \tmspace  -\thinmuskip {.1667em}=\tmspace  -\thinmuskip {.1667em}10\) and \(\lambda _w \tmspace  -\thinmuskip {.1667em}=\tmspace  -\thinmuskip {.1667em}0.2(L-1)\). ``fixed vi'' (orange) uses \hyperlink {abbrev}{CD} to optimize only couplings with default regularization while keeping the single potentials \(v_{i}\) fixed at their \hyperlink {abbrev}{MLE} optimum \(v_{i}^*\). The other optimization runs with \hyperlink {abbrev}{CD} (green, red, purple, brown) use default regularization for the single potentials and a regularization coefficient for the couplings according to legend description.}}{34}{figure.3.8}}
\newlabel{fig:precison-cd-regularization}{{3.8}{34}{Performance of contrastive divergence optimization of the full likelihood with different regularization settings compared to pseudo-likelihood (blue) for 280 proteins. Contact scores are computed as the \protect \hyperlink {abbrev}{APC} corrected Frobenius norm of the couplings \(\wij \). Default regularization coefficients as used with pseudo-likelihood are \(\lambda _v \eq 10\) and \(\lambda _w \eq 0.2(L-1)\). ``fixed vi'' (orange) uses \protect \hyperlink {abbrev}{CD} to optimize only couplings with default regularization while keeping the single potentials \(\vi \) fixed at their \protect \hyperlink {abbrev}{MLE} optimum \(\vi ^*\). The other optimization runs with \protect \hyperlink {abbrev}{CD} (green, red, purple, brown) use default regularization for the single potentials and a regularization coefficient for the couplings according to legend description}{figure.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Optimizing the Sampling Scheme for Contrastive Divergence}{34}{subsection.3.4.4}}
\newlabel{optimizing-the-sampling-scheme-for-contrastive-divergence}{{3.4.4}{34}{Optimizing the Sampling Scheme for Contrastive Divergence}{subsection.3.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Performance of contrastive divergence optimization of the full likelihood with different number of Gibbs steps compared to pseudo-likelihood (blue) for 287 proteins. Contact scores are computed as the \hyperlink {abbrev}{APC} corrected Frobenius norm of the couplings \(\mathbf  {w}_{ij}\). pseudo-likelihood: contact scores computed from pseudo-likelihood. The other methods derive contact scores from couplings computed from \hyperlink {abbrev}{CD} with different number of Gibbs sampling steps.}}{36}{figure.3.9}}
\newlabel{fig:precision-cd-gibbs-steps}{{3.9}{36}{Performance of contrastive divergence optimization of the full likelihood with different number of Gibbs steps compared to pseudo-likelihood (blue) for 287 proteins. Contact scores are computed as the \protect \hyperlink {abbrev}{APC} corrected Frobenius norm of the couplings \(\wij \). pseudo-likelihood: contact scores computed from pseudo-likelihood. The other methods derive contact scores from couplings computed from \protect \hyperlink {abbrev}{CD} with different number of Gibbs sampling steps}{figure.3.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Bayesian Model for Residue-Resdiue Contact Prediction}{36}{section.3.5}}
\newlabel{bayesian-model-for-residue-resdiue-contact-prediction}{{3.5}{36}{Bayesian Model for Residue-Resdiue Contact Prediction}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Efficiently Computing the negative Hessian of the regularized log-likelihood}{36}{subsection.3.5.1}}
\newlabel{neg-Hessian-computation}{{3.5.1}{36}{Efficiently Computing the negative Hessian of the regularized log-likelihood}{subsection.3.5.1}{}}
\newlabel{eq:Hw-offdiag}{{3.35}{38}{Efficiently Computing the negative Hessian of the regularized log-likelihood}{equation.3.5.32}{}}
\newlabel{eq:Hw-diag}{{3.39}{38}{Efficiently Computing the negative Hessian of the regularized log-likelihood}{equation.3.5.39}{}}
\newlabel{eq:mat-Hij}{{3.42}{38}{Efficiently Computing the negative Hessian of the regularized log-likelihood}{equation.3.5.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Efficiently Computing the Inverse of Matrix \(\mathbf  {\Lambda }_{ij,k}\)}{38}{subsection.3.5.2}}
\newlabel{inv-lambda-ij-k}{{3.5.2}{38}{\texorpdfstring {Efficiently Computing the Inverse of Matrix \(\Lijk \)}{Efficiently Computing the Inverse of Matrix \textbackslash {}Lijk}}{subsection.3.5.2}{}}
\newlabel{eq:mat-Lijk}{{3.43}{39}{\texorpdfstring {Efficiently Computing the Inverse of Matrix \(\Lijk \)}{Efficiently Computing the Inverse of Matrix \textbackslash {}Lijk}}{equation.3.5.43}{}}
\newlabel{eq:fast-inverse-mat-Lijk}{{3.51}{39}{\texorpdfstring {Efficiently Computing the Inverse of Matrix \(\Lijk \)}{Efficiently Computing the Inverse of Matrix \textbackslash {}Lijk}}{equation.3.5.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Training the Hyperparameters \(\mathbf  {\mu }_k\), \(\mathbf  {\Lambda }_k\) and \(\gamma _k\)}{40}{subsection.3.5.3}}
\newlabel{training-hyperparameters}{{3.5.3}{40}{\texorpdfstring {Training the Hyperparameters \(\muk \), \(\Lk \) and \(\gamma _k\)}{Training the Hyperparameters \textbackslash {}muk, \textbackslash {}Lk and \textbackslash {}gamma\_k}}{subsection.3.5.3}{}}
\newlabel{eq:reg}{{3.56}{40}{\texorpdfstring {Training the Hyperparameters \(\muk \), \(\Lk \) and \(\gamma _k\)}{Training the Hyperparameters \textbackslash {}muk, \textbackslash {}Lk and \textbackslash {}gamma\_k}}{equation.3.5.56}{}}
\newlabel{eq:ll-coupling-prior}{{3.57}{40}{\texorpdfstring {Training the Hyperparameters \(\muk \), \(\Lk \) and \(\gamma _k\)}{Training the Hyperparameters \textbackslash {}muk, \textbackslash {}Lk and \textbackslash {}gamma\_k}}{equation.3.5.57}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}The gradient of the log likelihood with respect to \(\mathbf  {\mu }\)}{40}{subsection.3.5.4}}
\newlabel{the-gradient-of-the-log-likelihood-with-respect-to-mathbfmu}{{3.5.4}{40}{\texorpdfstring {The gradient of the log likelihood with respect to \(\mathbf {\mu }\)}{The gradient of the log likelihood with respect to \textbackslash {}mathbf\{\textbackslash {}mu\}}}{subsection.3.5.4}{}}
\newlabel{eq:gradient-mukab}{{3.58}{40}{\texorpdfstring {The gradient of the log likelihood with respect to \(\mathbf {\mu }\)}{The gradient of the log likelihood with respect to \textbackslash {}mathbf\{\textbackslash {}mu\}}}{equation.3.5.58}{}}
\newlabel{eq:responsibilities}{{3.59}{41}{\texorpdfstring {The gradient of the log likelihood with respect to \(\mathbf {\mu }\)}{The gradient of the log likelihood with respect to \textbackslash {}mathbf\{\textbackslash {}mu\}}}{equation.3.5.59}{}}
\newlabel{eq:gradient-LL-mukab}{{3.60}{41}{\texorpdfstring {The gradient of the log likelihood with respect to \(\mathbf {\mu }\)}{The gradient of the log likelihood with respect to \textbackslash {}mathbf\{\textbackslash {}mu\}}}{equation.3.5.60}{}}
\newlabel{eq:matrix-gradient}{{3.62}{41}{\texorpdfstring {The gradient of the log likelihood with respect to \(\mathbf {\mu }\)}{The gradient of the log likelihood with respect to \textbackslash {}mathbf\{\textbackslash {}mu\}}}{equation.3.5.62}{}}
\newlabel{eq:gradient-muk-final}{{3.65}{41}{\texorpdfstring {The gradient of the log likelihood with respect to \(\mathbf {\mu }\)}{The gradient of the log likelihood with respect to \textbackslash {}mathbf\{\textbackslash {}mu\}}}{equation.3.5.65}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}The gradient of the log likelihood with respect to \(\mathbf  {\Lambda }_k\)}{41}{subsection.3.5.5}}
\newlabel{the-gradient-of-the-log-likelihood-with-respect-to-lk}{{3.5.5}{41}{\texorpdfstring {The gradient of the log likelihood with respect to \(\Lk \)}{The gradient of the log likelihood with respect to \textbackslash {}Lk}}{subsection.3.5.5}{}}
\newlabel{eq:grad-log-N-N-lambdakabcd}{{3.67}{42}{\texorpdfstring {The gradient of the log likelihood with respect to \(\Lk \)}{The gradient of the log likelihood with respect to \textbackslash {}Lk}}{equation.3.5.67}{}}
\newlabel{eq:gradient-lambdak-final}{{3.77}{42}{\texorpdfstring {The gradient of the log likelihood with respect to \(\Lk \)}{The gradient of the log likelihood with respect to \textbackslash {}Lk}}{equation.3.5.77}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.6}The gradient of the log likelihood with respect to \(\gamma _k\)}{43}{subsection.3.5.6}}
\newlabel{the-gradient-of-the-log-likelihood-with-respect-to-gamma_k}{{3.5.6}{43}{\texorpdfstring {The gradient of the log likelihood with respect to \(\gamma _k\)}{The gradient of the log likelihood with respect to \textbackslash {}gamma\_k}}{subsection.3.5.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Bayesian Statistical Model for Prediction of Protein Residue-Residue Distances}{43}{section.3.6}}
\newlabel{bayesian-statistical-model-for-prediction-of-protein-residue-residue-distances}{{3.6}{43}{Bayesian Statistical Model for Prediction of Protein Residue-Residue Distances}{section.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Modelling the dependence of \(\mathbf  {w}_{ij}\) on distance}{43}{subsection.3.6.1}}
\newlabel{modelling-the-dependence-of-wij-on-distance}{{3.6.1}{43}{\texorpdfstring {Modelling the dependence of \(\wij \) on distance}{Modelling the dependence of \textbackslash {}wij on distance}}{subsection.3.6.1}{}}
\newlabel{eq:definition-mixture-weights}{{3.84}{43}{\texorpdfstring {Modelling the dependence of \(\wij \) on distance}{Modelling the dependence of \textbackslash {}wij on distance}}{equation.3.6.84}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces The Gaussian mixture coefficients \(g_k(r_{ij})\) of \(p(\mathbf  {w}_{ij}|r_{ij})\) are modelled as softmax over linear functions \(\gamma _k(r_{ij})\). \(\rho _k\) sets the transition point between neighbouring components \(g_{k-1}(r_{ij})\) and \(g_k(r_{ij})\), while \(\alpha _k\) quantifies the abruptness of the transition between \(g_{k-1}(r_{ij})\) and \(g_k(r_{ij})\).}}{44}{figure.3.10}}
\newlabel{fig:softmax-linear-fct}{{3.10}{44}{The Gaussian mixture coefficients \(g_k(\rij )\) of \(p(\wij |\rij )\) are modelled as softmax over linear functions \(\gamma _k(\rij )\). \(\rho _k\) sets the transition point between neighbouring components \(g_{k-1}(\rij )\) and \(g_k(\rij )\), while \(\alpha _k\) quantifies the abruptness of the transition between \(g_{k-1}(\rij )\) and \(g_k(\rij )\)}{figure.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Training the Hyperparameters \(\rho _k\) and \(\alpha _k\) for distance-dependent prior}{44}{subsection.3.6.2}}
\newlabel{training-the-hyperparameters-rho_k-and-alpha_k-for-distance-dependent-prior}{{3.6.2}{44}{\texorpdfstring {Training the Hyperparameters \(\rho _k\) and \(\alpha _k\) for distance-dependent prior}{Training the Hyperparameters \textbackslash {}rho\_k and \textbackslash {}alpha\_k for distance-dependent prior}}{subsection.3.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Training Random Forest Contat Prior}{44}{section.3.7}}
\newlabel{training-random-forest-contat-prior}{{3.7}{44}{Training Random Forest Contat Prior}{section.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Sequence Derived Features}{44}{subsection.3.7.1}}
\newlabel{seq-features}{{3.7.1}{44}{Sequence Derived Features}{subsection.3.7.1}{}}
\gdef \LT@i {\LT@entry 
    {1}{102.19656pt}\LT@entry 
    {1}{221.12685pt}\LT@entry 
    {1}{81.2826pt}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1.1}Global Features}{45}{subsubsection.3.7.1.1}}
\newlabel{seq-features-global}{{3.7.1.1}{45}{Global Features}{subsubsection.3.7.1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{Features characterizing the total alignment}}{45}{table.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1.2}Single Position Features}{45}{subsubsection.3.7.1.2}}
\newlabel{seq-features-single}{{3.7.1.2}{45}{Single Position Features}{subsubsection.3.7.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{Single Position Sequence Features}}{45}{table.3.2}}
\gdef \LT@ii {\LT@entry 
    {1}{102.19656pt}\LT@entry 
    {1}{221.12685pt}\LT@entry 
    {1}{81.2826pt}}
\gdef \LT@iii {\LT@entry 
    {1}{102.19656pt}\LT@entry 
    {1}{221.12685pt}\LT@entry 
    {1}{81.2826pt}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1.3}Pairwise Features}{47}{subsubsection.3.7.1.3}}
\newlabel{seq-features-pairwise}{{3.7.1.3}{47}{Pairwise Features}{subsubsection.3.7.1.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{Pairwise Sequence Features}}{47}{table.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Observed number of contacts per residue has a non-linear relationship with protein length. Distribution is shown for several thresholds of sequence separation.}}{48}{figure.3.11}}
\newlabel{fig:avg-nr-contacts-per-residue-vs-protein-length}{{3.11}{48}{Observed number of contacts per residue has a non-linear relationship with protein length. Distribution is shown for several thresholds of sequence separation}{figure.3.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1.4}Protein length dependent Contact Prior}{48}{subsubsection.3.7.1.4}}
\newlabel{contact-prior-protein-length}{{3.7.1.4}{48}{Protein length dependent Contact Prior}{subsubsection.3.7.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces (ref:caption-avg-nr-contacts-per-residue-vs-log-protein-length-linfit)}}{49}{figure.3.12}}
\newlabel{fig:avg-nr-contacts-per-residue-vs-log-protein-length-linfit}{{3.12}{49}{(ref:caption-avg-nr-contacts-per-residue-vs-log-protein-length-linfit)}{figure.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Hyperparameter Optimization for Random Forest Prior}{49}{subsection.3.7.2}}
\newlabel{rf-hyperparameter-optimization}{{3.7.2}{49}{Hyperparameter Optimization for Random Forest Prior}{subsection.3.7.2}{}}
\gdef \LT@iv {\LT@entry 
    {2}{133.28621pt}\LT@entry 
    {1}{130.70433pt}\LT@entry 
    {1}{146.568pt}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Fraction of contacts among all possible contacts (\(\frac  {L(L-1)}{2}\)) in a protein against protein length L. The distribution has a non-linear relationship. At a sequence separation threshold \textgreater {}8 positions the fraction of contacts for intermediate size proteins with length \textgreater {}100 is approximately 2\%.}}{50}{figure.3.13}}
\newlabel{fig:fraction-contacts-vs-protein-length}{{3.13}{50}{Fraction of contacts among all possible contacts (\(\frac {L(L-1)}{2}\)) in a protein against protein length L. The distribution has a non-linear relationship. At a sequence separation threshold \textgreater {}8 positions the fraction of contacts for intermediate size proteins with length \textgreater {}100 is approximately 2\%}{figure.3.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces Mean precision over 200 proteins against highest scoring contact predictions from random forest models for different settings of \emph  {n\_estimators} and \emph  {max\_depth}. Dashed lines show the performance of models that have been learned on the five different subsets of training data. Solid lines give the mean precision over the five models. Only those models are shown that yielded the five highest mean precision values (given in parantheses in the legend). Random forest models with 1000 trees and maximum depth of trees of either 100, 1000 or unrestricted tree depth perform nearly identical (lines overlap). Random forest models with 500 trees and \emph  {max\_depth}=10 or \emph  {max\_depth}=100 perform slightly worse.}}{52}{figure.3.14}}
\newlabel{fig:rf-gridsearch-nestimators-maxfeatures}{{3.14}{52}{Mean precision over 200 proteins against highest scoring contact predictions from random forest models for different settings of \emph {n\_estimators} and \emph {max\_depth}. Dashed lines show the performance of models that have been learned on the five different subsets of training data. Solid lines give the mean precision over the five models. Only those models are shown that yielded the five highest mean precision values (given in parantheses in the legend). Random forest models with 1000 trees and maximum depth of trees of either 100, 1000 or unrestricted tree depth perform nearly identical (lines overlap). Random forest models with 500 trees and \emph {max\_depth}=10 or \emph {max\_depth}=100 perform slightly worse}{figure.3.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Mean precision over 200 proteins against highest scoring contact predictions from random forest models with different settings of \emph  {min\_samples\_leaf} and \emph  {max\_features}. Dashed lines show the performance of models that have been learned on the five different subsets of training data. Solid lines give the mean precision over the five models. Only those models are shown that yielded the five best mean precision values (given in parantheses in the legend).}}{53}{figure.3.15}}
\newlabel{fig:rf-gridsearch-maxdepth-minsampleleaf}{{3.15}{53}{Mean precision over 200 proteins against highest scoring contact predictions from random forest models with different settings of \emph {min\_samples\_leaf} and \emph {max\_features}. Dashed lines show the performance of models that have been learned on the five different subsets of training data. Solid lines give the mean precision over the five models. Only those models are shown that yielded the five best mean precision values (given in parantheses in the legend)}{figure.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Feature Selection}{54}{subsection.3.7.3}}
\newlabel{rf-feature-selection}{{3.7.3}{54}{Feature Selection}{subsection.3.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.4}Using Pseudo-likelihood Coevolution Score as Additional Feature}{54}{subsection.3.7.4}}
\newlabel{rf-with-pll-score}{{3.7.4}{54}{Using Pseudo-likelihood Coevolution Score as Additional Feature}{subsection.3.7.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Top ten features ranked according to \emph  {Gini importance}. \textbf  {pseudo-likelihood}: \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings computed with pseudo-likelihood. \textbf  {mean pair potential (Miyasawa \& Jernigan)}: average quasi-chemical energy of transfer of amino acids from water to the protein environment {[}\hyperlink {ref-Miyazawa1999a}{15}{]}. \textbf  {OMES+APC}: \hyperlink {abbrev}{APC} corrected OMES score according to Fodor\&Aldrich {[}\hyperlink {ref-Fodor2004a}{14}{]}. \textbf  {mean pair potential (Li\&Fang)}: average general contact potential by Li \& Fang {[}\hyperlink {ref-Li2011}{16}{]}. \textbf  {rel. solvent accessibilty i(j)}: RSA score computed with Netsurfp (v1.0) {[}\hyperlink {ref-Petersen2009a}{17}{]} for position i(j). \textbf  {MI+APC}: \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts). \textbf  {contact prior wrt L}: simple contact prior based on expected number of contacts wrt protein length (see methods section \ref  {contact-prior-protein-length}). \textbf  {log protein length}: logarithm of protein length. \textbf  {beta sheet propensity window(i)}: beta-sheet propensity according to Psipred {[}\hyperlink {ref-Jones1999}{18}{]} computed within a window of five positions around i. Features are described in detail in methods section \ref  {seq-features}.}}{55}{figure.3.16}}
\newlabel{fig:feature-importance-rf-with-pll-score}{{3.16}{55}{Top ten features ranked according to \emph {Gini importance}. \textbf {pseudo-likelihood}: \protect \hyperlink {abbrev}{APC} corrected Frobenius norm of couplings computed with pseudo-likelihood. \textbf {mean pair potential (Miyasawa \& Jernigan)}: average quasi-chemical energy of transfer of amino acids from water to the protein environment {[}\protect \hyperlink {ref-Miyazawa1999a}{15}{]}. \textbf {OMES+APC}: \protect \hyperlink {abbrev}{APC} corrected OMES score according to Fodor\&Aldrich {[}\protect \hyperlink {ref-Fodor2004a}{14}{]}. \textbf {mean pair potential (Li\&Fang)}: average general contact potential by Li \& Fang {[}\protect \hyperlink {ref-Li2011}{16}{]}. \textbf {rel. solvent accessibilty i(j)}: RSA score computed with Netsurfp (v1.0) {[}\protect \hyperlink {ref-Petersen2009a}{17}{]} for position i(j). \textbf {MI+APC}: \protect \hyperlink {abbrev}{APC} corrected mutual information between amino acid counts (using pseudo-counts). \textbf {contact prior wrt L}: simple contact prior based on expected number of contacts wrt protein length (see methods section \ref {contact-prior-protein-length}). \textbf {log protein length}: logarithm of protein length. \textbf {beta sheet propensity window(i)}: beta-sheet propensity according to Psipred {[}\protect \hyperlink {ref-Jones1999}{18}{]} computed within a window of five positions around i. Features are described in detail in methods section \ref {seq-features}}{figure.3.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Mean precision for top ranked contacts over 200 proteins for variaous random forest models trained on subsets of features. Subsets of features have been selected as described in section \ref  {rf-feature-selection}.}}{56}{figure.3.17}}
\newlabel{fig:feature-selection-rf-with-pll-score}{{3.17}{56}{Mean precision for top ranked contacts over 200 proteins for variaous random forest models trained on subsets of features. Subsets of features have been selected as described in section \ref {rf-feature-selection}}{figure.3.17}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Abbreviations}{57}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{abbrev}{{A}{57}{Abbreviations}{appendix.A}{}}
\gdef \LT@v {\LT@entry 
    {1}{88.57553pt}\LT@entry 
    {1}{103.71432pt}\LT@entry 
    {2}{87.47147pt}\LT@entry 
    {2}{263.90984pt}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Amino Acid Alphabet}{58}{section.A.1}}
\newlabel{amino-acids}{{A.1}{58}{Amino Acid Alphabet}{section.A.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Dataset Properties}{59}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{dataset-properties}{{B}{59}{Dataset Properties}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Alignment Diversity}{59}{section.B.1}}
\newlabel{alignment-diversity}{{B.1}{59}{Alignment Diversity}{section.B.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Proportion of Gaps in Alignment}{59}{section.B.2}}
\newlabel{proportion-of-gaps-in-alignment}{{B.2}{59}{Proportion of Gaps in Alignment}{section.B.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Alignment Size (number of sequences)}{59}{section.B.3}}
\newlabel{alignment-size-number-of-sequences}{{B.3}{59}{Alignment Size (number of sequences)}{section.B.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.4}Protein Length}{59}{section.B.4}}
\newlabel{protein-length}{{B.4}{59}{Protein Length}{section.B.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Distribution of alignment diversity (\(=\sqrt  (\frac  {N}{L})\)) in the dataset an its ten subsets.}}{60}{figure.B.1}}
\newlabel{fig:dataset-diversity}{{B.1}{60}{Distribution of alignment diversity (\(=\sqrt (\frac {N}{L})\)) in the dataset an its ten subsets}{figure.B.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Distribution of gap percentage of alignments in the dataset an its ten subsets.}}{61}{figure.B.2}}
\newlabel{fig:dataset-gaps}{{B.2}{61}{Distribution of gap percentage of alignments in the dataset an its ten subsets}{figure.B.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Distribution of alignment size (number of sequences N) in the dataset an its ten subsets.}}{62}{figure.B.3}}
\newlabel{fig:dataset-alignment-size}{{B.3}{62}{Distribution of alignment size (number of sequences N) in the dataset an its ten subsets}{figure.B.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.4}{\ignorespaces Distribution of protein length L in the dataset an its ten subsets.}}{63}{figure.B.4}}
\newlabel{fig:dataset-protein-length}{{B.4}{63}{Distribution of protein length L in the dataset an its ten subsets}{figure.B.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Amino Acid Interaction Preferences Reflected in Coupling Matrices}{65}{appendix.C}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{amino-acid-interaction-preferences-reflected-in-coupling-matrices}{{C}{65}{Amino Acid Interaction Preferences Reflected in Coupling Matrices}{appendix.C}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Pi-Cation interactions}{65}{section.C.1}}
\newlabel{pi-cation}{{C.1}{65}{Pi-Cation interactions}{section.C.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.2}Disulfide Bonds}{65}{section.C.2}}
\newlabel{disulfide}{{C.2}{65}{Disulfide Bonds}{section.C.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.1}{\ignorespaces Tyrosing (residue 37) and Lysine (residue 48) forming a cation-\(\pi \) interaction in protein 2ayd.}}{65}{figure.C.1}}
\newlabel{fig:coupling-matrix-pication-pymol}{{C.1}{65}{Tyrosing (residue 37) and Lysine (residue 48) forming a cation-\(\pi \) interaction in protein 2ayd}{figure.C.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.2}{\ignorespaces Coupling Matrix for residue pair i=37 and j=48 of PDB 2ayd chain A domain 1. Size of the bubbles represents coupling strength and color represents the direction of coupling: red = positive coupling, blue = negative coupling. Bars at the x-axis represent single potentials for residue i=37 and bars at the y-axis represent single potentials for residue j=48. Height of the bars represents potential strength and color represents positive (red) and negative (blue) values.}}{66}{figure.C.2}}
\newlabel{fig:coupling-matrix-pication-interaction}{{C.2}{66}{Coupling Matrix for residue pair i=37 and j=48 of PDB 2ayd chain A domain 1. Size of the bubbles represents coupling strength and color represents the direction of coupling: red = positive coupling, blue = negative coupling. Bars at the x-axis represent single potentials for residue i=37 and bars at the y-axis represent single potentials for residue j=48. Height of the bars represents potential strength and color represents positive (red) and negative (blue) values}{figure.C.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.3}{\ignorespaces Two cystein residues (residues 54 and 64) forming a covalent disulfide bond in protein 1alu.}}{67}{figure.C.3}}
\newlabel{fig:coupling-matrix-disulfide-pymol}{{C.3}{67}{Two cystein residues (residues 54 and 64) forming a covalent disulfide bond in protein 1alu}{figure.C.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.3}Aromatic-Proline Interactions}{67}{section.C.3}}
\newlabel{aromatic-proline}{{C.3}{67}{Aromatic-Proline Interactions}{section.C.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.4}Network-like structure of aromatic residues}{67}{section.C.4}}
\newlabel{aromatic-network}{{C.4}{67}{Network-like structure of aromatic residues}{section.C.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.4}{\ignorespaces Coupling Matrix for residue pair i=54 and j=64 of PDB 1alu chain A. Size of the bubbles represents coupling strength and color represents the direction of coupling: red = positive coupling, blue = negative coupling. Bars at the x-axis represent single potentials for residue i=54 and bars at the y-axis represent single potentials for residue j=64. Height of the bars represents potential strength and color represents positive (red) and negative (blue) values.}}{68}{figure.C.4}}
\newlabel{fig:coupling-matrix-disulfide-interaction}{{C.4}{68}{Coupling Matrix for residue pair i=54 and j=64 of PDB 1alu chain A. Size of the bubbles represents coupling strength and color represents the direction of coupling: red = positive coupling, blue = negative coupling. Bars at the x-axis represent single potentials for residue i=54 and bars at the y-axis represent single potentials for residue j=64. Height of the bars represents potential strength and color represents positive (red) and negative (blue) values}{figure.C.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.5}{\ignorespaces Proline and tryptophan (residues 17 and 34) stacked on top of each otherengaging in a CH/\(\pi \) interaction in protein 1alu.}}{69}{figure.C.5}}
\newlabel{fig:coupling-matrix-aromatic-proline-pymol}{{C.5}{69}{Proline and tryptophan (residues 17 and 34) stacked on top of each otherengaging in a CH/\(\pi \) interaction in protein 1alu}{figure.C.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.6}{\ignorespaces Coupling Matrix for residue pair i=17 and j=34 of PDB 1aol chain A. Size of the bubbles represents coupling strength and color represents the direction of coupling: red = positive coupling, blue = negative coupling. Bars at the x-axis represent single potentials for residue i=17 and bars at the y-axis represent single potentials for residue j=34. Height of the bars represents potential strength and color represents positive (red) and negative (blue) values.}}{70}{figure.C.6}}
\newlabel{fig:coupling-matrix-aromatic-proline}{{C.6}{70}{Coupling Matrix for residue pair i=17 and j=34 of PDB 1aol chain A. Size of the bubbles represents coupling strength and color represents the direction of coupling: red = positive coupling, blue = negative coupling. Bars at the x-axis represent single potentials for residue i=17 and bars at the y-axis represent single potentials for residue j=34. Height of the bars represents potential strength and color represents positive (red) and negative (blue) values}{figure.C.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.7}{\ignorespaces Network-like structure of aromatic residues in the protein core. 80\% of aromatic residues are involved in such networks that are important for protein stability {[}\hyperlink {ref-Burley1985}{2}{]}.}}{71}{figure.C.7}}
\newlabel{fig:aromatic-network}{{C.7}{71}{Network-like structure of aromatic residues in the protein core. 80\% of aromatic residues are involved in such networks that are important for protein stability {[}\protect \hyperlink {ref-Burley1985}{2}{]}}{figure.C.7}{}}
